{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f2d2418-6bb7-4f1d-a5fb-2396322fafb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df668d0c-1119-4ec9-9fbf-e6befb146c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cached\t\t\t\t\t  ERICA--exported.tar.gz\n",
      "distilroberta-finetuned\t\t\t  ERICA--exported.tar.gz.tar.gz\n",
      "distilroberta-finetuned__exported\t  hopperbot-medium\n",
      "distilroberta-finetuned__exported.tar.gz  runs\n",
      "ERICA\n"
     ]
    }
   ],
   "source": [
    "! ls ../../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51607f71-22ba-4027-8bbc-93fadc877313",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"../../models/ERICA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bcebc5-4053-4831-85ec-069013cc4c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(MODEL_NAME).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb72a91e-8e89-41ab-bcea-af6c1f68c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Conversation,\n",
    "    ConversationalPipeline,\n",
    ")\n",
    "\n",
    "from src.chat import *\n",
    "from src.classifier import Classifier\n",
    "from src.utils import DATA_DIR, ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae11576a-82dd-41c6-8151-6400bf6422b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/research/data\n",
      "/home/jovyan/work/research\n"
     ]
    }
   ],
   "source": [
    "print(DATA_DIR)\n",
    "print(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26444ad5-d9fd-404e-ab41-ae6e1a2f65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER = ROOT_DIR.parent.resolve().joinpath(\"models\").joinpath(\"distilroberta-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf9c533-daf1-4022-ab5a-7459408dfbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(CLASSIFIER).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ea018eb-dda0-46db-bc95-8ea736860efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    ")\n",
    "classifier = Classifier(model=str(CLASSIFIER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4622ad77-3e4c-476e-b5f7-30e668afe85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"../../models/ERICA\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"do_sample\": true,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_length\": 1000,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"pad_token_id\": 50256,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"conversational\": {\n",
       "      \"max_length\": 1000\n",
       "    }\n",
       "  },\n",
       "  \"temperature\": 0.8,\n",
       "  \"top_k\": 100,\n",
       "  \"top_p\": 0.7,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0dbf9cf2-782c-4694-a73e-deae8a0d5457",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.pad_token_id = tokenizer.eos_token_id\n",
    "config.max_length = 1000\n",
    "config.no_repeat_ngram_size = 3\n",
    "config.do_sample = True\n",
    "config.top_k = 100\n",
    "config.top_p = 0.7\n",
    "config.temperature = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab4c8e83-bf7b-41d3-bcf5-0c10e04790b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.save_pretrained(\"../../models/ERICA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c36e9554-44ee-43d8-bc39-55c24ee3934b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"../../models/ERICA\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"do_sample\": true,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_length\": 1000,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"pad_token_id\": 50256,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"conversational\": {\n",
       "      \"max_length\": 1000\n",
       "    }\n",
       "  },\n",
       "  \"temperature\": 0.8,\n",
       "  \"top_k\": 100,\n",
       "  \"top_p\": 0.7,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2987795d-fb7e-43bc-b1d8-dcf62e8605d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I'm feeling depressed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I'm feeling depressed\n",
      "Bot:  Why?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  My dad passed away\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My dad passed away\n",
      "Bot:  I'm so sorry to hear that. I lost my father recently as well. May he rest in peace.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Thank you. I am sorry for your loss as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Thank you. I am sorry for your loss as well.\n",
      "Bot:  I am so sad. I hope he is in a better place now.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  He is.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: He is.\n",
      "Bot:  You must be so proud of him!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I am.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I am.\n",
      "Bot:  What are you most proud of?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I am proud of building this chatbot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I am proud of building this chatbot.\n",
      "Bot:  That is great, what did you learn from it so far?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I learned about training bots in an effective way.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I learned about training bots in an effective way.\n",
      "Bot:  What was the method?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/research/src/chat.py:25\u001b[0m, in \u001b[0;36mchat\u001b[0;34m(model, tokenizer, device, classifier, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m>> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/q\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/quit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/e\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/exit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1161\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1160\u001b[0m     )\n\u001b[0;32m-> 1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py:1205\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat(model, tokenizer, classifier=classifier, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4938906a-0725-4406-8e3c-97fc3715952b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I'm feeling depressed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I'm feeling depressed\n",
      "Bot:  I'm sorry to hear that. What's wrong?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  My dad passed away yesterday\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My dad passed away yesterday\n",
      "Bot:  I'm so sorry to hear that. I hope you are doing okay.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Thanks. I am trying my best.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Thanks. I am trying my best.\n",
      "Bot:  What are you trying to do?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I am trying to be positive.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I am trying to be positive.\n",
      "Bot:  That's a good attitude to have.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  It really is. I have a more optimistic outlook on life.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: It really is. I have a more optimistic outlook on life.\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1084405/3896992558.py\", line 1, in <cell line: 1>\n",
      "    chat_pipeline(model, tokenizer, classifier=classifier, device=\"cpu\")\n",
      "  File \"/home/jovyan/work/research/src/chat.py\", line 82, in chat_pipeline\n",
      "    result = pipe(conversation)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/conversational.py\", line 239, in __call__\n",
      "    outputs = super().__call__(conversations, num_workers=num_workers, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1026, in __call__\n",
      "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1033, in run_single\n",
      "    model_outputs = self.forward(model_inputs, **forward_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 943, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/conversational.py\", line 276, in _forward\n",
      "    output_ids = self.model.generate(**model_inputs, **generate_kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py\", line 1278, in generate\n",
      "    return self.greedy_search(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation_utils.py\", line 1672, in greedy_search\n",
      "    outputs = self(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1068, in forward\n",
      "    lm_logits = self.lm_head(hidden_states)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 103, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1993, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "chat_pipeline(model, tokenizer, classifier=classifier, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd6ea083-c4d1-4878-8c4a-50252cccdef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db20087d-9302-4b8d-ae85-024214621bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.add_user_input(\"I am depressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "056f6682-13f5-43b1-a742-5efa6d27df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ConversationalPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=-1,\n",
    ")\n",
    "\n",
    "pipe.model.config.pad_token_id = pipe.tokenizer.eos_token_id\n",
    "pipe.model.config.max_length = 1000\n",
    "pipe.model.config.no_repeat_ngram_size = 3\n",
    "pipe.model.config.do_sample = True\n",
    "pipe.model.config.top_k = 100\n",
    "pipe.model.config.top_p = 0.7\n",
    "pipe.model.config.temperature = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c82e3481-8983-4581-9e00-bd2d9a01668b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"../../models/ERICA\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"do_sample\": true,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_length\": 1000,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 1024,\n",
       "  \"n_head\": 16,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 24,\n",
       "  \"n_positions\": 1024,\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"pad_token_id\": 50256,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"conversational\": {\n",
       "      \"max_length\": 1000\n",
       "    }\n",
       "  },\n",
       "  \"temperature\": 0.8,\n",
       "  \"top_k\": 100,\n",
       "  \"top_p\": 0.7,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.19.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95b383f2-bde3-4066-86dd-a5f8d9a30389",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_user_input(\"I'm feeling very depressed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59481db8-a0a1-4a55-9ffa-6c75a08aba8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 83afa87d-d3f0-44af-afc1-aa1f0072bf30 \n",
       "user >> I'm feeling very depressed \n",
       "bot >> I'm sorry to hear that.  Have you thought about seeking professional help? "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f98fcd8f-7188-46b5-95bd-0890d90fe280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 83afa87d-d3f0-44af-afc1-aa1f0072bf30 \n",
       "user >> I'm feeling very depressed \n",
       "bot >> I'm sorry to hear that.  Have you thought about seeking professional help? \n",
       "user >> I have tried, but it hasn't been helping \n",
       "bot >> I know what you mean.  Maybe you should try going to a spiritual service? "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"I have tried, but it hasn't been helping\")\n",
    "pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9b9de64-4aa0-44b4-9821-08c2a231ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 83afa87d-d3f0-44af-afc1-aa1f0072bf30 \n",
       "user >> I'm feeling very depressed \n",
       "bot >> I'm sorry to hear that.  Have you thought about seeking professional help? \n",
       "user >> I have tried, but it hasn't been helping \n",
       "bot >> I know what you mean.  Maybe you should try going to a spiritual service? \n",
       "user >> I don't really believe in that \n",
       "bot >> I understand.  Try going to find a local church that will pray for you. "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"I don't really believe in that\")\n",
    "pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24da52cf-0158-4c76-bf0d-ae195d1b6da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 83afa87d-d3f0-44af-afc1-aa1f0072bf30 \n",
       "user >> I'm feeling very depressed \n",
       "bot >> I'm sorry to hear that.  Have you thought about seeking professional help? \n",
       "user >> I have tried, but it hasn't been helping \n",
       "bot >> I know what you mean.  Maybe you should try going to a spiritual service? \n",
       "user >> I don't really believe in that \n",
       "bot >> I understand.  Try going to find a local church that will pray for you. \n",
       "user >> I don't go to church \n",
       "bot >> You should try it out.  It will change your life. "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"I don't go to church\")\n",
    "pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3433246-3b3b-4ed8-a14f-9a3761fb4d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: 83afa87d-d3f0-44af-afc1-aa1f0072bf30 \n",
       "user >> I'm feeling very depressed \n",
       "bot >> I'm sorry to hear that.  Have you thought about seeking professional help? \n",
       "user >> I have tried, but it hasn't been helping \n",
       "bot >> I know what you mean.  Maybe you should try going to a spiritual service? \n",
       "user >> I don't really believe in that \n",
       "bot >> I understand.  Try going to find a local church that will pray for you. \n",
       "user >> I don't go to church \n",
       "bot >> You should try it out.  It will change your life. \n",
       "user >> Religion hasn't been helpful \n",
       "bot >> !!!?!!.!!...!!..!! "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.add_user_input(\"Religion hasn't been helpful\")\n",
    "pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "44cd9b37-658a-468a-adef-7ab5db699dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = Conversation()\n",
    "\n",
    "\n",
    "def tokenizer_lengths(conversation):\n",
    "    return list(map(lambda x: len(tokenizer.encode(x)), conversation.past_user_inputs + conversation.generated_responses))\n",
    "\n",
    "\n",
    "def chat_bot(text):\n",
    "    conversation.add_user_input(text)\n",
    "    print(pipe(conversation))\n",
    "    token_lengths = tokenizer_lengths(conversation)\n",
    "    return token_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d471431-a42b-4f4d-a6a9-92211dfc01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2092a85d-ceeb-464c-b665-586ea999064f \n",
      "user >> I can't go to sleep \n",
      "bot >> I'm sorry to hear that. What's wrong? \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 11]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot(\"I can't go to sleep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66861f8b-db85-410d-82ac-c958d0f5e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2092a85d-ceeb-464c-b665-586ea999064f \n",
      "user >> I can't go to sleep \n",
      "bot >> I'm sorry to hear that. What's wrong? \n",
      "user >> I'm worried about the state of the world. \n",
      "bot >> I think that the world is headed in a very positive direction. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 10, 11, 13]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot(\"I'm worried about the state of the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "300cb9ae-8abf-4644-b65d-a8cff38e7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2092a85d-ceeb-464c-b665-586ea999064f \n",
      "user >> I can't go to sleep \n",
      "bot >> I'm sorry to hear that. What's wrong? \n",
      "user >> I'm worried about the state of the world. \n",
      "bot >> I think that the world is headed in a very positive direction. \n",
      "user >> I disagree, I think we're headed towards a very negative path. \n",
      "bot >> You're entitled to your opinion_comma_ but I think there's a lot of truth to it. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 10, 14, 11, 13, 22]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot(\"I disagree, I think we're headed towards a very negative path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4766dbe8-6a2d-413e-9e7b-9c14294e667a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2092a85d-ceeb-464c-b665-586ea999064f \n",
      "user >> I can't go to sleep \n",
      "bot >> I'm sorry to hear that. What's wrong? \n",
      "user >> I'm worried about the state of the world. \n",
      "bot >> I think that the world is headed in a very positive direction. \n",
      "user >> I disagree, I think we're headed towards a very negative path. \n",
      "bot >> You're entitled to your opinion_comma_ but I think there's a lot of truth to it. \n",
      "user >> I guess so \n",
      "bot >> So you think Trump is a bad president? \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 10, 14, 3, 11, 13, 22, 9]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot(\"I guess so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d93060af-1461-42be-8097-6644a5dd163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2092a85d-ceeb-464c-b665-586ea999064f \n",
      "user >> I can't go to sleep \n",
      "bot >> I'm sorry to hear that. What's wrong? \n",
      "user >> I'm worried about the state of the world. \n",
      "bot >> I think that the world is headed in a very positive direction. \n",
      "user >> I disagree, I think we're headed towards a very negative path. \n",
      "bot >> You're entitled to your opinion_comma_ but I think there's a lot of truth to it. \n",
      "user >> I guess so \n",
      "bot >> So you think Trump is a bad president? \n",
      "user >> Trump was a terrible president \n",
      "bot >> !!!?!!.!!...!!..!! \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6, 10, 14, 3, 5, 11, 13, 22, 9, 9]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_bot(\"Trump was a terrible president\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b0884f7-a779-44f8-a983-4705ce21b791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([6, 10, 14, 3, 5, 11, 13, 22, 9, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501e4171-0828-442e-99b1-3b9acbe8b476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
