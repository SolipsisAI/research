{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9140120d-0772-42e7-84f3-aff1359da025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c111c4-b582-463e-b7c0-0356ebab0d0a",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b398319f-9ede-4e96-b456-d3d84b9b512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df359e2-7028-4e7c-9c59-23c3fde30dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_labels = [\"dummy\", \"inform\", \"question\", \"directive\", \"commissive\"]\n",
    "emotion_labels = [\"no_emotion\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5df58cc-a1ac-4de2-a46e-b135aba6ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"daily_dialog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9361d3d3-5e5f-47a1-9ffd-9704621b73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4607242879e04cbca04405073e7ef20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd3c15add974c9fb0b2d04d62d6880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30398175186e42ea8ddcc6e3259f35d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, split_dataset in dataset.items():\n",
    "    split_dataset.to_csv(f\"daily_dialog-{split}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508309c8-c5f1-4bd5-a9ce-b8e8f90507bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"daily_dialog-train.csv\")\n",
    "df2 = pd.read_csv(\"daily_dialog-validation.csv\")\n",
    "df3 = pd.read_csv(\"daily_dialog-test.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "df1 = df2 = df3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "285027b7-63d7-4731-a7d5-60766e8c6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_cleaner import processing, Cleaner\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")\n",
    "cleaner = Cleaner( \n",
    "    model,\n",
    "    #processing.remove_stopword_token,\n",
    "    #processing.replace_punctuation_token,\n",
    "    processing.mutate_lemma_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a814688b-04e5-4971-8875-39684fa87c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dialog(dialog, remove_punctuation=True):\n",
    "    turns = dialog.replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace('\"', \"\").split(\"\\n\")\n",
    "    return turns\n",
    "\n",
    "def parse_label_numbers(label_numbers):\n",
    "    label_numbers = label_numbers.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")\n",
    "    return list(map(int, label_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "76c307df-f03f-4b88-991b-142848e384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    turns = parse_dialog(row[\"dialog\"])\n",
    "    act = parse_label_numbers(row[\"act\"])\n",
    "    emotion = parse_label_numbers(row[\"emotion\"])\n",
    "    for sequence, turn in enumerate(turns):\n",
    "        rows.append({\n",
    "            \"original_index\": i,\n",
    "            \"sequence\": sequence,\n",
    "            \"act_label\": act_labels[act[sequence]],\n",
    "            \"emotion_label\": emotion_labels[emotion[sequence]],\n",
    "            \"text\": turn\n",
    "        })\n",
    "\n",
    "turns_df = pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7c0c4aa2-a48a-439e-bf82-8613e44a36cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Havent you heard that he is in prison ?   What ? Beg your pardon . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Progress: 100%|██████████| 1/1 [00:00<00:00, 197.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['have not you hear that he be in prison ? what ? beg your pardon .']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = turns_df.iloc[190][\"text\"]\n",
    "print(text)\n",
    "cleaner.clean([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "772cbfa3-1bb9-4d49-b350-32e5ec95f8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Progress: 100%|██████████| 90010/90010 [01:32<00:00, 972.47it/s] \n"
     ]
    }
   ],
   "source": [
    "cleaned_texts = cleaner.clean(turns_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31d7961b-00fc-430d-82ba-7504884b51fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "turns_df[\"cleaned_text\"] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70d2a767-1e05-40e0-98da-0dd501131db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>sequence</th>\n",
       "      <th>act_label</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>directive</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>say , Jim , how about go for a few beer after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>commissive</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>You know that is tempting but is really not ...</td>\n",
       "      <td>you know that be tempting but be really not go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>question</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "      <td>what do you mean ? it will help we to relax .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>question</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>Do you really think so ? I dont . It will ju...</td>\n",
       "      <td>do you really think so ? I do not . it will ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>question</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>I guess you are right.But what shall we do ?...</td>\n",
       "      <td>I guess you be right . but what shall we do ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90005</th>\n",
       "      <td>999</td>\n",
       "      <td>7</td>\n",
       "      <td>question</td>\n",
       "      <td>surprise</td>\n",
       "      <td>are you kidding ? Can you afford it ? Do you...</td>\n",
       "      <td>be you kid ? can you afford it ? do you think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90006</th>\n",
       "      <td>999</td>\n",
       "      <td>8</td>\n",
       "      <td>directive</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>never mind that , Ill take care of it . Are ...</td>\n",
       "      <td>never mind that , Ill take care of it . be you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90007</th>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>commissive</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>yeah , I think so .</td>\n",
       "      <td>yeah , I think so .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90008</th>\n",
       "      <td>999</td>\n",
       "      <td>10</td>\n",
       "      <td>inform</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ok . Ill make the arrangements . It will be ...</td>\n",
       "      <td>ok . Ill make the arrangement . it will be gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90009</th>\n",
       "      <td>999</td>\n",
       "      <td>11</td>\n",
       "      <td>inform</td>\n",
       "      <td>happiness</td>\n",
       "      <td>wonderful ! Ill start packing our suitcases .</td>\n",
       "      <td>wonderful ! Ill start pack our suitcase .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90010 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       original_index  sequence   act_label emotion_label  \\\n",
       "0                   0         0   directive    no_emotion   \n",
       "1                   0         1  commissive    no_emotion   \n",
       "2                   0         2    question    no_emotion   \n",
       "3                   0         3    question    no_emotion   \n",
       "4                   0         4    question    no_emotion   \n",
       "...               ...       ...         ...           ...   \n",
       "90005             999         7    question      surprise   \n",
       "90006             999         8   directive    no_emotion   \n",
       "90007             999         9  commissive    no_emotion   \n",
       "90008             999        10      inform     happiness   \n",
       "90009             999        11      inform     happiness   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Say , Jim , how about going for a few beers af...   \n",
       "1        You know that is tempting but is really not ...   \n",
       "2         What do you mean ? It will help us to relax .    \n",
       "3        Do you really think so ? I dont . It will ju...   \n",
       "4        I guess you are right.But what shall we do ?...   \n",
       "...                                                  ...   \n",
       "90005    are you kidding ? Can you afford it ? Do you...   \n",
       "90006    never mind that , Ill take care of it . Are ...   \n",
       "90007                               yeah , I think so .    \n",
       "90008    ok . Ill make the arrangements . It will be ...   \n",
       "90009     wonderful ! Ill start packing our suitcases .    \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      say , Jim , how about go for a few beer after ...  \n",
       "1      you know that be tempting but be really not go...  \n",
       "2          what do you mean ? it will help we to relax .  \n",
       "3      do you really think so ? I do not . it will ju...  \n",
       "4      I guess you be right . but what shall we do ? ...  \n",
       "...                                                  ...  \n",
       "90005  be you kid ? can you afford it ? do you think ...  \n",
       "90006  never mind that , Ill take care of it . be you...  \n",
       "90007                                yeah , I think so .  \n",
       "90008  ok . Ill make the arrangement . it will be gre...  \n",
       "90009          wonderful ! Ill start pack our suitcase .  \n",
       "\n",
       "[90010 rows x 6 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc1b01-5cda-46ca-be18-51ec7513f243",
   "metadata": {},
   "source": [
    " # Prepare for Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ee46461-33f5-44dc-ac65-af7b1bdf5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = \"act\"\n",
    "\n",
    "classification = turns_df[[f\"{label_type}_label\", \"cleaned_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ebc94e3d-49a4-4cc8-b352-1bf61558b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1652978/2370742413.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  classification.rename({f\"{label_type}_label\": \"label\", \"cleaned_text\": \"text\"}, axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "classification.rename({f\"{label_type}_label\": \"label\", \"cleaned_text\": \"text\"}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92236c51-f26b-4b95-a580-e12cabacfacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classification[\"label\"].sort_values().drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "797aa83c-840d-4fe9-8b9e-57c13a367db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = labels_map = dict(list(zip(labels, labels.index)))\n",
    "id2label = dict((v,k) for k,v in labels_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "428674ed-49ab-4fe4-a275-1614bffab670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commissive': 0, 'directive': 1, 'inform': 2, 'question': 3}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5dce04c9-0cfd-4516-93db-d08941153f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1aefb961-6a13-4ac6-9a6e-836a542b45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2d9595b5-983f-4328-a71a-878d171060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fa054fd0-2561-4740-a1f9-5cd60159ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(classification, test_size=0.2)\n",
    "train_df[\"label\"].replace(labels_map, inplace=True)\n",
    "val_df[\"label\"].replace(labels_map, inplace=True)\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5fb0b172-a584-4813-9ea9-8709c1c50759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": val_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4e75587-a11a-472b-8402-39ec7bb124d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", num_labels=num_labels)\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "613df81c-a55b-461c-bab1-9e79620f6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = f\"../../models/distilroberta-daily_dialog-{label_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7854c98d-0995-4c4c-a91b-700e85abdcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8286d701-5854-45f1-a06c-bd1b4c88417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff065622-0547-45f4-b631-ee78c79bcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "932af9b7-6bb5-4ca4-a262-a044b5ac5496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7dd5aa4fac4d46a688c5dfb61fd6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72008 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bbd6d3226a44beaa99b6243b453e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d9160cd-38d8-44a3-b6e5-c81d7f938cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6007540-44c5-4119-bec8-bec1539bb6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18868' max='27003' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18868/27003 50:42 < 21:51, 6.20 it/s, Epoch 2.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.223400</td>\n",
       "      <td>1.236967</td>\n",
       "      <td>0.435229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.166100</td>\n",
       "      <td>1.166132</td>\n",
       "      <td>0.487612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# Optimizer step\u001b[39;00m\n\u001b[0;32m-> 2279\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2280\u001b[0m optimizer_was_run \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   2282\u001b[0m     \u001b[38;5;66;03m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/accelerate/optimizer.py:170\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py:379\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    378\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 379\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/profiler.py:622\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting():\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m--> 622\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_exit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RecordFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    624\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_exit(record)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_ops.py:591\u001b[0m, in \u001b[0;36mOpOverload.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<OpOverload(op=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, overload=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)>\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    588\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overloadname\n\u001b[1;32m    589\u001b[0m     )\n\u001b[0;32m--> 591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;66;03m# are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_op(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6631c-d1a4-4bce-b92a-4a32f90c378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62d8b7-8573-491a-9588-ea7e27323552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=output_dir, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e84baa-c39d-4dc8-b962-f1cc94da3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.config.id2label = id2label\n",
    "classifier.model.config.label2id = labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970d469-73c4-419c-930a-0521db362819",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b932a2-f195-416f-bf75-e6253beaabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=output_dir, return_all_scores=True)\n",
    "classifier.model.config.id2label = id2label\n",
    "classifier.model.config.label2id = label2id\n",
    "\n",
    "def classify(text):\n",
    "    results = classifier(text)\n",
    "    max_score = max(results[0], key=lambda x:x[\"score\"])\n",
    "    return max_score[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a034e87-9bea-4a0f-988d-f077ba06c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"What's going on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fd77c-651d-4b88-b2db-3cf569defce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"I don't think so.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db6427-532e-4048-aa71-0521d6f6e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"You think so? I don't know, really.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50209c-42b7-4daf-9101-dffbb70fd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do as I say.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58151f42-a00b-4f3e-b81e-37ca8b4485ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Tell that guy to shut up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36359c-92b4-491b-8bbb-8424e8c8c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"I'm sick of seeing you here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d84769-9639-4882-9376-27c45763a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Take the book and read it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d76a40-f2cd-4690-bb4a-9c92f4392438",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do you think it's okay?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a8ead-d123-4efa-9be8-9a789d44589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"It's tempting but it's not good for our fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006185d-e0b4-4777-ac61-11d6bc2517d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Sometimes I think life is not worth living.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0314107-7297-4fa5-bfe5-55f48ca7b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Find another person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7fa38-0c99-4097-9bc9-b9521646d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Re-train on this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49a74f-98dc-4024-9bfe-530b3b5a3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4f13d-2135-49ca-9d40-e925c67b470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Get this from google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa966d-ce9d-4c96-b070-9c36830ad8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('why not go again to celebrate out one-year anniversary ? We can go to the same beach , stay in the same hotel and enjoy a dinner in the same restaurant .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88013f-ff11-4fe0-befd-f965131b8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Why bother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e6a43-5ea7-4d16-b600-e78d7aa94602",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Who's the author of this article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82db99-af37-4357-9c02-7a02b55b2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Where was this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cebfc6-4301-4f6d-83b9-b3057e048dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
