{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9140120d-0772-42e7-84f3-aff1359da025",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c111c4-b582-463e-b7c0-0356ebab0d0a",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b398319f-9ede-4e96-b456-d3d84b9b512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df359e2-7028-4e7c-9c59-23c3fde30dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_labels = [\"dummy\", \"inform\", \"question\", \"directive\", \"commissive\"]\n",
    "emotion_labels = [\"no_emotion\", \"anger\", \"disgust\", \"fear\", \"happiness\", \"sadness\", \"surprise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5df58cc-a1ac-4de2-a46e-b135aba6ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"daily_dialog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9361d3d3-5e5f-47a1-9ffd-9704621b73a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4607242879e04cbca04405073e7ef20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd3c15add974c9fb0b2d04d62d6880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30398175186e42ea8ddcc6e3259f35d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, split_dataset in dataset.items():\n",
    "    split_dataset.to_csv(f\"daily_dialog-{split}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508309c8-c5f1-4bd5-a9ce-b8e8f90507bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"daily_dialog-train.csv\")\n",
    "df2 = pd.read_csv(\"daily_dialog-validation.csv\")\n",
    "df3 = pd.read_csv(\"daily_dialog-test.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "df1 = df2 = df3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285027b7-63d7-4731-a7d5-60766e8c6277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_cleaner import processing, Cleaner\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")\n",
    "cleaner = Cleaner( \n",
    "    model,\n",
    "    processing.remove_stopword_token,\n",
    "    processing.replace_punctuation_token,\n",
    "    processing.mutate_lemma_token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a814688b-04e5-4971-8875-39684fa87c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dialog(dialog, remove_punctuation=True):\n",
    "    turns = dialog.replace(\"\\'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace('\"', \"\").split(\"\\n\")\n",
    "    return turns\n",
    "\n",
    "def parse_label_numbers(label_numbers):\n",
    "    label_numbers = label_numbers.replace(\"[\", \"\").replace(\"]\", \"\").split(\" \")\n",
    "    return list(map(int, label_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76c307df-f03f-4b88-991b-142848e384f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    turns = parse_dialog(row[\"dialog\"])\n",
    "    act = parse_label_numbers(row[\"act\"])\n",
    "    emotion = parse_label_numbers(row[\"emotion\"])\n",
    "    for sequence, turn in enumerate(turns):\n",
    "        rows.append({\n",
    "            \"original_index\": i,\n",
    "            \"sequence\": sequence,\n",
    "            \"act_label\": act_labels[act[sequence]],\n",
    "            \"emotion_label\": emotion_labels[emotion[sequence]],\n",
    "            \"text\": turn\n",
    "        })\n",
    "\n",
    "turns_df = pd.DataFrame.from_records(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "772cbfa3-1bb9-4d49-b350-32e5ec95f8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Progress: 100%|██████████| 90010/90010 [01:34<00:00, 954.38it/s] \n"
     ]
    }
   ],
   "source": [
    "cleaned_texts = cleaner.clean(turns_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31d7961b-00fc-430d-82ba-7504884b51fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "      <th>turns</th>\n",
       "      <th>act_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Say , Jim , how about going for a few beers a...</td>\n",
       "      <td>[3 4 2 2 2 3 4 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 0 4 4 4 4]</td>\n",
       "      <td>[directive|no_emotion Say , Jim , how about go...</td>\n",
       "      <td>[directive, commissive, question, question, qu...</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Can you do push-ups ?, Of course I can . Its ...</td>\n",
       "      <td>[2 1 2 2 1 1]</td>\n",
       "      <td>[0 0 6 0 0 0]</td>\n",
       "      <td>[question|no_emotion Can you do push-ups ?, in...</td>\n",
       "      <td>[question, inform, question, question, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, surprise, no_emotion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Can you study with the radio on ?, No , I lis...</td>\n",
       "      <td>[2 1 2 1 1]</td>\n",
       "      <td>[0 0 0 0 0]</td>\n",
       "      <td>[question|no_emotion Can you study with the ra...</td>\n",
       "      <td>[question, inform, question, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Are you all right ?, I will be all right soon...</td>\n",
       "      <td>[2 1 1 1]</td>\n",
       "      <td>[0 0 0 0]</td>\n",
       "      <td>[question|no_emotion Are you all right ?, info...</td>\n",
       "      <td>[question, inform, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hey John , nice skates . Are they new ?, Yeah...</td>\n",
       "      <td>[2 1 2 1 1 2 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 6 0 6 0]</td>\n",
       "      <td>[question|no_emotion Hey John , nice skates . ...</td>\n",
       "      <td>[question, inform, question, inform, inform, q...</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13113</th>\n",
       "      <td>[Frank ’ s getting married , do you believe th...</td>\n",
       "      <td>[2 2 1 2 1 2 1]</td>\n",
       "      <td>[0 6 0 0 0 0 0]</td>\n",
       "      <td>[question|no_emotion Frank ’ s getting married...</td>\n",
       "      <td>[question, question, inform, question]</td>\n",
       "      <td>[no_emotion, surprise, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>[OK . Come back into the classroom , class ., ...</td>\n",
       "      <td>[1 2 1 1 1 2 1]</td>\n",
       "      <td>[0 0 0 5 0 0 0]</td>\n",
       "      <td>[inform|no_emotion OK . Come back into the cla...</td>\n",
       "      <td>[inform, question, inform, inform, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, sadness, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13115</th>\n",
       "      <td>[Do you have any hobbies ?   Yes , I like coll...</td>\n",
       "      <td>[2 1 2 1 2 1 1]</td>\n",
       "      <td>[0 4 4 0 6 0 0]</td>\n",
       "      <td>[question|no_emotion Do you have any hobbies ?...</td>\n",
       "      <td>[question, inform, question, inform, question]</td>\n",
       "      <td>[no_emotion, happiness, happiness, no_emotion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13116</th>\n",
       "      <td>[Jenny , whats wrong with you ? Why do you kee...</td>\n",
       "      <td>[2 1 1]</td>\n",
       "      <td>[0 0 0]</td>\n",
       "      <td>[question|no_emotion Jenny , whats wrong with ...</td>\n",
       "      <td>[question, inform, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13117</th>\n",
       "      <td>[What a nice day !, yes . How about going out ...</td>\n",
       "      <td>[1 3 4 1 1 1 3 2 3 4 1 1]</td>\n",
       "      <td>[4 0 4 4 4 0 0 6 0 0 4 4]</td>\n",
       "      <td>[inform|happiness What a nice day !, directive...</td>\n",
       "      <td>[inform, directive, commissive, inform, inform...</td>\n",
       "      <td>[happiness, no_emotion, happiness, happiness, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13118 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  dialog  \\\n",
       "0      [Say , Jim , how about going for a few beers a...   \n",
       "1      [Can you do push-ups ?, Of course I can . Its ...   \n",
       "2      [Can you study with the radio on ?, No , I lis...   \n",
       "3      [Are you all right ?, I will be all right soon...   \n",
       "4      [Hey John , nice skates . Are they new ?, Yeah...   \n",
       "...                                                  ...   \n",
       "13113  [Frank ’ s getting married , do you believe th...   \n",
       "13114  [OK . Come back into the classroom , class ., ...   \n",
       "13115  [Do you have any hobbies ?   Yes , I like coll...   \n",
       "13116  [Jenny , whats wrong with you ? Why do you kee...   \n",
       "13117  [What a nice day !, yes . How about going out ...   \n",
       "\n",
       "                             act                    emotion  \\\n",
       "0          [3 4 2 2 2 3 4 1 3 4]      [0 0 0 0 0 0 4 4 4 4]   \n",
       "1                  [2 1 2 2 1 1]              [0 0 6 0 0 0]   \n",
       "2                    [2 1 2 1 1]                [0 0 0 0 0]   \n",
       "3                      [2 1 1 1]                  [0 0 0 0]   \n",
       "4            [2 1 2 1 1 2 1 3 4]        [0 0 0 0 0 6 0 6 0]   \n",
       "...                          ...                        ...   \n",
       "13113            [2 2 1 2 1 2 1]            [0 6 0 0 0 0 0]   \n",
       "13114            [1 2 1 1 1 2 1]            [0 0 0 5 0 0 0]   \n",
       "13115            [2 1 2 1 2 1 1]            [0 4 4 0 6 0 0]   \n",
       "13116                    [2 1 1]                    [0 0 0]   \n",
       "13117  [1 3 4 1 1 1 3 2 3 4 1 1]  [4 0 4 4 4 0 0 6 0 0 4 4]   \n",
       "\n",
       "                                                   turns  \\\n",
       "0      [directive|no_emotion Say , Jim , how about go...   \n",
       "1      [question|no_emotion Can you do push-ups ?, in...   \n",
       "2      [question|no_emotion Can you study with the ra...   \n",
       "3      [question|no_emotion Are you all right ?, info...   \n",
       "4      [question|no_emotion Hey John , nice skates . ...   \n",
       "...                                                  ...   \n",
       "13113  [question|no_emotion Frank ’ s getting married...   \n",
       "13114  [inform|no_emotion OK . Come back into the cla...   \n",
       "13115  [question|no_emotion Do you have any hobbies ?...   \n",
       "13116  [question|no_emotion Jenny , whats wrong with ...   \n",
       "13117  [inform|happiness What a nice day !, directive...   \n",
       "\n",
       "                                               act_label  \\\n",
       "0      [directive, commissive, question, question, qu...   \n",
       "1         [question, inform, question, question, inform]   \n",
       "2                   [question, inform, question, inform]   \n",
       "3                             [question, inform, inform]   \n",
       "4      [question, inform, question, inform, inform, q...   \n",
       "...                                                  ...   \n",
       "13113             [question, question, inform, question]   \n",
       "13114         [inform, question, inform, inform, inform]   \n",
       "13115     [question, inform, question, inform, question]   \n",
       "13116                         [question, inform, inform]   \n",
       "13117  [inform, directive, commissive, inform, inform...   \n",
       "\n",
       "                                           emotion_label  \n",
       "0      [no_emotion, no_emotion, no_emotion, no_emotio...  \n",
       "1      [no_emotion, no_emotion, surprise, no_emotion,...  \n",
       "2       [no_emotion, no_emotion, no_emotion, no_emotion]  \n",
       "3                   [no_emotion, no_emotion, no_emotion]  \n",
       "4      [no_emotion, no_emotion, no_emotion, no_emotio...  \n",
       "...                                                  ...  \n",
       "13113     [no_emotion, surprise, no_emotion, no_emotion]  \n",
       "13114  [no_emotion, no_emotion, no_emotion, sadness, ...  \n",
       "13115  [no_emotion, happiness, happiness, no_emotion,...  \n",
       "13116               [no_emotion, no_emotion, no_emotion]  \n",
       "13117  [happiness, no_emotion, happiness, happiness, ...  \n",
       "\n",
       "[13118 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turns_df[\"cleaned_text\"] = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d2a767-1e05-40e0-98da-0dd501131db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>act</th>\n",
       "      <th>emotion</th>\n",
       "      <th>turns</th>\n",
       "      <th>act_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Say , Jim , how about going for a few beers a...</td>\n",
       "      <td>[3 4 2 2 2 3 4 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 0 4 4 4 4]</td>\n",
       "      <td>[directive|no_emotion Say , Jim , how about go...</td>\n",
       "      <td>[directive, commissive, question, question, qu...</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Can you do push-ups ?, Of course I can . Its ...</td>\n",
       "      <td>[2 1 2 2 1 1]</td>\n",
       "      <td>[0 0 6 0 0 0]</td>\n",
       "      <td>[question|no_emotion Can you do push-ups ?, in...</td>\n",
       "      <td>[question, inform, question, question, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, surprise, no_emotion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Can you study with the radio on ?, No , I lis...</td>\n",
       "      <td>[2 1 2 1 1]</td>\n",
       "      <td>[0 0 0 0 0]</td>\n",
       "      <td>[question|no_emotion Can you study with the ra...</td>\n",
       "      <td>[question, inform, question, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Are you all right ?, I will be all right soon...</td>\n",
       "      <td>[2 1 1 1]</td>\n",
       "      <td>[0 0 0 0]</td>\n",
       "      <td>[question|no_emotion Are you all right ?, info...</td>\n",
       "      <td>[question, inform, inform]</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Hey John , nice skates . Are they new ?, Yeah...</td>\n",
       "      <td>[2 1 2 1 1 2 1 3 4]</td>\n",
       "      <td>[0 0 0 0 0 6 0 6 0]</td>\n",
       "      <td>[question|no_emotion Hey John , nice skates . ...</td>\n",
       "      <td>[question, inform, question, inform, inform, q...</td>\n",
       "      <td>[no_emotion, no_emotion, no_emotion, no_emotio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialog                    act  \\\n",
       "0  [Say , Jim , how about going for a few beers a...  [3 4 2 2 2 3 4 1 3 4]   \n",
       "1  [Can you do push-ups ?, Of course I can . Its ...          [2 1 2 2 1 1]   \n",
       "2  [Can you study with the radio on ?, No , I lis...            [2 1 2 1 1]   \n",
       "3  [Are you all right ?, I will be all right soon...              [2 1 1 1]   \n",
       "4  [Hey John , nice skates . Are they new ?, Yeah...    [2 1 2 1 1 2 1 3 4]   \n",
       "\n",
       "                 emotion                                              turns  \\\n",
       "0  [0 0 0 0 0 0 4 4 4 4]  [directive|no_emotion Say , Jim , how about go...   \n",
       "1          [0 0 6 0 0 0]  [question|no_emotion Can you do push-ups ?, in...   \n",
       "2            [0 0 0 0 0]  [question|no_emotion Can you study with the ra...   \n",
       "3              [0 0 0 0]  [question|no_emotion Are you all right ?, info...   \n",
       "4    [0 0 0 0 0 6 0 6 0]  [question|no_emotion Hey John , nice skates . ...   \n",
       "\n",
       "                                           act_label  \\\n",
       "0  [directive, commissive, question, question, qu...   \n",
       "1     [question, inform, question, question, inform]   \n",
       "2               [question, inform, question, inform]   \n",
       "3                         [question, inform, inform]   \n",
       "4  [question, inform, question, inform, inform, q...   \n",
       "\n",
       "                                       emotion_label  \n",
       "0  [no_emotion, no_emotion, no_emotion, no_emotio...  \n",
       "1  [no_emotion, no_emotion, surprise, no_emotion,...  \n",
       "2   [no_emotion, no_emotion, no_emotion, no_emotion]  \n",
       "3               [no_emotion, no_emotion, no_emotion]  \n",
       "4  [no_emotion, no_emotion, no_emotion, no_emotio...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ac5779-b83b-46d4-813f-5d6d2179d3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Say , Jim , how about going for a few beers after dinner ?',\n",
       " 'You know that is tempting but is really not good for our fitness .',\n",
       " 'What do you mean ? It will help us to relax .',\n",
       " 'Do you really think so ? I dont . It will just make us fat and act silly . Remember last time ?',\n",
       " 'I guess you are right.But what shall we do ? I dont feel like sitting at home .',\n",
       " 'I suggest a walk over to the gym where we can play singsong and meet some of our friends .',\n",
       " 'Thats a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .',\n",
       " 'Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .',\n",
       " 'Good.Let  s go now .   All right .']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.iloc[0][\"dialog\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfc1b01-5cda-46ca-be18-51ec7513f243",
   "metadata": {},
   "source": [
    " # Prepare for Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ee46461-33f5-44dc-ac65-af7b1bdf5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(act_label, emotion_label, label_type):\n",
    "    if label_type == \"act\":\n",
    "        return act_label\n",
    "    elif label_type == \"emotion\":\n",
    "        return emotion_label\n",
    "    else:\n",
    "        return f\"{act_label}|{emotion_label}\"\n",
    "\n",
    "label_type = \"combo\"\n",
    "\n",
    "examples = []\n",
    "\n",
    "for row_index, row in new_df.iterrows():\n",
    "    for dialog_index, utterance in enumerate(row[\"dialog\"]):\n",
    "        example = {}\n",
    "        act_label = row[\"act_label\"][dialog_index]\n",
    "        emotion_label = row[\"emotion_label\"][dialog_index]\n",
    "        # example[\"label\"] = f\"{act_label}|{emotion_label}\"\n",
    "        example[\"label\"] = get_label(act_label, emotion_label, label_type)\n",
    "        example[\"text\"] = utterance\n",
    "        examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d555c2a-5fbe-4181-bd5f-52228a903bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.DataFrame.from_records(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebc94e3d-49a4-4cc8-b352-1bf61558b85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>directive|no_emotion</td>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>commissive|no_emotion</td>\n",
       "      <td>You know that is tempting but is really not go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>question|no_emotion</td>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question|no_emotion</td>\n",
       "      <td>Do you really think so ? I dont . It will just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>question|no_emotion</td>\n",
       "      <td>I guess you are right.But what shall we do ? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90005</th>\n",
       "      <td>question|surprise</td>\n",
       "      <td>are you kidding ? Can you afford it ? Do you t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90006</th>\n",
       "      <td>directive|no_emotion</td>\n",
       "      <td>never mind that , Ill take care of it . Are yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90007</th>\n",
       "      <td>commissive|no_emotion</td>\n",
       "      <td>yeah , I think so .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90008</th>\n",
       "      <td>inform|happiness</td>\n",
       "      <td>ok . Ill make the arrangements . It will be gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90009</th>\n",
       "      <td>inform|happiness</td>\n",
       "      <td>wonderful ! Ill start packing our suitcases .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label  \\\n",
       "0       directive|no_emotion   \n",
       "1      commissive|no_emotion   \n",
       "2        question|no_emotion   \n",
       "3        question|no_emotion   \n",
       "4        question|no_emotion   \n",
       "...                      ...   \n",
       "90005      question|surprise   \n",
       "90006   directive|no_emotion   \n",
       "90007  commissive|no_emotion   \n",
       "90008       inform|happiness   \n",
       "90009       inform|happiness   \n",
       "\n",
       "                                                    text  \n",
       "0      Say , Jim , how about going for a few beers af...  \n",
       "1      You know that is tempting but is really not go...  \n",
       "2          What do you mean ? It will help us to relax .  \n",
       "3      Do you really think so ? I dont . It will just...  \n",
       "4      I guess you are right.But what shall we do ? I...  \n",
       "...                                                  ...  \n",
       "90005  are you kidding ? Can you afford it ? Do you t...  \n",
       "90006  never mind that , Ill take care of it . Are yo...  \n",
       "90007                                yeah , I think so .  \n",
       "90008  ok . Ill make the arrangements . It will be gr...  \n",
       "90009      wonderful ! Ill start packing our suitcases .  \n",
       "\n",
       "[90010 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35bc8694-21a8-40a7-a491-927ebf9913f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = classification[[\"label\"]].sort_values(\"label\").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "797aa83c-840d-4fe9-8b9e-57c13a367db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = labels_map = dict(list(zip(labels.label, labels.index)))\n",
    "id2label = dict((v,k) for k,v in labels_map.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "428674ed-49ab-4fe4-a275-1614bffab670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commissive|anger': 0,\n",
       " 'commissive|disgust': 1,\n",
       " 'commissive|fear': 2,\n",
       " 'commissive|happiness': 3,\n",
       " 'commissive|no_emotion': 4,\n",
       " 'commissive|sadness': 5,\n",
       " 'commissive|surprise': 6,\n",
       " 'directive|anger': 7,\n",
       " 'directive|disgust': 8,\n",
       " 'directive|fear': 9,\n",
       " 'directive|happiness': 10,\n",
       " 'directive|no_emotion': 11,\n",
       " 'directive|sadness': 12,\n",
       " 'directive|surprise': 13,\n",
       " 'inform|anger': 14,\n",
       " 'inform|disgust': 15,\n",
       " 'inform|fear': 16,\n",
       " 'inform|happiness': 17,\n",
       " 'inform|no_emotion': 18,\n",
       " 'inform|sadness': 19,\n",
       " 'inform|surprise': 20,\n",
       " 'question|anger': 21,\n",
       " 'question|disgust': 22,\n",
       " 'question|fear': 23,\n",
       " 'question|happiness': 24,\n",
       " 'question|no_emotion': 25,\n",
       " 'question|sadness': 26,\n",
       " 'question|surprise': 27}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dce04c9-0cfd-4516-93db-d08941153f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aefb961-6a13-4ac6-9a6e-836a542b45ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d9595b5-983f-4328-a71a-878d171060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa054fd0-2561-4740-a1f9-5cd60159ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(classification, test_size=0.2)\n",
    "train_df[\"label\"].replace(labels_map, inplace=True)\n",
    "val_df[\"label\"].replace(labels_map, inplace=True)\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fb0b172-a584-4813-9ea9-8709c1c50759",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\"train\": train_dataset, \"test\": val_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4e75587-a11a-472b-8402-39ec7bb124d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", num_labels=num_labels)\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "613df81c-a55b-461c-bab1-9e79620f6d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "output_dir = f\"../../models/distilroberta-daily_dialog-{label_type}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7854c98d-0995-4c4c-a91b-700e85abdcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1051188/2607597888.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "/opt/conda/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8286d701-5854-45f1-a06c-bd1b4c88417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff065622-0547-45f4-b631-ee78c79bcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "932af9b7-6bb5-4ca4-a262-a044b5ac5496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5509295a30384b4baf4be3fbb5530ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72008 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef638c23fa42039f6f8fc20e0864db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18002 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)\n",
    "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d9160cd-38d8-44a3-b6e5-c81d7f938cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6007540-44c5-4119-bec8-bec1539bb6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43267' max='54006' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43267/54006 1:52:49 < 28:00, 6.39 it/s, Epoch 4.81/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.368300</td>\n",
       "      <td>1.344033</td>\n",
       "      <td>0.565604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.274700</td>\n",
       "      <td>1.339678</td>\n",
       "      <td>0.577380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.170700</td>\n",
       "      <td>1.312579</td>\n",
       "      <td>0.579158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.048400</td>\n",
       "      <td>1.364442</td>\n",
       "      <td>0.568270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6631c-d1a4-4bce-b92a-4a32f90c378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62d8b7-8573-491a-9588-ea7e27323552",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=output_dir, return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e84baa-c39d-4dc8-b962-f1cc94da3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.config.id2label = id2label\n",
    "classifier.model.config.label2id = labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970d469-73c4-419c-930a-0521db362819",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b932a2-f195-416f-bf75-e6253beaabfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=output_dir, return_all_scores=True)\n",
    "classifier.model.config.id2label = id2label\n",
    "classifier.model.config.label2id = label2id\n",
    "\n",
    "def classify(text):\n",
    "    results = classifier(text)\n",
    "    max_score = max(results[0], key=lambda x:x[\"score\"])\n",
    "    return max_score[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a034e87-9bea-4a0f-988d-f077ba06c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"What's going on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33fd77c-651d-4b88-b2db-3cf569defce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"I don't think so.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db6427-532e-4048-aa71-0521d6f6e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"You think so? I don't know, really.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50209c-42b7-4daf-9101-dffbb70fd02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do as I say.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58151f42-a00b-4f3e-b81e-37ca8b4485ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Tell that guy to shut up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36359c-92b4-491b-8bbb-8424e8c8c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"I'm sick of seeing you here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d84769-9639-4882-9376-27c45763a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Take the book and read it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d76a40-f2cd-4690-bb4a-9c92f4392438",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do you think it's okay?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a8ead-d123-4efa-9be8-9a789d44589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"It's tempting but it's not good for our fitness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006185d-e0b4-4777-ac61-11d6bc2517d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Sometimes I think life is not worth living.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0314107-7297-4fa5-bfe5-55f48ca7b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Find another person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7fa38-0c99-4097-9bc9-b9521646d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Re-train on this dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49a74f-98dc-4024-9bfe-530b3b5a3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Do this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4f13d-2135-49ca-9d40-e925c67b470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Get this from google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa966d-ce9d-4c96-b070-9c36830ad8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify('why not go again to celebrate out one-year anniversary ? We can go to the same beach , stay in the same hotel and enjoy a dinner in the same restaurant .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88013f-ff11-4fe0-befd-f965131b8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Why bother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e6a43-5ea7-4d16-b600-e78d7aa94602",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Who's the author of this article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82db99-af37-4357-9c02-7a02b55b2de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"Where was this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cebfc6-4301-4f6d-83b9-b3057e048dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
