{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19be9dc6-9ab1-4cb2-b75c-742db3ee929f",
   "metadata": {},
   "source": [
    "https://discuss.huggingface.co/t/gpt-2-trained-models-output-repeated/12962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d822b1ea-868c-43f1-a471-63fd54782d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c9fe99-f10b-4aaa-8f43-c1eebd4bbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import main\n",
    "from src.utils import prepare_data\n",
    "\n",
    "data_filepath = \"../../data/processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1537f8-f29b-4266-b75a-e2814df31574",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df, val_df = prepare_data(data_filepath, filter_args={\"key\": \"character\", \"value\": \"bitjockey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdee8151-0270-4b2c-a817-ee679d4ce884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>[_puts head in hands_]</td>\n",
       "      <td>[_nods_]</td>\n",
       "      <td>Nothing specific. Just...pay attention to her ...</td>\n",
       "      <td>Do you have any advice?</td>\n",
       "      <td>Not likely to take it well.</td>\n",
       "      <td>Right.</td>\n",
       "      <td>Yeah...we don't want to give Nix the idea that...</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>[_narrows eyes_] I see.</td>\n",
       "      <td>[_shrugs_] It's mostly just s-supporting codeb...</td>\n",
       "      <td>_Interesting_...and what industry would that be?</td>\n",
       "      <td>Sango Dynamics</td>\n",
       "      <td>Okay...what company?</td>\n",
       "      <td>I'm...just a programmer. Not...not even for on...</td>\n",
       "      <td>[_to Thea_] Thatâ€™s alright. Itâ€™s understandabl...</td>\n",
       "      <td>[_small yelp_] Y-yes. Sorry. I-I get nervous, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>[_texts_] What I meant was that I agree. We sh...</td>\n",
       "      <td>[*under her breath*] hopper what the fuck\\n[*t...</td>\n",
       "      <td>[_texts_] ok</td>\n",
       "      <td>[I defer to your opinion, Charlotte. This face...</td>\n",
       "      <td>[*texts*]...We should add that we want any inf...</td>\n",
       "      <td>[*texts*] And we need to figure out _exactly_ ...</td>\n",
       "      <td>[*texts*] OK but if we rush this he might turn...</td>\n",
       "      <td>[_texts_] we should do this asap. we don't hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Yeah</td>\n",
       "      <td>((maximum awkward))</td>\n",
       "      <td>_is still standing_</td>\n",
       "      <td>((is hopper still standing? bc charlotte is si...</td>\n",
       "      <td>...Are you doing okay?</td>\n",
       "      <td>(( ðŸ˜‚ ))</td>\n",
       "      <td>_awkwardly pats Charlotte on the back_</td>\n",
       "      <td>(( this is the most awkward thing ever lol ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>(( â€œI have found that the way of the samurai i...</td>\n",
       "      <td>[_A lot of the annotation are comments or ques...</td>\n",
       "      <td>[_The annotation is in kanji. The handwriting ...</td>\n",
       "      <td>[_Picks out the Japanese edition of Hagakure_]</td>\n",
       "      <td>[_Thea is still in the library. She's engrosse...</td>\n",
       "      <td>Thanks. Uhm. Good talk. [_nods at both of them...</td>\n",
       "      <td>Library.</td>\n",
       "      <td>Hmm. Is there a copy around?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841</th>\n",
       "      <td>[_fidgets_]</td>\n",
       "      <td>[_sighs_] Alright. Fine.</td>\n",
       "      <td>...Alex.</td>\n",
       "      <td>[_shakes head_] It's nothing.</td>\n",
       "      <td>What has been?</td>\n",
       "      <td>[_softly_] It's just been so hard.</td>\n",
       "      <td>...what is it?</td>\n",
       "      <td>[_puts head in hands_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4908</th>\n",
       "      <td>Well it's one hell of a coincidence his sprite...</td>\n",
       "      <td>So...what are we at? He's worse at social inte...</td>\n",
       "      <td>No kidding? He messaged somebody, she showed u...</td>\n",
       "      <td>He knew her by *name*.\\n*Kalahan growls that l...</td>\n",
       "      <td>Yeah, which is _fucked_.</td>\n",
       "      <td>*Kalahan doesn't stop pacing, but he mutters j...</td>\n",
       "      <td>Like I said. Doesn't make _sense_</td>\n",
       "      <td>He seemed surprised that another technomancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>[_texts_] well theyre not going after _me_...b...</td>\n",
       "      <td>the universe is insulting me</td>\n",
       "      <td>[_texts_] yeah..</td>\n",
       "      <td>r u serious? AFTER i wiped your data????</td>\n",
       "      <td>[_texts_] where 2 begin. Short version: we r d...</td>\n",
       "      <td>crazy with you is always entertaining for me</td>\n",
       "      <td>sure</td>\n",
       "      <td>[_texts_] do u want an update on my life bcuz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>They take some time to work</td>\n",
       "      <td>....I  thought the meds were helping?</td>\n",
       "      <td>[_softly again_] I was going to go somewhere a...</td>\n",
       "      <td>[*isn't sure what to say*]</td>\n",
       "      <td>(( ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚))</td>\n",
       "      <td>((I think you accidentally a word))</td>\n",
       "      <td>[_sighs_] because you had your reasons. And be...</td>\n",
       "      <td>...How are you not? Medusa _broke into your ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>[_goes back out, and knocks on Julia and Akari...</td>\n",
       "      <td>[_waves back, heads into her Not Sad Apartment_]</td>\n",
       "      <td>Later, Hopper. [_waves_]</td>\n",
       "      <td>Yes, we're going to go get you food now.</td>\n",
       "      <td>_bark?_</td>\n",
       "      <td>[_smiles_] We could all use it, I think. I'll....</td>\n",
       "      <td>I should...let you get your stuff packed away....</td>\n",
       "      <td>[_nods_]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               response  \\\n",
       "3837                             [_puts head in hands_]   \n",
       "1626                            [_narrows eyes_] I see.   \n",
       "4094  [_texts_] What I meant was that I agree. We sh...   \n",
       "287                                                Yeah   \n",
       "1727  (( â€œI have found that the way of the samurai i...   \n",
       "3841                                        [_fidgets_]   \n",
       "4908  Well it's one hell of a coincidence his sprite...   \n",
       "2452  [_texts_] well theyre not going after _me_...b...   \n",
       "868                         They take some time to work   \n",
       "2261  [_goes back out, and knocks on Julia and Akari...   \n",
       "\n",
       "                                                context  \\\n",
       "3837                                           [_nods_]   \n",
       "1626  [_shrugs_] It's mostly just s-supporting codeb...   \n",
       "4094  [*under her breath*] hopper what the fuck\\n[*t...   \n",
       "287                                 ((maximum awkward))   \n",
       "1727  [_A lot of the annotation are comments or ques...   \n",
       "3841                           [_sighs_] Alright. Fine.   \n",
       "4908  So...what are we at? He's worse at social inte...   \n",
       "2452                       the universe is insulting me   \n",
       "868               ....I  thought the meds were helping?   \n",
       "2261   [_waves back, heads into her Not Sad Apartment_]   \n",
       "\n",
       "                                              context/0  \\\n",
       "3837  Nothing specific. Just...pay attention to her ...   \n",
       "1626   _Interesting_...and what industry would that be?   \n",
       "4094                                       [_texts_] ok   \n",
       "287                                 _is still standing_   \n",
       "1727  [_The annotation is in kanji. The handwriting ...   \n",
       "3841                                           ...Alex.   \n",
       "4908  No kidding? He messaged somebody, she showed u...   \n",
       "2452                                   [_texts_] yeah..   \n",
       "868   [_softly again_] I was going to go somewhere a...   \n",
       "2261                           Later, Hopper. [_waves_]   \n",
       "\n",
       "                                              context/1  \\\n",
       "3837                            Do you have any advice?   \n",
       "1626                                     Sango Dynamics   \n",
       "4094  [I defer to your opinion, Charlotte. This face...   \n",
       "287   ((is hopper still standing? bc charlotte is si...   \n",
       "1727     [_Picks out the Japanese edition of Hagakure_]   \n",
       "3841                      [_shakes head_] It's nothing.   \n",
       "4908  He knew her by *name*.\\n*Kalahan growls that l...   \n",
       "2452           r u serious? AFTER i wiped your data????   \n",
       "868                          [*isn't sure what to say*]   \n",
       "2261           Yes, we're going to go get you food now.   \n",
       "\n",
       "                                              context/2  \\\n",
       "3837                        Not likely to take it well.   \n",
       "1626                               Okay...what company?   \n",
       "4094  [*texts*]...We should add that we want any inf...   \n",
       "287                              ...Are you doing okay?   \n",
       "1727  [_Thea is still in the library. She's engrosse...   \n",
       "3841                                     What has been?   \n",
       "4908                           Yeah, which is _fucked_.   \n",
       "2452  [_texts_] where 2 begin. Short version: we r d...   \n",
       "868                                           (( ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚))   \n",
       "2261                                            _bark?_   \n",
       "\n",
       "                                              context/3  \\\n",
       "3837                                             Right.   \n",
       "1626  I'm...just a programmer. Not...not even for on...   \n",
       "4094  [*texts*] And we need to figure out _exactly_ ...   \n",
       "287                                             (( ðŸ˜‚ ))   \n",
       "1727  Thanks. Uhm. Good talk. [_nods at both of them...   \n",
       "3841                 [_softly_] It's just been so hard.   \n",
       "4908  *Kalahan doesn't stop pacing, but he mutters j...   \n",
       "2452       crazy with you is always entertaining for me   \n",
       "868                 ((I think you accidentally a word))   \n",
       "2261  [_smiles_] We could all use it, I think. I'll....   \n",
       "\n",
       "                                              context/4  \\\n",
       "3837  Yeah...we don't want to give Nix the idea that...   \n",
       "1626  [_to Thea_] Thatâ€™s alright. Itâ€™s understandabl...   \n",
       "4094  [*texts*] OK but if we rush this he might turn...   \n",
       "287              _awkwardly pats Charlotte on the back_   \n",
       "1727                                           Library.   \n",
       "3841                                     ...what is it?   \n",
       "4908                  Like I said. Doesn't make _sense_   \n",
       "2452                                               sure   \n",
       "868   [_sighs_] because you had your reasons. And be...   \n",
       "2261  I should...let you get your stuff packed away....   \n",
       "\n",
       "                                              context/5  \n",
       "3837                                          Thank you  \n",
       "1626  [_small yelp_] Y-yes. Sorry. I-I get nervous, ...  \n",
       "4094  [_texts_] we should do this asap. we don't hav...  \n",
       "287       (( this is the most awkward thing ever lol ))  \n",
       "1727                       Hmm. Is there a copy around?  \n",
       "3841                             [_puts head in hands_]  \n",
       "4908  He seemed surprised that another technomancer ...  \n",
       "2452  [_texts_] do u want an update on my life bcuz ...  \n",
       "868   ...How are you not? Medusa _broke into your ap...  \n",
       "2261                                           [_nods_]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62485e57-c587-49c7-8b38-09ac2ce4611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2022 01:19:30 - WARNING - src.train -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_dir': 'output-medium', 'model_type': 'gpt2', 'model_name_or_path': 'microsoft/DialoGPT-medium', 'config_name': 'microsoft/DialoGPT-medium', 'tokenizer_name': 'microsoft/DialoGPT-medium', 'cache_dir': 'cached', 'block_size': 512, 'do_train': True, 'do_eval': True, 'evaluate_during_training': False, 'per_gpu_train_batch_size': 4, 'per_gpu_eval_batch_size': 4, 'gradient_accumulation_steps': 1, 'learning_rate': 5e-05, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 3, 'max_steps': -1, 'warmup_steps': 0, 'logging_steps': 1000, 'save_steps': 3500, 'save_total_limit': None, 'eval_all_checkpoints': False, 'no_cuda': False, 'overwrite_output_dir': True, 'overwrite_cache': True, 'should_continue': False, 'seed': 42, 'local_rank': -1, 'fp16': False, 'fp16_opt_level': 'O1'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6d0b91d5824681851554f02e9f39c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21e0d31acf84f5d8bc429dc036c7ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c3a25c92fe4c86a25a7b33956bb583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45b5c5b71984dedb3d46e4b16d467e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:921: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f1e43e191a436d947f057694d3b6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/823M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2022 01:20:03 - INFO - src.train -   Training/evaluation parameters <src.args.Args object at 0x7faeebccb010>\n",
      "06/05/2022 01:20:03 - INFO - src.dataset -   Creating features from dataset file at cached\n",
      "06/05/2022 01:20:05 - INFO - src.dataset -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "06/05/2022 01:20:05 - INFO - src.train -   ***** Running training *****\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Num examples = 4967\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Num Epochs = 3\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Instantaneous batch size per GPU = 4\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Gradient Accumulation steps = 1\n",
      "06/05/2022 01:20:05 - INFO - src.train -     Total optimization steps = 3723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e37f0f9e03044758e7a9bbb17718cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fee15ef1083496d8ba4f96b7fc1945b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8ed627a8b34e42910c64bfb63402ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95af452726174b05b7d6d9acff867919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2022 01:34:39 - INFO - src.train -   Saving model checkpoint to output-medium/checkpoint-3500\n",
      "06/05/2022 01:34:42 - INFO - src.train -   Saving optimizer and scheduler states to output-medium/checkpoint-3500\n",
      "06/05/2022 01:35:38 - INFO - src.train -    global_step = 3723, average loss = 1.7945089038264326\n",
      "06/05/2022 01:35:38 - INFO - src.train -   Saving model checkpoint to output-medium\n",
      "06/05/2022 01:35:42 - INFO - src.train -   Evaluate the following checkpoints: ['output-medium']\n",
      "06/05/2022 01:35:45 - INFO - src.dataset -   Creating features from dataset file at cached\n",
      "06/05/2022 01:35:45 - INFO - src.dataset -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "06/05/2022 01:35:45 - INFO - src.train -   ***** Running evaluation  *****\n",
      "06/05/2022 01:35:45 - INFO - src.train -     Num examples = 552\n",
      "06/05/2022 01:35:45 - INFO - src.train -     Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d44820527c4745a04e3f8255ca3f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/05/2022 01:35:53 - INFO - src.train -   ***** Eval results  *****\n",
      "06/05/2022 01:35:53 - INFO - src.train -     perplexity = tensor(4.6761)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'perplexity_': tensor(4.6761)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(trn_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dddbc0-4599-474c-aa4a-c4cae6593722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation, ConversationalPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51400f6c-5817-499d-9d6d-4efbe90c67c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversational_pipeline = pipeline(\"conversational\", model=\"output-small\", tokenizer=\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3de113-d8ec-46a2-824d-ac3dddb4a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "conversation_1 = Conversation(\"Hello. How are you?\")\n",
    "conversation_2 = Conversation(\"How is Shiro doing?\")\n",
    "\n",
    "responses = conversational_pipeline([conversation_1, conversation_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39546740-6fcf-492b-81ee-c07ec0be03c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm doing alright.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].generated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3103106-1c74-4a62-ab3b-0e5085094667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       " user >> Hello. How are you? \n",
       " bot >> I'm doing alright. ,\n",
       " Conversation id: c094e49f-553a-4799-9a86-7af3e2e4bd47 \n",
       " user >> How is Shiro doing? \n",
       " bot >> [_shrugs_] I don't know. ]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5141149f-6b27-44d7-a456-ec19da70417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1.add_user_input(\"That's good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e748e7a8-3a61-4fd7-8d3c-15eb199bd414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       "user >> Hello. How are you? \n",
       "bot >> I'm doing alright. \n",
       "user >> That's good! "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72e6771-d2f3-43c1-a03a-080b39ccaf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       "user >> Hello. How are you? \n",
       "bot >> I'm doing alright. \n",
       "user >> That's good! \n",
       "bot >> [_sighs_] "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_pipeline(conversation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d84660-613b-47e4-adc6-8a30a6ff0ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[_sighs_]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_1.generated_responses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da149d0e-44ba-456f-b9b7-1498f9881924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
