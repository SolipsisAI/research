{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d822b1ea-868c-43f1-a471-63fd54782d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c9fe99-f10b-4aaa-8f43-c1eebd4bbe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import main\n",
    "from src.utils import prepare_data\n",
    "\n",
    "data_filepath = \"../../data/processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f1537f8-f29b-4266-b75a-e2814df31574",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df, val_df = prepare_data(data_filepath, filter_args={\"key\": \"character\", \"value\": \"bitjockey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdee8151-0270-4b2c-a817-ee679d4ce884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Do I...?</td>\n",
       "      <td>[_questioning look_]</td>\n",
       "      <td>Do you....</td>\n",
       "      <td>Right.</td>\n",
       "      <td>Regardless...we..need a solution</td>\n",
       "      <td>[_quietly_] no. But we....need to find out. To...</td>\n",
       "      <td>And we don't know who.</td>\n",
       "      <td>[_is quiet_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>[_texts_] does shiro know about this already?</td>\n",
       "      <td>[*texts*] there's a park near our house where ...</td>\n",
       "      <td>[_responds_]  That junior fence guy, yeah?</td>\n",
       "      <td>[_responds_] oooh.  That sounds like fun.  I l...</td>\n",
       "      <td>[*texts*] so, uh, my mom found out that her bi...</td>\n",
       "      <td>[_texts_] i remember</td>\n",
       "      <td>[*texts*] remember how hopper suggested combin...</td>\n",
       "      <td>[*texts*] i said there's been a development re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>(( is she still holding her arm? ))</td>\n",
       "      <td>[_does not look away from Hopper_]</td>\n",
       "      <td>*Kalahan takes a deep breath and squares his s...</td>\n",
       "      <td>[_This is probably the most intense you've eve...</td>\n",
       "      <td>*Kalahan clenches his teeth and fists, really ...</td>\n",
       "      <td>So if you shouldn't live, _why should I?_</td>\n",
       "      <td>And what you did would have _broken_ me.</td>\n",
       "      <td>[_quietly_] I can‚Äôt imagine what you went through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>frag</td>\n",
       "      <td>we're not exactly _common_</td>\n",
       "      <td>so what are the _fucking odds_ that this shama...</td>\n",
       "      <td>_yup_</td>\n",
       "      <td>like u</td>\n",
       "      <td>yup</td>\n",
       "      <td>hes</td>\n",
       "      <td>yeah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>[_goes quiet_{</td>\n",
       "      <td>I...have a few people on my hit list</td>\n",
       "      <td>[_smiles_]</td>\n",
       "      <td>They made a huge mistake, attacking dragons...</td>\n",
       "      <td>We will save her. And we'll get back at those ...</td>\n",
       "      <td>*He nods as he scans the area.*\\nIndeed...I ho...</td>\n",
       "      <td>[_nods_] But you have people here now to help ...</td>\n",
       "      <td>*Kalahan shrugs, and scratches the back of his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>[_texts @ultranos Akari and Julia_] good morning</td>\n",
       "      <td>[_Medusa has found clean clothes from...somewh...</td>\n",
       "      <td>[_she will make her way to hoppers apartment_]</td>\n",
       "      <td>[_texts_] üëç</td>\n",
       "      <td>[_texts_] ok did u want 2 get some</td>\n",
       "      <td>[_texts_] jst wk up</td>\n",
       "      <td>[_texts_] ....no?</td>\n",
       "      <td>[_texts_] have u had breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>Hope they..figure something out.</td>\n",
       "      <td>Oh hmm.</td>\n",
       "      <td>Nix is going to meet with Temper like...right ...</td>\n",
       "      <td>Nice. It's good to be back home</td>\n",
       "      <td>Uh...so how..has your day been.</td>\n",
       "      <td>[_will help_]</td>\n",
       "      <td>[*will go to start packing hopper`s stuff*]</td>\n",
       "      <td>[_will follow if someone leads her_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>So...how up to speed are you?</td>\n",
       "      <td>Ah, okay. [_glances at Charlotte_]</td>\n",
       "      <td>[_nods_] Right. So...look, this _issue_ is all...</td>\n",
       "      <td>[_nods_] That's accurate.</td>\n",
       "      <td>At..our disposal? I..yes.</td>\n",
       "      <td>Well, he...you?...seem to have access to more ...</td>\n",
       "      <td>That's...intriguing. [_makes a face_]</td>\n",
       "      <td>[_Amarok looks interested_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>[_smiles and...chuckles?_] Whoops.</td>\n",
       "      <td>[_Julia's tries to hold in a laugh and fails._]</td>\n",
       "      <td>[_blinks at Akari, looks into her mug, and the...</td>\n",
       "      <td>I have seen you drink soycaf, Alex. There is n...</td>\n",
       "      <td>[_a slight smile; tries to drink from the empt...</td>\n",
       "      <td>...able to talk?</td>\n",
       "      <td>That's...unfortunate that she has those...thin...</td>\n",
       "      <td>Oh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>[_turns around and sits back down, and sips ho...</td>\n",
       "      <td>[_to Hopper_] Can...I know you don't want to r...</td>\n",
       "      <td>[_looks at Medusa, smiles, but doesn't say any...</td>\n",
       "      <td>[_to Hopper_] You didn't finish your cocoa.</td>\n",
       "      <td>[_stares for a second then looks at Julia with...</td>\n",
       "      <td>[_will try to get up and head to her room unle...</td>\n",
       "      <td>[_doesn't respond_]</td>\n",
       "      <td>Everyone doing good here?  Need anything else ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               response  \\\n",
       "2520                                           Do I...?   \n",
       "4484      [_texts_] does shiro know about this already?   \n",
       "2690                (( is she still holding her arm? ))   \n",
       "507                                                frag   \n",
       "4674                                     [_goes quiet_{   \n",
       "2881   [_texts @ultranos Akari and Julia_] good morning   \n",
       "2211                   Hope they..figure something out.   \n",
       "2367                      So...how up to speed are you?   \n",
       "2019                 [_smiles and...chuckles?_] Whoops.   \n",
       "2827  [_turns around and sits back down, and sips ho...   \n",
       "\n",
       "                                                context  \\\n",
       "2520                               [_questioning look_]   \n",
       "4484  [*texts*] there's a park near our house where ...   \n",
       "2690                 [_does not look away from Hopper_]   \n",
       "507                          we're not exactly _common_   \n",
       "4674               I...have a few people on my hit list   \n",
       "2881  [_Medusa has found clean clothes from...somewh...   \n",
       "2211                                            Oh hmm.   \n",
       "2367                 Ah, okay. [_glances at Charlotte_]   \n",
       "2019    [_Julia's tries to hold in a laugh and fails._]   \n",
       "2827  [_to Hopper_] Can...I know you don't want to r...   \n",
       "\n",
       "                                              context/0  \\\n",
       "2520                                         Do you....   \n",
       "4484         [_responds_]  That junior fence guy, yeah?   \n",
       "2690  *Kalahan takes a deep breath and squares his s...   \n",
       "507   so what are the _fucking odds_ that this shama...   \n",
       "4674                                         [_smiles_]   \n",
       "2881     [_she will make her way to hoppers apartment_]   \n",
       "2211  Nix is going to meet with Temper like...right ...   \n",
       "2367  [_nods_] Right. So...look, this _issue_ is all...   \n",
       "2019  [_blinks at Akari, looks into her mug, and the...   \n",
       "2827  [_looks at Medusa, smiles, but doesn't say any...   \n",
       "\n",
       "                                              context/1  \\\n",
       "2520                                             Right.   \n",
       "4484  [_responds_] oooh.  That sounds like fun.  I l...   \n",
       "2690  [_This is probably the most intense you've eve...   \n",
       "507                                               _yup_   \n",
       "4674     They made a huge mistake, attacking dragons...   \n",
       "2881                                        [_texts_] üëç   \n",
       "2211                    Nice. It's good to be back home   \n",
       "2367                          [_nods_] That's accurate.   \n",
       "2019  I have seen you drink soycaf, Alex. There is n...   \n",
       "2827        [_to Hopper_] You didn't finish your cocoa.   \n",
       "\n",
       "                                              context/2  \\\n",
       "2520                   Regardless...we..need a solution   \n",
       "4484  [*texts*] so, uh, my mom found out that her bi...   \n",
       "2690  *Kalahan clenches his teeth and fists, really ...   \n",
       "507                                              like u   \n",
       "4674  We will save her. And we'll get back at those ...   \n",
       "2881                 [_texts_] ok did u want 2 get some   \n",
       "2211                    Uh...so how..has your day been.   \n",
       "2367                          At..our disposal? I..yes.   \n",
       "2019  [_a slight smile; tries to drink from the empt...   \n",
       "2827  [_stares for a second then looks at Julia with...   \n",
       "\n",
       "                                              context/3  \\\n",
       "2520  [_quietly_] no. But we....need to find out. To...   \n",
       "4484                               [_texts_] i remember   \n",
       "2690          So if you shouldn't live, _why should I?_   \n",
       "507                                                 yup   \n",
       "4674  *He nods as he scans the area.*\\nIndeed...I ho...   \n",
       "2881                                [_texts_] jst wk up   \n",
       "2211                                      [_will help_]   \n",
       "2367  Well, he...you?...seem to have access to more ...   \n",
       "2019                                   ...able to talk?   \n",
       "2827  [_will try to get up and head to her room unle...   \n",
       "\n",
       "                                              context/4  \\\n",
       "2520                             And we don't know who.   \n",
       "4484  [*texts*] remember how hopper suggested combin...   \n",
       "2690           And what you did would have _broken_ me.   \n",
       "507                                                 hes   \n",
       "4674  [_nods_] But you have people here now to help ...   \n",
       "2881                                  [_texts_] ....no?   \n",
       "2211        [*will go to start packing hopper`s stuff*]   \n",
       "2367              That's...intriguing. [_makes a face_]   \n",
       "2019  That's...unfortunate that she has those...thin...   \n",
       "2827                                [_doesn't respond_]   \n",
       "\n",
       "                                              context/5  \n",
       "2520                                       [_is quiet_]  \n",
       "4484  [*texts*] i said there's been a development re...  \n",
       "2690  [_quietly_] I can‚Äôt imagine what you went through  \n",
       "507                                                yeah  \n",
       "4674  *Kalahan shrugs, and scratches the back of his...  \n",
       "2881                     [_texts_] have u had breakfast  \n",
       "2211               [_will follow if someone leads her_]  \n",
       "2367                        [_Amarok looks interested_]  \n",
       "2019                                                Oh.  \n",
       "2827  Everyone doing good here?  Need anything else ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62485e57-c587-49c7-8b38-09ac2ce4611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/04/2022 23:50:23 - WARNING - src.train -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:921: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "06/04/2022 23:50:27 - INFO - src.train -   Training/evaluation parameters <src.args.Args object at 0x7f8762fb5450>\n",
      "06/04/2022 23:50:27 - INFO - src.dataset -   Creating features from dataset file at cached\n",
      "06/04/2022 23:50:29 - INFO - src.dataset -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "06/04/2022 23:50:29 - INFO - src.train -   ***** Running training *****\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Num examples = 4967\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Num Epochs = 3\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Instantaneous batch size per GPU = 4\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Gradient Accumulation steps = 1\n",
      "06/04/2022 23:50:29 - INFO - src.train -     Total optimization steps = 3723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fcedbbf35244cfa2edffb83b7ee910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac40b69cf4424812b9da0920873ebb95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fbe1da41434686899d9b677949897e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1737cf14abbd4eb893872cf21cf939b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1241 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/04/2022 23:55:58 - INFO - src.train -   Saving model checkpoint to output-small/checkpoint-3500\n",
      "06/04/2022 23:56:01 - INFO - src.train -   Saving optimizer and scheduler states to output-small/checkpoint-3500\n",
      "06/04/2022 23:56:22 - INFO - src.train -    global_step = 3723, average loss = 2.2265559562649293\n",
      "06/04/2022 23:56:22 - INFO - src.train -   Saving model checkpoint to output-small\n",
      "06/04/2022 23:56:25 - INFO - src.train -   Evaluate the following checkpoints: ['output-small']\n",
      "06/04/2022 23:56:26 - INFO - src.dataset -   Creating features from dataset file at cached\n",
      "06/04/2022 23:56:26 - INFO - src.dataset -   Saving features into cached file cached/gpt2_cached_lm_512\n",
      "06/04/2022 23:56:26 - INFO - src.train -   ***** Running evaluation  *****\n",
      "06/04/2022 23:56:26 - INFO - src.train -     Num examples = 552\n",
      "06/04/2022 23:56:26 - INFO - src.train -     Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c969009408644ea93e1f857183b4541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/04/2022 23:56:29 - INFO - src.train -   ***** Eval results  *****\n",
      "06/04/2022 23:56:29 - INFO - src.train -     perplexity = tensor(7.2604)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'perplexity_': tensor(7.2604)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(trn_df, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1d6421-32d9-46f9-b0a5-086c45f82561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: How are you today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowBot: I'm fine.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: Are you sure?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowBot: It's fine\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: Are you absolutely sure?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowBot: Yeah, I'm fine\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: Okay, that's good, I guess.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowBot: !!!@Charlotte!! üçø!!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">> User: What's goin gon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShadowBot: !@bitjockey!! @Charlotte we're meeting up to do something\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/DialoGPT-small')\n",
    "model = AutoModelWithLMHead.from_pretrained('output-small')\n",
    "\n",
    "# Let's chat for 5 lines\n",
    "for step in range(5):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(input(\">> User:\") + tokenizer.eos_token, return_tensors='pt')\n",
    "    # print(new_user_input_ids)\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids, max_length=200,\n",
    "        pad_token_id=tokenizer.eos_token_id,  \n",
    "        no_repeat_ngram_size=3,       \n",
    "        do_sample=True, \n",
    "        top_k=100, \n",
    "        top_p=0.7,\n",
    "        temperature = 0.8\n",
    "    )\n",
    "    \n",
    "    # pretty print last ouput tokens from bot\n",
    "    print(\"ShadowBot: {}\".format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dddbc0-4599-474c-aa4a-c4cae6593722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation, ConversationalPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51400f6c-5817-499d-9d6d-4efbe90c67c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conversational_pipeline = pipeline(\"conversational\", model=\"output-small\", tokenizer=\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc3de113-d8ec-46a2-824d-ac3dddb4a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "conversation_1 = Conversation(\"Hello. How are you?\")\n",
    "conversation_2 = Conversation(\"How is Shiro doing?\")\n",
    "\n",
    "responses = conversational_pipeline([conversation_1, conversation_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39546740-6fcf-492b-81ee-c07ec0be03c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm doing alright.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0].generated_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3103106-1c74-4a62-ab3b-0e5085094667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       " user >> Hello. How are you? \n",
       " bot >> I'm doing alright. ,\n",
       " Conversation id: c094e49f-553a-4799-9a86-7af3e2e4bd47 \n",
       " user >> How is Shiro doing? \n",
       " bot >> [_shrugs_] I don't know. ]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5141149f-6b27-44d7-a456-ec19da70417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_1.add_user_input(\"That's good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e748e7a8-3a61-4fd7-8d3c-15eb199bd414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       "user >> Hello. How are you? \n",
       "bot >> I'm doing alright. \n",
       "user >> That's good! "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f72e6771-d2f3-43c1-a03a-080b39ccaf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conversation id: ccc61d84-e1da-468e-a33e-2e1d0effdf3f \n",
       "user >> Hello. How are you? \n",
       "bot >> I'm doing alright. \n",
       "user >> That's good! \n",
       "bot >> [_sighs_] "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_pipeline(conversation_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d84660-613b-47e4-adc6-8a30a6ff0ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[_sighs_]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_1.generated_responses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da149d0e-44ba-456f-b9b7-1498f9881924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
