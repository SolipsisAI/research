{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc19e10-b8f3-4b0e-8e0e-6a3d74c79d82",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT\n",
    "\n",
    "https://www.modeldifferently.com/en/2021/12/generaci%C3%B3n-de-fake-news-con-gpt-2/#data-loading-and-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5342b571-99e6-4257-9052-9a2eeb9db178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50890486-20bc-4265-b21b-2bc52142159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from datasets import Dataset, list_metrics, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d1459b-99ae-4d54-ae62-1ff1f60666ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"gpt2\"\n",
    "#model_cls = GPT2LMHeadModel\n",
    "#tokenizer_cls = GPT2Tokenizer\n",
    "\n",
    "MODEL_NAME = \"microsoft/DialoGPT-small\"\n",
    "model_cls = AutoModelForCausalLM\n",
    "tokenizer_cls = AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1722bf0b-9462-4fbe-a369-ab4e3ac13c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    cuda: True\n",
      "    current_device: 0\n",
      "    device_count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev) \n",
    "\n",
    "print(f\"\"\"\n",
    "    cuda: {torch.cuda.is_available()}\n",
    "    current_device: {torch.cuda.current_device()}\n",
    "    device_count: {torch.cuda.device_count()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a6c3ca9-76aa-4338-bdee-d444467cee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e5c7d-99cd-4fb0-b92c-c06fc8d31739",
   "metadata": {},
   "source": [
    "## Load Data, Tokenizer, and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae2ca3-2502-4c89-b8f7-d2438099d78b",
   "metadata": {},
   "source": [
    "### Data Loading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6348c3-7b02-48e6-bd03-8b54763c722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32080</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32081</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Right. Geeze. I...did not expect to ever hear from him again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32082</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>...Surprise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um...sure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_as she talks she takes the book off the table and carefully tucks it away in her bag_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um, yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32088</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Tomorrow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32089</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_she will leave with the others_]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "32080  Charlotte   \n",
       "32081       Toby   \n",
       "32082  Charlotte   \n",
       "32083  Charlotte   \n",
       "32084       Toby   \n",
       "32085  Charlotte   \n",
       "32086  Charlotte   \n",
       "32087       Toby   \n",
       "32088       Toby   \n",
       "32089  Charlotte   \n",
       "\n",
       "                                                                                                                              text  \n",
       "32080                                   What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.  \n",
       "32081                                                                Right. Geeze. I...did not expect to ever hear from him again.  \n",
       "32082                                                                                                                 ...Surprise?  \n",
       "32083  So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.  \n",
       "32084                                                                                                                   Um...sure.  \n",
       "32085                                                         Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?  \n",
       "32086                                     [_as she talks she takes the book off the table and carefully tucks it away in her bag_]  \n",
       "32087                                                                                                                    Um, yeah.  \n",
       "32088                                                                                                                    Tomorrow.  \n",
       "32089                                                                                           [_she will leave with the others_]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../data/processed.csv\"\n",
    "df = pd.read_csv(filepath, encoding=\"utf-8\", usecols=[\"character\", \"content\"]).rename(columns={\"content\": \"text\"})\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f9585-6e12-4bf1-990f-40aeb39f5952",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b09bb6c-1983-4e87-b805-3dab99ae9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model_cls.from_pretrained(MODEL_NAME, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502b3b5d-d0b6-47f9-9424-a0a646a95ba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ModuleUtilsMixin.num_parameters of GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.num_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e23c7b-052d-411c-ac45-66bfcf9540f0",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ff1d2c-2dfd-4f29-939e-bf4f299a3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = tokenizer_cls.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138c94af-7007-4dbb-afe4-59eeeb05d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab_size: {base_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfce691-d927-41cd-95bd-db815dfb6c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = base_tokenizer.get_vocab()\n",
    "vocabulary[\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec35b380-12ca-4328-b383-bfa391cc2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9e4984-f7dd-4a15-8363-a09aa557a8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2753c1-7f96-4d54-93d7-9734f52215f1",
   "metadata": {},
   "source": [
    "## Conversational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef9899-32f8-4f89-8917-53db3c6f6155",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "643ea45d-7857-496d-8a2e-595ef714b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "from typing import Dict, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    data_or_filename: Union[str, pd.DataFrame],\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "    test_size: float = 0.1,\n",
    "    flatten: bool = True,\n",
    "):\n",
    "    data = load_csv(data_or_filename) if isinstance(data_or_filename, str) else data_or_filename\n",
    "\n",
    "    contexted_data = prepare_context(\n",
    "        data,\n",
    "        filter_by=filter_by,\n",
    "        filter_value=filter_value,\n",
    "        content_key=content_key,\n",
    "        n=n,\n",
    "    )\n",
    "\n",
    "    trn_df, val_df = train_test_split(contexted_data, test_size=test_size)\n",
    "    \n",
    "    if flatten:\n",
    "        train_dataset = prepare_dataset(trn_df)\n",
    "        val_dataset = prepare_dataset(val_df)\n",
    "        return train_dataset, val_dataset\n",
    "\n",
    "    return trn_df, val_df\n",
    "\n",
    "\n",
    "def prepare_context(\n",
    "    data: pd.DataFrame,\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "):\n",
    "    if filter_by:\n",
    "        indexes = data.loc[data[filter_by] == filter_value].index\n",
    "    else:\n",
    "        indexes = range(n, len(data[content_key]))\n",
    "\n",
    "    contexted = []\n",
    "\n",
    "    for i in indexes:\n",
    "        row = []\n",
    "        prev = i - 1 - n\n",
    "        for j in range(i, prev, -1):\n",
    "            row.append(data.iloc[j][content_key])\n",
    "        contexted.append(row)\n",
    "\n",
    "    columns = [\"response\", \"context\"]\n",
    "    columns = columns + [\"context/\" + str(i) for i in range(n - 1)]\n",
    "\n",
    "    df = pd.DataFrame.from_records(contexted, columns=columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    columns = [col for col in df] \n",
    "    dataset = Dataset.from_pandas(concat_text(df))\n",
    "    dataset = dataset.remove_columns(columns + ['__index_level_0__'])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def concat_text(df):\n",
    "    df[\"text\"] = df.apply(concat_text_in_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def concat_text_in_row(row):\n",
    "    concat_text = f\"{base_tokenizer.eos_token}\".join(row.values)\n",
    "    # Add to end\n",
    "    concat_text += base_tokenizer.eos_token\n",
    "    return concat_text\n",
    "\n",
    "\n",
    "def construct_conv(example, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example]))\n",
    "    print(f\"Conv Length: {len(conv)}\") \n",
    "    print(set(list(map(len, conv))))\n",
    "    conv = flatten(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e7b3ccf-e3ab-4c2f-a38e-1c3384db0222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer._pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce5db7f6-8486-4b76-a76f-63559628fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = prepare_data(df, filter_by=\"character\", filter_value=\"bitjockey\", flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc165239-6ec7-43f9-b981-772f8783d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "450f2318-9c52-403a-b5a8-8d15b75078ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenizer):\n",
    "    def _tokenize(example):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example if \"__index\" not in x]))\n",
    "        conv = flatten(conv)\n",
    "        return conv\n",
    "        \n",
    "    def _preprocess(examples):\n",
    "        #flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        #conv = list([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in examples])\n",
    "        #conv = flatten(conv)\n",
    "        #return {\"input_ids\": conv}\n",
    "        return {\"input_ids\": list(map(_tokenize, examples))}\n",
    "    \n",
    "    return _preprocess\n",
    "\n",
    "\n",
    "def tokenize(example):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example]))\n",
    "    print(f\"Conv Length: {len(conv)}\") \n",
    "    print(set(list(map(len, conv))))\n",
    "    conv = flatten(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def debug_preprocess(tokenizer, max_length=250): \n",
    "    def _tokenize(examples):\n",
    "        input_ids = [tokenizer.encode(v, padding=\"max_length\", max_length=250) for k, v in examples.items() if isinstance(v, str)]\n",
    "        examples[\"input_ids\"] = input_ids\n",
    "        return examples\n",
    "    return _tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bcc0914-a207-4d1c-9a9a-6634a2e6517c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 4967\n",
       "})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4c2c91b-70c9-456b-8ca5-63bbe748e289",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 552\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "53a7fc9a-668f-4382-88bf-f816e8ae0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def preprocess_conv(tokenizer):\n",
    "    def _construct(examples):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "        conv = list(reversed([tokenizer.encode(v) + [tokenizer.eos_token_id] for k,v in examples.items() if isinstance(v, str)]))\n",
    "        conv = flatten(conv)\n",
    "        examples[\"input_ids\"] = conv\n",
    "        return examples \n",
    "    return _construct\n",
    "\n",
    "\n",
    "def preprocess_function(tokenizer, max_length=512):\n",
    "    def _construct(examples):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "        concat_text = f\"{tokenizer.eos_token}\".join(reversed([v for _, v in examples.items() if isinstance(v, str)]))\n",
    "        concat_text = concat_text + tokenizer.eos_token\n",
    "        tokenized = tokenizer(concat_text, padding=\"max_length\",  max_length=max_length)\n",
    "        examples[\"input_ids\"] = tokenized[\"input_ids\"]\n",
    "        examples[\"attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "        return examples\n",
    "        \n",
    "    return _construct\n",
    "\n",
    "\n",
    "def collate(examples: List[torch.Tensor], tokenizer):\n",
    "    if tokenizer._pad_token is None:\n",
    "        return pad_sequence(examples, batch_first=True)\n",
    "    return pad_sequence(\n",
    "        examples, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1dd1f4b2-6f33-4fb0-85c7-6a8347b25018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='microsoft/DialoGPT-small', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "61d53884-df1c-42d0-8a32-648afca98ae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8da77eb3064bc686e77bd86a3663fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4967 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a5181b7c374b35a6180901b319d393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(train_dataset.features.keys()))\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(val_dataset.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dcd83ed6-3fac-447a-bd65-2a8c56397b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [*nods*]<|endoftext|>Hmmm.<|endoftext|>Interesting.<|endoftext|>Were you....in that situation?<|endoftext|>[_shrugs one shoulder, so as not to disturb Shiro_] Sort of. I guess I bounced between homes of relatives in the tribe, after my father died. Didn't really stay in one home for very long.<|endoftext|>Were they...okay?<|endoftext|>[*gets a confused look, but doesn't say anything*]<|endoftext|>I mean...did they treat you okay?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    decoded = base_tokenizer.decode(tokenized_train_dataset[0][\"input_ids\"])\n",
    "    print(len(tokenized_train_dataset[i][\"input_ids\"]), decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68930df4-c807-418a-ba40-9db502d9daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 4967\n",
       "})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2bf184bd-0785-4853-ac2e-aef373830e05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "tokenized_val_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d05942e-528c-4b02-b8d3-085a99a10951",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee5835-da48-468b-b2af-45d407d9a8c9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52d02923-9740-413b-ba81-c46597c56423",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"perplexity\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2313d34-3806-4d23-a40a-495d36c084e2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc4fb8f8-39eb-45f9-a9a0-25575af5e5f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.resize_token_embeddings(len(base_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "52086282-7820-4e5f-91b3-549529ed7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "FINETUNED_MODEL = 'AI-05162022a-myDialoGPT2-small'\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=base_tokenizer,\n",
    "    mlm=False,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "trainer = None\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=FINETUNED_MODEL,          # output directory\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=1,              # total # of training epochs\n",
    "    per_device_train_batch_size=3,  # batch size per device during training\n",
    "    per_device_eval_batch_size=3,   # batch size for evaluation\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    logging_dir=FINETUNED_MODEL,            # directory for storing logs\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7e9eab83-e5f6-4da7-8d90-69d808da13c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "985db8b4-0d4d-4c9b-a96c-a712c4c1ebf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4967\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1656' max='1656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1656/1656 04:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.436600</td>\n",
       "      <td>2.351059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to AI-05162022a-myDialoGPT2-small/checkpoint-500\n",
      "Configuration saved in AI-05162022a-myDialoGPT2-small/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4388\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.490338164251208e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in AI-05162022a-myDialoGPT2-small/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to AI-05162022a-myDialoGPT2-small/checkpoint-1000\n",
      "Configuration saved in AI-05162022a-myDialoGPT2-small/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4136\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.9806763285024154e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in AI-05162022a-myDialoGPT2-small/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to AI-05162022a-myDialoGPT2-small/checkpoint-1500\n",
      "Configuration saved in AI-05162022a-myDialoGPT2-small/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4366\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.710144927536232e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in AI-05162022a-myDialoGPT2-small/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 552\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "2.3510587215423584\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "8.5521\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "64.545\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "21.515\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric train_runtime:\n",
      "275.5118\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "18.028\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "6.011\n",
      "Attempted to log scalar metric total_flos:\n",
      "659531708928000.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "2.436564883172224\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1656, training_loss=2.436564883172224, metrics={'train_runtime': 275.5118, 'train_samples_per_second': 18.028, 'train_steps_per_second': 6.011, 'total_flos': 659531708928000.0, 'train_loss': 2.436564883172224, 'epoch': 1.0})"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d0a77399-5118-458b-8147-54139ede96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to AI-05162022a-myDialoGPT2-small\n",
      "Configuration saved in AI-05162022a-myDialoGPT2-small/config.json\n",
      "Model weights saved in AI-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "tokenizer config file saved in AI-05162022a-myDialoGPT2-small/tokenizer_config.json\n",
      "Special tokens file saved in AI-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "Configuration saved in AI-05162022a-myDialoGPT2-small/config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(FINETUNED_MODEL)\n",
    "base_tokenizer.save_pretrained(FINETUNED_MODEL)\n",
    "config.save_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "490541df-a595-4c80-8e5c-9b8ff66a9c39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file AI-05162022a-myDialoGPT2-small/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"AI-05162022a-myDialoGPT2-small\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"conversational\": {\n",
      "      \"max_length\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50258\n",
      "}\n",
      "\n",
      "loading weights file AI-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at AI-05162022a-myDialoGPT2-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading file AI-05162022a-myDialoGPT2-small/vocab.json\n",
      "loading file AI-05162022a-myDialoGPT2-small/merges.txt\n",
      "loading file AI-05162022a-myDialoGPT2-small/tokenizer.json\n",
      "loading file AI-05162022a-myDialoGPT2-small/added_tokens.json\n",
      "loading file AI-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "loading file AI-05162022a-myDialoGPT2-small/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(FINETUNED_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af6daae3-1241-4782-920e-16b5e67933f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, text, chat_history_ids=None, step=0):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.7\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    return response, chat_history_ids, step + 1\n",
    "\n",
    "def chat(model, tokenizer):\n",
    "    step = 0\n",
    "    chat_history_ids = []\n",
    "    \n",
    "    while True: \n",
    "        text = input(\">> \")\n",
    "        if text in [\"/q\", \"/quit\", \"/e\", \"/exit\"]: break\n",
    "        print(f\"User: {text}\")\n",
    "        response, chat_history_ids, step = generate_responses(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            text=text,\n",
    "            chat_history_ids=chat_history_ids,\n",
    "            step=step\n",
    "        )\n",
    "        print(f\"Bot: {response}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e5dce-153c-46be-80b7-f29db173c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "Bot: Hey\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How are you?\n",
      "Bot: I am ok.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How is Shiro?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How is Shiro?\n",
      "Bot: Just talking\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Where are we meeting?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Where are we meeting?\n",
      "Bot: In the common room.\n"
     ]
    }
   ],
   "source": [
    "chat(finetuned_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe9c9a-2d91-421e-b3ce-74cece0cf3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "008d0fde93e84ef3a3b8fd48815738b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0218414ac4074dd8b7fcda5d94df1d5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "055d2ccf8f0640dc904be5c69f323f3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6aa4cccd2efa4405b8a08b9c8a5cf0a7",
       "style": "IPY_MODEL_1bdfc7dc6ba4458090fbd8b0a5a9b162",
       "value": "100%"
      }
     },
     "07ef12239e304c60abac0f0610b595ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4bacc41267fd4650ac2a2c1e08ffc998",
       "style": "IPY_MODEL_9b6a971d34b042b2a96798a4d36c71da",
       "value": "100%"
      }
     },
     "090f44bae54a4bd999fba6f6b38ed2e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_88470d7490ab49018efc0aaa93ced0c4",
        "IPY_MODEL_d92262eb5d86406b823762b71043dad2",
        "IPY_MODEL_c8df7df58c6a40328bce1c52137090af"
       ],
       "layout": "IPY_MODEL_e307d9088ccb46a48d9e91726009824e"
      }
     },
     "0b7bb1c17004432d8abfafd4c7bae994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_07ef12239e304c60abac0f0610b595ca",
        "IPY_MODEL_69a26e52000f432baa273d2e63bfc638",
        "IPY_MODEL_75f31d2dfce944a0be91316491817ee2"
       ],
       "layout": "IPY_MODEL_51946d084f6746c1a3c09f56184c92e8"
      }
     },
     "0be465e1cf4447a3adbf258f2270c806": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "0dc3f171042c47278b2cb452942a408e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_23f18331df904043b10ca377aa6e6d1b",
       "style": "IPY_MODEL_1f05f264716b4a9a9ea9e1c0dd620264",
       "value": " 4967/4967 [00:01&lt;00:00, 2522.21ex/s]"
      }
     },
     "0eb153a6d24a4c60935cd2ddb0828dec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "12ecfcbfa28343929fb696c4a40cb052": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1bdfc7dc6ba4458090fbd8b0a5a9b162": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1d8c110dd6974ce9bfacda91de2503ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1f05f264716b4a9a9ea9e1c0dd620264": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "203e1695d825454292e573b4f462ba22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "20e616d395f440b5a5e980ac8ddbef4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "21b0dbe462844ec9bf717468fb8b8e01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "23f18331df904043b10ca377aa6e6d1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "25c58e59a25d4932845f4bee6ecdda31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_796f3a7a70fa4595adef7311a0e01032",
       "style": "IPY_MODEL_3a147c09e2fd46009cc73b2136161a82",
       "value": "100%"
      }
     },
     "26b071cfe02a4c7e935a47a24e5fae9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f96dc8097b594dca8183872ed6f3bef3",
       "max": 552,
       "style": "IPY_MODEL_62b31e116eff494ea6aa3e4748e974d6",
       "value": 552
      }
     },
     "27f34ae8dcff4b4e86dd131f46f961ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "28caa364fd7e4a9f9ed2ee3e08cfc438": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "29d639d9b1d84a88a5862abdf5cefe2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8bdebd2eec954d6bb17f3955ed5bf460",
        "IPY_MODEL_e99390fc96424f2bbe45d31bb27253ca",
        "IPY_MODEL_0dc3f171042c47278b2cb452942a408e"
       ],
       "layout": "IPY_MODEL_8b27e3fdb3af46d2a0ef19df0a48557d"
      }
     },
     "2c34db9948be4e6189fbaa037e39d353": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2c493dfbf0844c8cbf2ecce410f3aff7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2d2aa8512d634d50a7b27328c9457c01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6502320cc23a4300b9ff87f835ca648a",
       "style": "IPY_MODEL_f7ffe86b31194dc0898142af6642a442",
       "value": " 4967/4967 [00:01&lt;00:00, 2625.33ex/s]"
      }
     },
     "30edd17af89c42fd9875bd9fff5fa40a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4df0e8db222b45408044c4aba7b51e0d",
       "style": "IPY_MODEL_3daf62708e0a4768a50ac603923cf774",
       "value": " 4967/4967 [00:01&lt;00:00, 2587.44ex/s]"
      }
     },
     "34da0370b69249dc9b88ac816f813930": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3699d86409d844abb3df6fe4e4b30ab6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "373ec59c50ca49a6b6f2b245ea996ed2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "37c1f92f573b46daad2b9d397144a2de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_373ec59c50ca49a6b6f2b245ea996ed2",
       "max": 552,
       "style": "IPY_MODEL_0218414ac4074dd8b7fcda5d94df1d5a",
       "value": 552
      }
     },
     "39c611a60aa2471b93f8b67f5f0b202a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e9b0346c25e143dc9e7d2eccc1f7bab9",
        "IPY_MODEL_26b071cfe02a4c7e935a47a24e5fae9b",
        "IPY_MODEL_6faa485920714e9aaa8ac63cda923bb7"
       ],
       "layout": "IPY_MODEL_fed22b11b0c44ac7be09054550a12e48"
      }
     },
     "3a147c09e2fd46009cc73b2136161a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3b3129d9a2e14dd09ed68335292da156": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3cd912a828ed47b78218c4f62a634a56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3daf62708e0a4768a50ac603923cf774": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4a0bec6e4db14504b6fb466d847d8f32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4bacc41267fd4650ac2a2c1e08ffc998": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4c486ba77902469abb447c5a3ad19688": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4df0e8db222b45408044c4aba7b51e0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "50a255543ad846d38c374c8b295adbf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "51946d084f6746c1a3c09f56184c92e8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "524ae93b291546c3b3e4ddb6da4f5db1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_27f34ae8dcff4b4e86dd131f46f961ee",
       "style": "IPY_MODEL_af1aeae66c9849c5b07267e2afb990cc",
       "value": " 552/552 [00:00&lt;00:00, 2593.69ex/s]"
      }
     },
     "54de1bbdb07e4a4aac6a3be6acde98fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5b6c638d3d5a4e7e9cbb483d522e64f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5be704d5d60e46fab544770e7d2e3cee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "60f588dfdf974d2eb25262bfc36ae031": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "62b31e116eff494ea6aa3e4748e974d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "635a476747084be5a203dda619169b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_4a0bec6e4db14504b6fb466d847d8f32",
       "max": 4967,
       "style": "IPY_MODEL_e08b65aee463405ba32c0f2d3f574f5f",
       "value": 4967
      }
     },
     "6502320cc23a4300b9ff87f835ca648a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6892aa7fb8204fa38acc7320219c2b57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "69a26e52000f432baa273d2e63bfc638": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_203e1695d825454292e573b4f462ba22",
       "max": 4967,
       "style": "IPY_MODEL_0eb153a6d24a4c60935cd2ddb0828dec",
       "value": 4967
      }
     },
     "6aa4cccd2efa4405b8a08b9c8a5cf0a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6faa485920714e9aaa8ac63cda923bb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5b6c638d3d5a4e7e9cbb483d522e64f8",
       "style": "IPY_MODEL_ff985e6ebb554c3eac18abe05922a821",
       "value": " 552/552 [00:00&lt;00:00, 2554.37ex/s]"
      }
     },
     "70466dc5c2f344208d6bcc4ef3804771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0be465e1cf4447a3adbf258f2270c806",
       "style": "IPY_MODEL_54de1bbdb07e4a4aac6a3be6acde98fc",
       "value": "100%"
      }
     },
     "759c1fde832f4a86acc2669fa9c77110": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3699d86409d844abb3df6fe4e4b30ab6",
       "style": "IPY_MODEL_c16ec312189942eead02eff2bf4ad304",
       "value": "100%"
      }
     },
     "75f31d2dfce944a0be91316491817ee2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ae7fe4e8170044138913f418a085bfa8",
       "style": "IPY_MODEL_e2be5492304a4f4393bcc8824520e3a4",
       "value": " 4967/4967 [00:02&lt;00:00, 2356.24ex/s]"
      }
     },
     "796f3a7a70fa4595adef7311a0e01032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "79f001d5040244f9874013c11bf73528": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7c52c2cf442f4c30a08f0ec714eb5541": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9a0483df291b4b20b87c23e804f5b3d4",
       "style": "IPY_MODEL_50a255543ad846d38c374c8b295adbf1",
       "value": " 552/552 [00:00&lt;00:00, 2434.93ex/s]"
      }
     },
     "7f50b4c5c3ab4d018a6be9afbe33773e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "80903f31815d426496f5c98963fc9ef7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_cab32fc3db204e1caf2f4612f1c90fc3",
        "IPY_MODEL_c5c49a4b3d084e9b89acad5abcf1336c",
        "IPY_MODEL_9574019fec564238ba952cbd9e1487e7"
       ],
       "layout": "IPY_MODEL_6892aa7fb8204fa38acc7320219c2b57"
      }
     },
     "846da358d51341b88c36d561d0fbac02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_055d2ccf8f0640dc904be5c69f323f3d",
        "IPY_MODEL_f1e17278387b433ab57e4157629c8cdd",
        "IPY_MODEL_7c52c2cf442f4c30a08f0ec714eb5541"
       ],
       "layout": "IPY_MODEL_adbcb8b16f22478ba2919475b68072a2"
      }
     },
     "850eb2b76745466fa1f9e18b7ae51330": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "88470d7490ab49018efc0aaa93ced0c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_eb4a1a21fa2f45f5b9171550b4317f5b",
       "style": "IPY_MODEL_3b3129d9a2e14dd09ed68335292da156",
       "value": "100%"
      }
     },
     "88e579de85ca40ad8d1f440bed56e8fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "89e0f291c7d54b03bf359b44c96b12ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8aba1d1db48447ac9cb0789d01df3650": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_34da0370b69249dc9b88ac816f813930",
       "max": 552,
       "style": "IPY_MODEL_008d0fde93e84ef3a3b8fd48815738b2",
       "value": 552
      }
     },
     "8b27e3fdb3af46d2a0ef19df0a48557d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8bdebd2eec954d6bb17f3955ed5bf460": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8ff21fd71a0e48c4b630dcec23d0ff45",
       "style": "IPY_MODEL_ca97d517044e4c9c8fca2d29b0570358",
       "value": "100%"
      }
     },
     "8ff21fd71a0e48c4b630dcec23d0ff45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "930b09044c6447c9ac4660ba78621cf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b038f7bbb6da43b99edf238ec8507a22",
       "style": "IPY_MODEL_5be704d5d60e46fab544770e7d2e3cee",
       "value": " 552/552 [00:00&lt;00:00, 2423.47ex/s]"
      }
     },
     "9574019fec564238ba952cbd9e1487e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7f50b4c5c3ab4d018a6be9afbe33773e",
       "style": "IPY_MODEL_f13a6cc17e6a4948b782a8d5db2d8cd4",
       "value": " 4967/4967 [00:02&lt;00:00, 2280.38ex/s]"
      }
     },
     "9a0483df291b4b20b87c23e804f5b3d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9a20e0e096fd47e2ab759a8d5a047ecb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9b6a971d34b042b2a96798a4d36c71da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9f7ee58a4a6041808949a5af4a9667dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "adbcb8b16f22478ba2919475b68072a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ae7fe4e8170044138913f418a085bfa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "af1aeae66c9849c5b07267e2afb990cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b038f7bbb6da43b99edf238ec8507a22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c16ec312189942eead02eff2bf4ad304": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c3a5181b7c374b35a6180901b319d393": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f86b3fee1620497eb81d3360a389efd7",
        "IPY_MODEL_8aba1d1db48447ac9cb0789d01df3650",
        "IPY_MODEL_524ae93b291546c3b3e4ddb6da4f5db1"
       ],
       "layout": "IPY_MODEL_ebdde0e58f8446808938193c783aef3a"
      }
     },
     "c5c49a4b3d084e9b89acad5abcf1336c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2c34db9948be4e6189fbaa037e39d353",
       "max": 4967,
       "style": "IPY_MODEL_28caa364fd7e4a9f9ed2ee3e08cfc438",
       "value": 4967
      }
     },
     "c8df7df58c6a40328bce1c52137090af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_12ecfcbfa28343929fb696c4a40cb052",
       "style": "IPY_MODEL_e964fbf0e28544179f1fd0fc2f201840",
       "value": " 552/552 [00:00&lt;00:00, 2543.59ex/s]"
      }
     },
     "ca97d517044e4c9c8fca2d29b0570358": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cab32fc3db204e1caf2f4612f1c90fc3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1d8c110dd6974ce9bfacda91de2503ff",
       "style": "IPY_MODEL_79f001d5040244f9874013c11bf73528",
       "value": "100%"
      }
     },
     "cc0ff0af3aef4440b1fcde2a1c5db921": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ce8da77eb3064bc686e77bd86a3663fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_759c1fde832f4a86acc2669fa9c77110",
        "IPY_MODEL_f2f7fd6a05d740fe8e831467fafdd063",
        "IPY_MODEL_2d2aa8512d634d50a7b27328c9457c01"
       ],
       "layout": "IPY_MODEL_f2dac6ee05a844d3a3539866040be63b"
      }
     },
     "d49171bb6d1049ed9a5eb1e81d160218": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d92262eb5d86406b823762b71043dad2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9f7ee58a4a6041808949a5af4a9667dc",
       "max": 552,
       "style": "IPY_MODEL_3cd912a828ed47b78218c4f62a634a56",
       "value": 552
      }
     },
     "e08b65aee463405ba32c0f2d3f574f5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e2be5492304a4f4393bcc8824520e3a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e307d9088ccb46a48d9e91726009824e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e964fbf0e28544179f1fd0fc2f201840": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e99390fc96424f2bbe45d31bb27253ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9a20e0e096fd47e2ab759a8d5a047ecb",
       "max": 4967,
       "style": "IPY_MODEL_850eb2b76745466fa1f9e18b7ae51330",
       "value": 4967
      }
     },
     "e9b0346c25e143dc9e7d2eccc1f7bab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_88e579de85ca40ad8d1f440bed56e8fa",
       "style": "IPY_MODEL_4c486ba77902469abb447c5a3ad19688",
       "value": "100%"
      }
     },
     "eb4a1a21fa2f45f5b9171550b4317f5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ebdde0e58f8446808938193c783aef3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ec4556fd529045e5a85fc42dce1bcfe6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_70466dc5c2f344208d6bcc4ef3804771",
        "IPY_MODEL_37c1f92f573b46daad2b9d397144a2de",
        "IPY_MODEL_930b09044c6447c9ac4660ba78621cf6"
       ],
       "layout": "IPY_MODEL_60f588dfdf974d2eb25262bfc36ae031"
      }
     },
     "ed40755bf2364e00a8e362addab06e5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_25c58e59a25d4932845f4bee6ecdda31",
        "IPY_MODEL_635a476747084be5a203dda619169b92",
        "IPY_MODEL_30edd17af89c42fd9875bd9fff5fa40a"
       ],
       "layout": "IPY_MODEL_fcbe655ae6c9419fa7481b7fc4531447"
      }
     },
     "f13a6cc17e6a4948b782a8d5db2d8cd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f1e17278387b433ab57e4157629c8cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cc0ff0af3aef4440b1fcde2a1c5db921",
       "max": 552,
       "style": "IPY_MODEL_2c493dfbf0844c8cbf2ecce410f3aff7",
       "value": 552
      }
     },
     "f2dac6ee05a844d3a3539866040be63b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f2f7fd6a05d740fe8e831467fafdd063": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_d49171bb6d1049ed9a5eb1e81d160218",
       "max": 4967,
       "style": "IPY_MODEL_89e0f291c7d54b03bf359b44c96b12ca",
       "value": 4967
      }
     },
     "f7ffe86b31194dc0898142af6642a442": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f86b3fee1620497eb81d3360a389efd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_20e616d395f440b5a5e980ac8ddbef4d",
       "style": "IPY_MODEL_21b0dbe462844ec9bf717468fb8b8e01",
       "value": "100%"
      }
     },
     "f96dc8097b594dca8183872ed6f3bef3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fcbe655ae6c9419fa7481b7fc4531447": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fed22b11b0c44ac7be09054550a12e48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ff985e6ebb554c3eac18abe05922a821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
