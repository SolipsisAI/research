{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc19e10-b8f3-4b0e-8e0e-6a3d74c79d82",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT\n",
    "\n",
    "https://www.modeldifferently.com/en/2021/12/generaci%C3%B3n-de-fake-news-con-gpt-2/#data-loading-and-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5342b571-99e6-4257-9052-9a2eeb9db178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50890486-20bc-4265-b21b-2bc52142159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from datasets import Dataset, list_metrics, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d1459b-99ae-4d54-ae62-1ff1f60666ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"gpt2\"\n",
    "#model_cls = GPT2LMHeadModel\n",
    "#tokenizer_cls = GPT2Tokenizer\n",
    "\n",
    "MODEL_NAME = \"microsoft/DialoGPT-small\"\n",
    "model_cls = AutoModelForCausalLM\n",
    "tokenizer_cls = AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1722bf0b-9462-4fbe-a369-ab4e3ac13c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    cuda: True\n",
      "    current_device: 0\n",
      "    device_count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev) \n",
    "\n",
    "print(f\"\"\"\n",
    "    cuda: {torch.cuda.is_available()}\n",
    "    current_device: {torch.cuda.current_device()}\n",
    "    device_count: {torch.cuda.device_count()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6c3ca9-76aa-4338-bdee-d444467cee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e5c7d-99cd-4fb0-b92c-c06fc8d31739",
   "metadata": {},
   "source": [
    "## Load Data, Tokenizer, and Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae2ca3-2502-4c89-b8f7-d2438099d78b",
   "metadata": {},
   "source": [
    "### Data Loading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6348c3-7b02-48e6-bd03-8b54763c722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32080</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32081</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Right. Geeze. I...did not expect to ever hear from him again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32082</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>...Surprise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um...sure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_as she talks she takes the book off the table and carefully tucks it away in her bag_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um, yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32088</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Tomorrow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32089</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_she will leave with the others_]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "32080  Charlotte   \n",
       "32081       Toby   \n",
       "32082  Charlotte   \n",
       "32083  Charlotte   \n",
       "32084       Toby   \n",
       "32085  Charlotte   \n",
       "32086  Charlotte   \n",
       "32087       Toby   \n",
       "32088       Toby   \n",
       "32089  Charlotte   \n",
       "\n",
       "                                                                                                                              text  \n",
       "32080                                   What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.  \n",
       "32081                                                                Right. Geeze. I...did not expect to ever hear from him again.  \n",
       "32082                                                                                                                 ...Surprise?  \n",
       "32083  So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.  \n",
       "32084                                                                                                                   Um...sure.  \n",
       "32085                                                         Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?  \n",
       "32086                                     [_as she talks she takes the book off the table and carefully tucks it away in her bag_]  \n",
       "32087                                                                                                                    Um, yeah.  \n",
       "32088                                                                                                                    Tomorrow.  \n",
       "32089                                                                                           [_she will leave with the others_]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../data/processed.csv\"\n",
    "df = pd.read_csv(filepath, encoding=\"utf-8\", usecols=[\"character\", \"content\"]).rename(columns={\"content\": \"text\"})\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f9585-6e12-4bf1-990f-40aeb39f5952",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b09bb6c-1983-4e87-b805-3dab99ae9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model_cls.from_pretrained(MODEL_NAME, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "502b3b5d-d0b6-47f9-9424-a0a646a95ba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ModuleUtilsMixin.num_parameters of GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d0c2b-1055-47bd-97dd-ba5c7a91aad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e23c7b-052d-411c-ac45-66bfcf9540f0",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ff1d2c-2dfd-4f29-939e-bf4f299a3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = tokenizer_cls.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138c94af-7007-4dbb-afe4-59eeeb05d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab_size: {base_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd8a188-dff8-478d-abf7-289d564575cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbfce691-d927-41cd-95bd-db815dfb6c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17250"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = base_tokenizer.get_vocab()\n",
    "vocabulary[\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec35b380-12ca-4328-b383-bfa391cc2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce9e4984-f7dd-4a15-8363-a09aa557a8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2753c1-7f96-4d54-93d7-9734f52215f1",
   "metadata": {},
   "source": [
    "## Conversational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef9899-32f8-4f89-8917-53db3c6f6155",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "643ea45d-7857-496d-8a2e-595ef714b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "from typing import Dict, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    data_or_filename: Union[str, pd.DataFrame],\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "    test_size: float = 0.1,\n",
    "    flatten: bool = True,\n",
    "):\n",
    "    data = load_csv(data_or_filename) if isinstance(data_or_filename, str) else data_or_filename\n",
    "\n",
    "    contexted_data = prepare_context(\n",
    "        data,\n",
    "        filter_by=filter_by,\n",
    "        filter_value=filter_value,\n",
    "        content_key=content_key,\n",
    "        n=n,\n",
    "    )\n",
    "\n",
    "    trn_df, val_df = train_test_split(contexted_data, test_size=test_size, shuffle=False)\n",
    "    \n",
    "    return trn_df, val_df\n",
    "\n",
    "\n",
    "def prepare_context(\n",
    "    data: pd.DataFrame,\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "    flatten: bool = True,\n",
    "    eos_token: str = \"<|endoftext|>\",\n",
    "):\n",
    "    if filter_by:\n",
    "        indexes = data.loc[data[filter_by] == filter_value].index\n",
    "        for idx, i in enumerate(indexes):\n",
    "            if i > n:\n",
    "                break\n",
    "        indexes = indexes[idx:]\n",
    "    else:\n",
    "        indexes = range(n, len(data[content_key]))\n",
    "        \n",
    "    contexted = []\n",
    "\n",
    "    for i in indexes:\n",
    "        row = []\n",
    "        prev = i - 1 - n\n",
    "        for j in range(i, prev, -1):\n",
    "            row.append(data.iloc[j][content_key])\n",
    "        contexted.append(row)\n",
    "            \n",
    "    columns = [\"response\", \"context\"]\n",
    "    columns = columns + [\"context/\" + str(i) for i in range(n - 1)]\n",
    "\n",
    "    print(columns)\n",
    "    df = pd.DataFrame.from_records(contexted, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    columns = [col for col in df] \n",
    "    dataset = Dataset.from_pandas(concat_text(df))\n",
    "    dataset = dataset.remove_columns(columns + ['__index_level_0__'])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def concat_text(df):\n",
    "    df[\"text\"] = df.apply(concat_text_in_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def concat_text_in_row(row, eos_token):\n",
    "    concat_text = f\"{eos_token}\".join(row)\n",
    "    # Add to end\n",
    "    concat_text += eos_token\n",
    "    print(concat_text)\n",
    "    return concat_text\n",
    "\n",
    "\n",
    "def construct_conv(example, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example]))\n",
    "    print(f\"Conv Length: {len(conv)}\") \n",
    "    print(set(list(map(len, conv))))\n",
    "    conv = flatten(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e7b3ccf-e3ab-4c2f-a38e-1c3384db0222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31b401d3-929a-488e-b915-cb79e8a15cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[*Charlotte immediately becomes very, very tense*]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     character                                                text\n",
       "862  Charlotte  [*Charlotte immediately becomes very, very tense*]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"text\"] == \"[*Charlotte immediately becomes very, very tense*]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "979578fa-8f76-4862-bb0b-ac30b18b21b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>...Do you...want to talk about it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>No. I'm fine. We need to make sure you're..okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[*makes a face again*] I'm _really_ sorry for just...falling apart like that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>(( 🤦🏽 ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>no you shouldn't be sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>it happens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>do you..take anything for that? to help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[*Charlotte immediately becomes very, very tense*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>Oh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>Description</td>\n",
       "      <td>_[Nix tenses from the corner, but does not end her phone call or move back over]_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>There are...complications...with that. And I _really_ prefer not to talk about it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>_nods_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[*relaxes a bit, but is still clearly more on-edge than she was before*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>(( 🤦🏽 ))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>(( you found charlotte's Trauma Button!))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>I should..probably go. If you need anything my commlink is..always open. Uhm, hope you'll be okay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "855    Charlotte   \n",
       "856    bitjockey   \n",
       "857    Charlotte   \n",
       "858    bitjockey   \n",
       "859    bitjockey   \n",
       "860    bitjockey   \n",
       "861    bitjockey   \n",
       "862    Charlotte   \n",
       "863    Charlotte   \n",
       "864    bitjockey   \n",
       "865  Description   \n",
       "866    Charlotte   \n",
       "867    bitjockey   \n",
       "868    Charlotte   \n",
       "869    bitjockey   \n",
       "870    Charlotte   \n",
       "871    bitjockey   \n",
       "\n",
       "                                                                                                  text  \n",
       "855                                                                 ...Do you...want to talk about it?  \n",
       "856                                                    No. I'm fine. We need to make sure you're..okay  \n",
       "857                       [*makes a face again*] I'm _really_ sorry for just...falling apart like that  \n",
       "858                                                                                           (( 🤦🏽 ))  \n",
       "859                                                                          no you shouldn't be sorry  \n",
       "860                                                                                         it happens  \n",
       "861                                                           do you..take anything for that? to help?  \n",
       "862                                                 [*Charlotte immediately becomes very, very tense*]  \n",
       "863                                                                                                No.  \n",
       "864                                                                                                Oh.  \n",
       "865                  _[Nix tenses from the corner, but does not end her phone call or move back over]_  \n",
       "866                 There are...complications...with that. And I _really_ prefer not to talk about it.  \n",
       "867                                                                                             _nods_  \n",
       "868                           [*relaxes a bit, but is still clearly more on-edge than she was before*]  \n",
       "869                                                                                           (( 🤦🏽 ))  \n",
       "870                                                          (( you found charlotte's Trauma Button!))  \n",
       "871  I should..probably go. If you need anything my commlink is..always open. Uhm, hope you'll be okay  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[862-7:862+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ce5db7f6-8486-4b76-a76f-63559628fa4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5']\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = prepare_data(df, filter_by=\"character\", filter_value=\"Charlotte\", flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80d9e8e2-818e-40b9-9881-1654803aaf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>[*Charlotte immediately becomes very, very tense*]</td>\n",
       "      <td>do you..take anything for that? to help?</td>\n",
       "      <td>it happens</td>\n",
       "      <td>no you shouldn't be sorry</td>\n",
       "      <td>(( 🤦🏽 ))</td>\n",
       "      <td>[*makes a face again*] I'm _really_ sorry for just...falling apart like that</td>\n",
       "      <td>No. I'm fine. We need to make sure you're..okay</td>\n",
       "      <td>...Do you...want to talk about it?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               response  \\\n",
       "344  [*Charlotte immediately becomes very, very tense*]   \n",
       "\n",
       "                                      context   context/0  \\\n",
       "344  do you..take anything for that? to help?  it happens   \n",
       "\n",
       "                     context/1 context/2  \\\n",
       "344  no you shouldn't be sorry  (( 🤦🏽 ))   \n",
       "\n",
       "                                                                        context/3  \\\n",
       "344  [*makes a face again*] I'm _really_ sorry for just...falling apart like that   \n",
       "\n",
       "                                           context/4  \\\n",
       "344  No. I'm fine. We need to make sure you're..okay   \n",
       "\n",
       "                              context/5  \n",
       "344  ...Do you...want to talk about it?  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df[\"response\"] == \"[*Charlotte immediately becomes very, very tense*]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c2cb1f-f5e1-4b95-9436-2b06ac7b981f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24214</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>Uhm, well. I need a refresher? I think?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character                                     text\n",
       "24214  bitjockey  Uhm, well. I need a refresher? I think?"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"text\"] == \"Uhm, well. I need a refresher? I think?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e70fe161-ffe6-40a0-beba-baeb7e88d48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24214</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>Uhm, well. I need a refresher? I think?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24215</th>\n",
       "      <td>Akari</td>\n",
       "      <td>Right.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24216</th>\n",
       "      <td>Description</td>\n",
       "      <td>[_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24217</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_nods_] Right, right...so..how can I help?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24218</th>\n",
       "      <td>Akari</td>\n",
       "      <td>[_thinking_] I remember you being more interested in the practical than the theory. Is that still true?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24219</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_nods_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24220</th>\n",
       "      <td>Akari</td>\n",
       "      <td>I asked Shiro herself with some help on the chemistry and math, and I've got computer simulations running to try out some possible behavior and designs. But I'm still in need of help with actually moving it out of the theoretical. [_shakes head_] I need a proof-of-concept.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24221</th>\n",
       "      <td>Akari</td>\n",
       "      <td>How far into biomemetics are you willing to go for robots?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24222</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>What do you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24223</th>\n",
       "      <td>Akari</td>\n",
       "      <td>I suppose that's a bad way of wording it, considering who I'm talking to. [_shakes head_] How small are you able to go in building robots? Because I'm not sure if we're going to end up taking biomemetics to the cellular level here. But I know I need an excellent roboticist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24224</th>\n",
       "      <td>Akari</td>\n",
       "      <td>I _could_ build a proof of concept by myself, but I don't know if I could do it in time. And, well...this isn't exactly something I want to fuck up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24225</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>I can help with that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24226</th>\n",
       "      <td>Akari</td>\n",
       "      <td>I was hoping you'd say that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24227</th>\n",
       "      <td>Akari</td>\n",
       "      <td>...was that just what you wanted to talk about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24228</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>Uhm...yes. I was wondering if we could have dinner together? All of us? Maybe soon?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24229</th>\n",
       "      <td>Akari</td>\n",
       "      <td>I don't see why not. Did you want to have the others over as well, or just the 3 of us?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24230</th>\n",
       "      <td>Description</td>\n",
       "      <td>[_Meanwhile, back in the common room..._]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24231</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Nix said kinda the same thing, and it's not like she's _never_ gone out of town for a job without letting me know first, but...[*she trails off*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24232</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>\"But...\"?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24233</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>We sort of...had an argument, last time we talked?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24234</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>...oh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24235</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>So...the brain weasels are gnawing on that bit, huh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24236</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>...That's a way to put it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24237</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>Blame Arcade.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24238</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>But I think it gets the idea across.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24239</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>I don't know if she's in the middle of doing something dangerous and I should be _worried_, or if she just...doesn't want to talk to me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24240</th>\n",
       "      <td>Omnilord</td>\n",
       "      <td>[_interjects kinda rudely because he only half heard it..._] Brain weasels sounds like an episode of X-Files.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24241</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>[_blinks_] The what now?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24242</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>I--wait, what?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24243</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>...anyway.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24244</th>\n",
       "      <td>Omnilord</td>\n",
       "      <td>Brain...weasels...wait, are you talking about sci-fi shows, or... [_looks really guilty_] never mind.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24245</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>It's all right, Collateral. I just stared at Arcade blankly the first time he said it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24246</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>[_to Charlotte_] Could be that she just can't be distracted at the moment. Not because it's dangerous. Or that she's just not going to know her schedule so she _doesn't_ want you to worry if she can't reach her comm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24247</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>[_rueful look_] Doesn't really _feel_ any better from where we're sitting, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24248</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[*charlotte looks Unconvinced*]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24249</th>\n",
       "      <td>Amarok</td>\n",
       "      <td>...is your sister the type to go cold shoulder?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         character  \\\n",
       "24214    bitjockey   \n",
       "24215        Akari   \n",
       "24216  Description   \n",
       "24217    bitjockey   \n",
       "24218        Akari   \n",
       "24219    bitjockey   \n",
       "24220        Akari   \n",
       "24221        Akari   \n",
       "24222    bitjockey   \n",
       "24223        Akari   \n",
       "24224        Akari   \n",
       "24225    bitjockey   \n",
       "24226        Akari   \n",
       "24227        Akari   \n",
       "24228    bitjockey   \n",
       "24229        Akari   \n",
       "24230  Description   \n",
       "24231    Charlotte   \n",
       "24232       Amarok   \n",
       "24233    Charlotte   \n",
       "24234       Amarok   \n",
       "24235       Amarok   \n",
       "24236    Charlotte   \n",
       "24237       Amarok   \n",
       "24238       Amarok   \n",
       "24239    Charlotte   \n",
       "24240     Omnilord   \n",
       "24241       Amarok   \n",
       "24242    Charlotte   \n",
       "24243       Amarok   \n",
       "24244     Omnilord   \n",
       "24245       Amarok   \n",
       "24246       Amarok   \n",
       "24247       Amarok   \n",
       "24248    Charlotte   \n",
       "24249       Amarok   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "24214                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Uhm, well. I need a refresher? I think?  \n",
       "24215                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Right.  \n",
       "24216  [_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]  \n",
       "24217                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [_nods_] Right, right...so..how can I help?  \n",
       "24218                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [_thinking_] I remember you being more interested in the practical than the theory. Is that still true?  \n",
       "24219                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [_nods_]  \n",
       "24220                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    I asked Shiro herself with some help on the chemistry and math, and I've got computer simulations running to try out some possible behavior and designs. But I'm still in need of help with actually moving it out of the theoretical. [_shakes head_] I need a proof-of-concept.  \n",
       "24221                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           How far into biomemetics are you willing to go for robots?  \n",
       "24222                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    What do you mean?  \n",
       "24223                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I suppose that's a bad way of wording it, considering who I'm talking to. [_shakes head_] How small are you able to go in building robots? Because I'm not sure if we're going to end up taking biomemetics to the cellular level here. But I know I need an excellent roboticist.  \n",
       "24224                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 I _could_ build a proof of concept by myself, but I don't know if I could do it in time. And, well...this isn't exactly something I want to fuck up.  \n",
       "24225                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                I can help with that.  \n",
       "24226                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         I was hoping you'd say that.  \n",
       "24227                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...was that just what you wanted to talk about?  \n",
       "24228                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Uhm...yes. I was wondering if we could have dinner together? All of us? Maybe soon?  \n",
       "24229                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I don't see why not. Did you want to have the others over as well, or just the 3 of us?  \n",
       "24230                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [_Meanwhile, back in the common room..._]  \n",
       "24231                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Nix said kinda the same thing, and it's not like she's _never_ gone out of town for a job without letting me know first, but...[*she trails off*]  \n",
       "24232                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \"But...\"?  \n",
       "24233                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   We sort of...had an argument, last time we talked?  \n",
       "24234                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...oh.  \n",
       "24235                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 So...the brain weasels are gnawing on that bit, huh.  \n",
       "24236                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...That's a way to put it  \n",
       "24237                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Blame Arcade.  \n",
       "24238                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 But I think it gets the idea across.  \n",
       "24239                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              I don't know if she's in the middle of doing something dangerous and I should be _worried_, or if she just...doesn't want to talk to me  \n",
       "24240                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [_interjects kinda rudely because he only half heard it..._] Brain weasels sounds like an episode of X-Files.  \n",
       "24241                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [_blinks_] The what now?  \n",
       "24242                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       I--wait, what?  \n",
       "24243                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           ...anyway.  \n",
       "24244                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Brain...weasels...wait, are you talking about sci-fi shows, or... [_looks really guilty_] never mind.  \n",
       "24245                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               It's all right, Collateral. I just stared at Arcade blankly the first time he said it.  \n",
       "24246                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [_to Charlotte_] Could be that she just can't be distracted at the moment. Not because it's dangerous. Or that she's just not going to know her schedule so she _doesn't_ want you to worry if she can't reach her comm.  \n",
       "24247                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [_rueful look_] Doesn't really _feel_ any better from where we're sitting, but...  \n",
       "24248                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [*charlotte looks Unconvinced*]  \n",
       "24249                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...is your sister the type to go cold shoulder?  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[24214:24250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc165239-6ec7-43f9-b981-772f8783d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "450f2318-9c52-403a-b5a8-8d15b75078ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenizer):\n",
    "    def _tokenize(example):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example if \"__index\" not in x]))\n",
    "        conv = flatten(conv)\n",
    "        return conv\n",
    "        \n",
    "    def _preprocess(examples):\n",
    "        #flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "        #conv = list([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in examples])\n",
    "        #conv = flatten(conv)\n",
    "        #return {\"input_ids\": conv}\n",
    "        return {\"input_ids\": list(map(_tokenize, examples))}\n",
    "    \n",
    "    return _preprocess\n",
    "\n",
    "\n",
    "def tokenize(example):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example]))\n",
    "    print(f\"Conv Length: {len(conv)}\") \n",
    "    print(set(list(map(len, conv))))\n",
    "    conv = flatten(conv)\n",
    "    return conv\n",
    "\n",
    "\n",
    "def debug_preprocess(tokenizer, max_length=250): \n",
    "    def _tokenize(examples):\n",
    "        input_ids = [tokenizer.encode(v, padding=\"max_length\", max_length=250) for k, v in examples.items() if isinstance(v, str)]\n",
    "        examples[\"input_ids\"] = input_ids\n",
    "        return examples\n",
    "    return _tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bcc0914-a207-4d1c-9a9a-6634a2e6517c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 4967\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4c2c91b-70c9-456b-8ca5-63bbe748e289",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 552\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a7fc9a-668f-4382-88bf-f816e8ae0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def preprocess_conv(tokenizer):\n",
    "    def _construct(examples):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "        conv = list(reversed([tokenizer.encode(v) + [tokenizer.eos_token_id] for k,v in examples.items() if isinstance(v, str)]))\n",
    "        conv = flatten(conv)\n",
    "        examples[\"input_ids\"] = conv\n",
    "        return examples \n",
    "    return _construct\n",
    "\n",
    "\n",
    "def preprocess_function(tokenizer, max_length=512):\n",
    "    def _construct(examples):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "        concat_text = f\"{tokenizer.eos_token}\".join(reversed([v for _, v in examples.items() if isinstance(v, str)]))\n",
    "        concat_text = concat_text + tokenizer.eos_token\n",
    "        tokenized = tokenizer(concat_text, padding=\"max_length\",  max_length=max_length)\n",
    "        examples[\"input_ids\"] = tokenized[\"input_ids\"]\n",
    "        examples[\"attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "        return examples\n",
    "        \n",
    "    return _construct\n",
    "\n",
    "\n",
    "def collate(examples: List[torch.Tensor], tokenizer):\n",
    "    if tokenizer._pad_token is None:\n",
    "        return pad_sequence(examples, batch_first=True)\n",
    "    return pad_sequence(\n",
    "        examples, batch_first=True, padding_value=tokenizer.pad_token_id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dd1f4b2-6f33-4fb0-85c7-6a8347b25018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='microsoft/DialoGPT-small', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d53884-df1c-42d0-8a32-648afca98ae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bc92872a5345028d28083f5c7811a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4967 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c20e3a818542e28b85516a65489638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(train_dataset.features.keys()))\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(val_dataset.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcd83ed6-3fac-447a-bd65-2a8c56397b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 [_will follow Hopper_]<|endoftext|>[_once they reach Anton and Arcade_] Hello<|endoftext|>[_to Anton_] This is my mo--mentor, Akari.<|endoftext|>[_shakes hands_] Nice to meet you.<|endoftext|>[_noticed the slip, hides a smile_]<|endoftext|>[_laughs nervously_] Uhm, so Anton. You are a decker, right?<|endoftext|>That's right<|endoftext|>I hear this is where the tech talk is happening.<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 [gives you a weird look] Yeah?<|endoftext|>You know if, um, if there's something wrong with the washer in your building then I'm sure my parents wouldn't mind you using theirs for a bit.<|endoftext|>[goes quiet for a bit, looks shocked like she realized something, and just looks both sad and embarrassed at the same time]<|endoftext|>Oh. _Right_<|endoftext|>Or, I mean have you considered--apartment hunting, maybe? We're getting some good jobs, so. Maybe time to consider an upgrade?...Uh, not that there's anything _wrong_ with....yours.....<|endoftext|>[Doesn’t respond; looks at the floor; shuffles foot]<|endoftext|>[softly] yeah<|endoftext|>It’s [sighs, as per usual] not ideal<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 \"Blue...shit\"...?<|endoftext|>[_sighs_] What my ass..[_glares at Kalahan for a second_] ociate here means is..<|endoftext|>There was a vial containing a blue drug stolen from the Pyrausta office.<|endoftext|>I wasn't aware that Pyrausta had released _any_ drug.<|endoftext|>They haven't<|endoftext|>So an experimental sample of...something.<|endoftext|>Not publicly...<|endoftext|>Right. It had some _interesting_ side effects.<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 I was just...saying that I'm trying. To get [_waves hand around_] all this.<|endoftext|>Ah, yeah. It's a lot. Like, a _lot_, a lot.<|endoftext|>[_quietly_]  It is quite a lot.<|endoftext|>It's an adjustment. I suppose fro everyone here in this room right now especially.<|endoftext|>Yeah.<|endoftext|>And I...well, I know I'm having a hard time.<|endoftext|>Which is fair, considering<|endoftext|>[_nods_] That is.<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 then what's with the fucking Therapist Speak?<|endoftext|>What do you mean?<|endoftext|>you know exactly what i mean<|endoftext|>No<|endoftext|>ok, seriously. what's going on<|endoftext|>Nothing. Everything's fine.<|endoftext|>it doesn't _seem_ fine<|endoftext|>Trust me<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 Oh, that'd be nice, thanks.<|endoftext|>Although I should probably make some more. It's...gonna be a long night.<|endoftext|>[_Tachyon takes the teapot and goes into the kitchen_]<|endoftext|>What can we do to help...<|endoftext|>I...don't know. I just...this is probably why Cobalt asked Tachyon to stay close by.<|endoftext|>[_looks at hopper_] not a think until we find out some skulls need crushing to help Shiro get home.<|endoftext|>I see.<|endoftext|>And we don't know the last place she was at? Approximate coordinates?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 But...he went in the wrong direction.<|endoftext|>He wasn't looking. He just...ran out onto Memorial Drive.<|endoftext|>The driver had no way to stop in time.<|endoftext|>[_quietly_] Shit.<|endoftext|>*Softly curses in Maōri again.*<|endoftext|>[_closes her eyes_]<|endoftext|>*Kalahan growls.*<|endoftext|>[_softly_] And your parents? They blamed you for something you couldn't possibly predict?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 What do you need me to do?<|endoftext|>Any particular kind?<|endoftext|>[_looks at Collateral_] Uh, hold on.<|endoftext|>[_texts Charlotte_] What kind of tea do you like?<|endoftext|>...and...are you up for meeting one more person at the moment?<|endoftext|>[*texts*] hrbl no caf<|endoftext|>Collateral, could you...ask Kalahan to come back over here?<|endoftext|>Actually. [_texts @Kalahan _] no caffeine, herbal<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 I mean, there's the physical things, like her impossible hair or her hands and all that.<|endoftext|>But...that I can have all of her attention. That she's safety and has my back always.<|endoftext|>And then there's the little things. Like how she always lets Cafall tackle her. Or hates artificial strawberry flavor.<|endoftext|>I..I don't know. I just...do.<|endoftext|>[_Shiro's ears have gone a little red._]<|endoftext|>[_Shiro closes her eyes, bows her head so her forehead is touching Amarok's hair, and sighs._]<|endoftext|>She...makes me feel human again.<|endoftext|>[_smiles_] I can see that<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
      "256 she knows nix??<|endoftext|>yes<|endoftext|>o<|endoftext|>thats wat u meant by \"know the same people\"<|endoftext|>is nix..friends w this person?<|endoftext|>....something like that<|endoftext|>.......<|endoftext|>k<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    decoded = base_tokenizer.decode(tokenized_train_dataset[i][\"input_ids\"])\n",
    "    print(len(tokenized_train_dataset[i][\"input_ids\"]), decoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68930df4-c807-418a-ba40-9db502d9daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 4967\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bf184bd-0785-4853-ac2e-aef373830e05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "tokenized_val_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d05942e-528c-4b02-b8d3-085a99a10951",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee5835-da48-468b-b2af-45d407d9a8c9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52d02923-9740-413b-ba81-c46597c56423",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"perplexity\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2313d34-3806-4d23-a40a-495d36c084e2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc4fb8f8-39eb-45f9-a9a0-25575af5e5f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.resize_token_embeddings(len(base_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52086282-7820-4e5f-91b3-549529ed7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = 'SP-05162022a-myDialoGPT2-small'\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=base_tokenizer,\n",
    "    mlm=False,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "trainer = None\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=FINETUNED_MODEL,          # output directory\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,           # total # of training epochs\n",
    "    per_device_train_batch_size=3,  # batch size per device during training\n",
    "    per_device_eval_batch_size=3,   # batch size for evaluation\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    logging_dir=FINETUNED_MODEL,            # directory for storing logs\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e9eab83-e5f6-4da7-8d90-69d808da13c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "985db8b4-0d4d-4c9b-a96c-a712c4c1ebf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4967\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 3\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 3\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4968' max='4968' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4968/4968 14:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.185300</td>\n",
       "      <td>2.858918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.789500</td>\n",
       "      <td>2.627786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.598600</td>\n",
       "      <td>2.557067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-500\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "4.1728\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.496779388083736e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-1000\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.3785\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.993558776167472e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-1500\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.1853\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.490338164251208e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 552\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "2.8589184284210205\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "8.4877\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "65.036\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "21.679\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-2000\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.9583\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.9871175523349438e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-2500\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.8546\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.4838969404186795e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-3000\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.7895\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.9806763285024154e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-3000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 552\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "2.62778639793396\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "8.5124\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "64.846\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "21.615\n",
      "Attempted to log scalar metric epoch:\n",
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-3500\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.6801\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.4774557165861514e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-4000\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.6111\n",
      "Attempted to log scalar metric learning_rate:\n",
      "9.742351046698874e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small/checkpoint-4500\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.5986\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.710144927536232e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in SP-05162022a-myDialoGPT2-small/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 552\n",
      "  Batch size = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "2.5570669174194336\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "8.5078\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "64.882\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "21.627\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric train_runtime:\n",
      "860.1493\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "17.324\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "5.776\n",
      "Attempted to log scalar metric total_flos:\n",
      "1980352723968000.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "2.982759656921485\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4968, training_loss=2.982759656921485, metrics={'train_runtime': 860.1493, 'train_samples_per_second': 17.324, 'train_steps_per_second': 5.776, 'total_flos': 1980352723968000.0, 'train_loss': 2.982759656921485, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0a77399-5118-458b-8147-54139ede96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to SP-05162022a-myDialoGPT2-small\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/config.json\n",
      "Model weights saved in SP-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "tokenizer config file saved in SP-05162022a-myDialoGPT2-small/tokenizer_config.json\n",
      "Special tokens file saved in SP-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "Configuration saved in SP-05162022a-myDialoGPT2-small/config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(FINETUNED_MODEL)\n",
    "base_tokenizer.save_pretrained(FINETUNED_MODEL)\n",
    "config.save_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "490541df-a595-4c80-8e5c-9b8ff66a9c39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file SP-05162022a-myDialoGPT2-small/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"SP-05162022a-myDialoGPT2-small\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"conversational\": {\n",
      "      \"max_length\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50258\n",
      "}\n",
      "\n",
      "loading weights file SP-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at SP-05162022a-myDialoGPT2-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading file SP-05162022a-myDialoGPT2-small/vocab.json\n",
      "loading file SP-05162022a-myDialoGPT2-small/merges.txt\n",
      "loading file SP-05162022a-myDialoGPT2-small/tokenizer.json\n",
      "loading file SP-05162022a-myDialoGPT2-small/added_tokens.json\n",
      "loading file SP-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "loading file SP-05162022a-myDialoGPT2-small/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(FINETUNED_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af6daae3-1241-4782-920e-16b5e67933f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, text, chat_history_ids=None, step=0):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.7\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    return response, chat_history_ids, step + 1\n",
    "\n",
    "def chat(model, tokenizer):\n",
    "    step = 0\n",
    "    chat_history_ids = []\n",
    "    \n",
    "    while True: \n",
    "        text = input(\">> \")\n",
    "        if text in [\"/q\", \"/quit\", \"/e\", \"/exit\"]: break\n",
    "        print(f\"User: {text}\")\n",
    "        response, chat_history_ids, step = generate_responses(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            text=text,\n",
    "            chat_history_ids=chat_history_ids,\n",
    "            step=step\n",
    "        )\n",
    "        print(f\"Bot: {response}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e12e5dce-153c-46be-80b7-f29db173c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hello?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello?\n",
      "Bot: *Kalahan is in a really awkward spot in the living room with Lauren.*\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  what's going on\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: what's going on\n",
      "Bot: *He's been standing there for a few minutes, his arms crossed, but he's still not sure if he should be standing or sitting.*\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Are you okay?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Are you okay?\n",
      "Bot: ...No.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What happened?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What happened?\n",
      "Bot: It's..it's been a rough day.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Has it?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Has it?\n",
      "Bot: [_nods_]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  /quit\n"
     ]
    }
   ],
   "source": [
    "chat(finetuned_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e6352-e9a2-4bfd-a05f-8ea1beec58fd",
   "metadata": {},
   "source": [
    "## Re-do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbfe9c9a-2d91-421e-b3ce-74cece0cf3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response                                                    [_looks concerned_] ..what do you mean?\n",
       "context                                                     Now...I think...it was the same as you.\n",
       "context/0                         I...remember much...of it. I...lose sense of time...near the end.\n",
       "context/1                                                                       It is...unpleasant.\n",
       "context/2                                                                                  [_nods_]\n",
       "context/3                                                                  ...perhaps...it is time.\n",
       "context/4    [_smiles weakly_] I thought...with everything that..you might want to talk to someone.\n",
       "context/5                                                                ...is that...why you came?\n",
       "Name: 3466, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44b06ee5-ab76-40b9-af9f-665db0b3b1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character                                     text\n",
       "14345  bitjockey  [_looks concerned_] ..what do you mean?"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"text\"] == \"[_looks concerned_] ..what do you mean?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1a5d749-d467-47cd-9e97-6127a5838ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14346</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>[_sighs_] They tried to...program me, I suppose. Simsense. Simulations. Drugs, I think.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>I...remember the tank. But...near the end...things are chaotic. The memories...slip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_stiffens_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>So there are...gaps too? In your memory?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>At that point...yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>I...some are there but...I can't...hold onto them.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "14345  bitjockey   \n",
       "14346      Shiro   \n",
       "14347      Shiro   \n",
       "14348  bitjockey   \n",
       "14349  bitjockey   \n",
       "14350      Shiro   \n",
       "14351      Shiro   \n",
       "\n",
       "                                                                                          text  \n",
       "14345                                                  [_looks concerned_] ..what do you mean?  \n",
       "14346  [_sighs_] They tried to...program me, I suppose. Simsense. Simulations. Drugs, I think.  \n",
       "14347     I...remember the tank. But...near the end...things are chaotic. The memories...slip.  \n",
       "14348                                                                             [_stiffens_]  \n",
       "14349                                                 So there are...gaps too? In your memory?  \n",
       "14350                                                                     At that point...yes.  \n",
       "14351                                       I...some are there but...I can't...hold onto them.  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[14345:14352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae90d01a-4d00-4577-b4ae-b0c0d185e6dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hiya\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hiya\n",
      "Bot: So, uh, what's up?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Nothing much. You?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Nothing much. You?\n",
      "Bot: I...just woke up.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  You did?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: You did?\n",
      "Bot: Yeah.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Did you sleep okay?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Did you sleep okay?\n",
      "Bot: You know it sounds like you are going to have a panic attack and start screaming.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What?\n",
      "Bot: _::sits up straighter::_\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How you doing?\n",
      "Bot: Just.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Just?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Just?\n",
      "Bot: About.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I don't know\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I don't know\n",
      "Bot: Did your dad..tell you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  [_shrugs_]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: [_shrugs_]\n",
      "Bot: I was born in '97, so I...had some time to think about it before coming back to this.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How old are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How old are you?\n",
      "Bot: ...I'm not really sure.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  /quit\n"
     ]
    }
   ],
   "source": [
    "chat(finetuned_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8923873-b6dc-4de0-bec1-4793f060e5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "      <td>Now...I think...it was the same as you.</td>\n",
       "      <td>I...remember much...of it. I...lose sense of time...near the end.</td>\n",
       "      <td>It is...unpleasant.</td>\n",
       "      <td>[_nods_]</td>\n",
       "      <td>...perhaps...it is time.</td>\n",
       "      <td>[_smiles weakly_] I thought...with everything that..you might want to talk to someone.</td>\n",
       "      <td>...is that...why you came?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     response  \\\n",
       "3466  [_looks concerned_] ..what do you mean?   \n",
       "\n",
       "                                      context  \\\n",
       "3466  Now...I think...it was the same as you.   \n",
       "\n",
       "                                                              context/0  \\\n",
       "3466  I...remember much...of it. I...lose sense of time...near the end.   \n",
       "\n",
       "                context/1 context/2                 context/3  \\\n",
       "3466  It is...unpleasant.  [_nods_]  ...perhaps...it is time.   \n",
       "\n",
       "                                                                                   context/4  \\\n",
       "3466  [_smiles weakly_] I thought...with everything that..you might want to talk to someone.   \n",
       "\n",
       "                       context/5  \n",
       "3466  ...is that...why you came?  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df[\"response\"] == \"[_looks concerned_] ..what do you mean?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a630dba-39a3-4115-8b46-4030cd94d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '[_looks concerned_] ..what do you mean?',\n",
       " 'context': 'Now...I think...it was the same as you.',\n",
       " 'context/0': 'I...remember much...of it. I...lose sense of time...near the end.',\n",
       " 'context/1': 'It is...unpleasant.',\n",
       " 'context/2': '[_nods_]',\n",
       " 'context/3': '...perhaps...it is time.',\n",
       " 'context/4': '[_smiles weakly_] I thought...with everything that..you might want to talk to someone.',\n",
       " 'context/5': '...is that...why you came?',\n",
       " '__index_level_0__': 3466}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8c67c-5c65-4e8c-9070-a5d13fdcd9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
