{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc19e10-b8f3-4b0e-8e0e-6a3d74c79d82",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT\n",
    "\n",
    "https://www.modeldifferently.com/en/2021/12/generaci%C3%B3n-de-fake-news-con-gpt-2/#data-loading-and-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5342b571-99e6-4257-9052-9a2eeb9db178",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50890486-20bc-4265-b21b-2bc52142159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re, pandas as pd, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM\n",
    ")\n",
    "from datasets import Dataset, list_metrics, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d1459b-99ae-4d54-ae62-1ff1f60666ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"gpt2\"\n",
    "#model_cls = GPT2LMHeadModel\n",
    "#tokenizer_cls = GPT2Tokenizer\n",
    "\n",
    "MODEL_NAME = \"microsoft/DialoGPT-small\"\n",
    "model_cls = AutoModelForCausalLM\n",
    "tokenizer_cls = AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1722bf0b-9462-4fbe-a369-ab4e3ac13c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    cuda: True\n",
      "    current_device: 0\n",
      "    device_count: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev) \n",
    "\n",
    "print(f\"\"\"\n",
    "    cuda: {torch.cuda.is_available()}\n",
    "    current_device: {torch.cuda.current_device()}\n",
    "    device_count: {torch.cuda.device_count()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6c3ca9-76aa-4338-bdee-d444467cee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e5c7d-99cd-4fb0-b92c-c06fc8d31739",
   "metadata": {},
   "source": [
    "## Load Data, Tokenizer, and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8ad0b0c-5ec6-410f-adfa-ba3c1ee3486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../data/empatheticdialogues/train.csv\"\n",
    "df = pd.read_csv(filepath, encoding=\"utf-8\", on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "726c82f8-539c-4fb9-9566-f4a67c79d4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_idx</th>\n",
       "      <th>utterance</th>\n",
       "      <th>selfeval</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>1</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>6</td>\n",
       "      <td>sentimental</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "      <td>5|5|5_2|2|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>1</td>\n",
       "      <td>afraid</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>2</td>\n",
       "      <td>it feels like hitting to blank wall when i se...</td>\n",
       "      <td>4|3|4_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>2</td>\n",
       "      <td>afraid</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>3</td>\n",
       "      <td>Oh ya? I don't really see how</td>\n",
       "      <td>4|3|4_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>3</td>\n",
       "      <td>afraid</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>2</td>\n",
       "      <td>dont you feel so.. its a wonder</td>\n",
       "      <td>4|3|4_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hit:1_conv:2</td>\n",
       "      <td>4</td>\n",
       "      <td>afraid</td>\n",
       "      <td>i used to scare for darkness</td>\n",
       "      <td>3</td>\n",
       "      <td>I do actually hit blank walls a lot of times b...</td>\n",
       "      <td>4|3|4_3|5|5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx      context  \\\n",
       "0  hit:0_conv:1              1  sentimental   \n",
       "1  hit:0_conv:1              2  sentimental   \n",
       "2  hit:0_conv:1              3  sentimental   \n",
       "3  hit:0_conv:1              4  sentimental   \n",
       "4  hit:0_conv:1              5  sentimental   \n",
       "5  hit:0_conv:1              6  sentimental   \n",
       "6  hit:1_conv:2              1       afraid   \n",
       "7  hit:1_conv:2              2       afraid   \n",
       "8  hit:1_conv:2              3       afraid   \n",
       "9  hit:1_conv:2              4       afraid   \n",
       "\n",
       "                                              prompt  speaker_idx  \\\n",
       "0  I remember going to the fireworks with my best...            1   \n",
       "1  I remember going to the fireworks with my best...            0   \n",
       "2  I remember going to the fireworks with my best...            1   \n",
       "3  I remember going to the fireworks with my best...            0   \n",
       "4  I remember going to the fireworks with my best...            1   \n",
       "5  I remember going to the fireworks with my best...            0   \n",
       "6                       i used to scare for darkness            2   \n",
       "7                       i used to scare for darkness            3   \n",
       "8                       i used to scare for darkness            2   \n",
       "9                       i used to scare for darkness            3   \n",
       "\n",
       "                                           utterance     selfeval tags  \n",
       "0  I remember going to see the fireworks with my ...  5|5|5_2|2|5  NaN  \n",
       "1  Was this a friend you were in love with_comma_...  5|5|5_2|2|5  NaN  \n",
       "2                This was a best friend. I miss her.  5|5|5_2|2|5  NaN  \n",
       "3                                Where has she gone?  5|5|5_2|2|5  NaN  \n",
       "4                                 We no longer talk.  5|5|5_2|2|5  NaN  \n",
       "5  Oh was this something that happened because of...  5|5|5_2|2|5  NaN  \n",
       "6   it feels like hitting to blank wall when i se...  4|3|4_3|5|5  NaN  \n",
       "7                      Oh ya? I don't really see how  4|3|4_3|5|5  NaN  \n",
       "8                   dont you feel so.. its a wonder   4|3|4_3|5|5  NaN  \n",
       "9  I do actually hit blank walls a lot of times b...  4|3|4_3|5|5  NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42d3e174-fcaf-4cf0-9edc-b21000c5a181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember going to the fireworks with my best friend. There was a lot of people_comma_ but it only felt like us in the world.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2][\"prompt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7699a15b-8674-467f-8eed-14ab9ab8c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = tokenizer_cls.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5bc4d23-3949-4c1a-ae62-5042989855f0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"context\"] = df[[\"conv_id\", \"prompt\", \"utterance\"]].groupby(\"conv_id\")[\"utterance\"].transform(lambda x: base_tokenizer.eos_token.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ad7f14c-7c82-4dae-80e1-01c2b6717aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people_comma_ we felt like the only people in the world.<|endoftext|>Was this a friend you were in love with_comma_ or just a best friend?<|endoftext|>This was a best friend. I miss her.<|endoftext|>Where has she gone?<|endoftext|>We no longer talk.<|endoftext|>Oh was this something that happened because of an argument?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"context\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae2ca3-2502-4c89-b8f7-d2438099d78b",
   "metadata": {},
   "source": [
    "### Data Loading from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6348c3-7b02-48e6-bd03-8b54763c722a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32080</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32081</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Right. Geeze. I...did not expect to ever hear from him again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32082</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>...Surprise?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um...sure.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_as she talks she takes the book off the table and carefully tucks it away in her bag_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Um, yeah.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32088</th>\n",
       "      <td>Toby</td>\n",
       "      <td>Tomorrow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32089</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>[_she will leave with the others_]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "32080  Charlotte   \n",
       "32081       Toby   \n",
       "32082  Charlotte   \n",
       "32083  Charlotte   \n",
       "32084       Toby   \n",
       "32085  Charlotte   \n",
       "32086  Charlotte   \n",
       "32087       Toby   \n",
       "32088       Toby   \n",
       "32089  Charlotte   \n",
       "\n",
       "                                                                                                                              text  \n",
       "32080                                   What're the odds, right? But yes, we, uh...know each other.  And he's also here in Boston.  \n",
       "32081                                                                Right. Geeze. I...did not expect to ever hear from him again.  \n",
       "32082                                                                                                                 ...Surprise?  \n",
       "32083  So, uh, would you want to talk to him? Because this is all stuff he really should get the chance to ask you about directly.  \n",
       "32084                                                                                                                   Um...sure.  \n",
       "32085                                                         Ok, good. Um, we should probably go. But, uh, I'll see you tomorrow?  \n",
       "32086                                     [_as she talks she takes the book off the table and carefully tucks it away in her bag_]  \n",
       "32087                                                                                                                    Um, yeah.  \n",
       "32088                                                                                                                    Tomorrow.  \n",
       "32089                                                                                           [_she will leave with the others_]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../data/empatheticdialogues/train.csv\"\n",
    "df = pd.read_csv(filepath, encoding=\"utf-8\", usecols=[\"character\", \"content\"]).rename(columns={\"content\": \"text\"})\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f9585-6e12-4bf1-990f-40aeb39f5952",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b09bb6c-1983-4e87-b805-3dab99ae9d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model_cls.from_pretrained(MODEL_NAME, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "502b3b5d-d0b6-47f9-9424-a0a646a95ba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ModuleUtilsMixin.num_parameters of GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.num_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d0c2b-1055-47bd-97dd-ba5c7a91aad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70e23c7b-052d-411c-ac45-66bfcf9540f0",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44ff1d2c-2dfd-4f29-939e-bf4f299a3572",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_tokenizer = tokenizer_cls.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138c94af-7007-4dbb-afe4-59eeeb05d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"vocab_size: {base_tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbfce691-d927-41cd-95bd-db815dfb6c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17250"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = base_tokenizer.get_vocab()\n",
    "vocabulary[\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec35b380-12ca-4328-b383-bfa391cc2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9e4984-f7dd-4a15-8363-a09aa557a8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2753c1-7f96-4d54-93d7-9734f52215f1",
   "metadata": {},
   "source": [
    "## Conversational Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef9899-32f8-4f89-8917-53db3c6f6155",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "643ea45d-7857-496d-8a2e-595ef714b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "from typing import Dict, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def load_csv(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "\n",
    "def prepare_data(\n",
    "    data_or_filename: Union[str, pd.DataFrame],\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "    test_size: float = 0.1,\n",
    "):\n",
    "    data = load_csv(data_or_filename) if isinstance(data_or_filename, str) else data_or_filename\n",
    "\n",
    "    contexted_data = prepare_context(\n",
    "        data,\n",
    "        filter_by=filter_by,\n",
    "        filter_value=filter_value,\n",
    "        content_key=content_key,\n",
    "        n=n,\n",
    "    )\n",
    "\n",
    "    trn_df, val_df = train_test_split(contexted_data, test_size=test_size, shuffle=False)\n",
    "    \n",
    "    return trn_df, val_df\n",
    "\n",
    "\n",
    "def prepare_context(\n",
    "    data: pd.DataFrame,\n",
    "    filter_by: str = None,\n",
    "    filter_value: str = None,\n",
    "    content_key: str = \"text\",\n",
    "    n: int = 7,\n",
    "):\n",
    "    if filter_by:\n",
    "        indexes = data.loc[data[filter_by] == filter_value].index\n",
    "        for idx, i in enumerate(indexes):\n",
    "            if i > n:\n",
    "                break\n",
    "        indexes = indexes[idx:]\n",
    "    else:\n",
    "        indexes = range(n, len(data[content_key]))\n",
    "        \n",
    "    contexted = []\n",
    "\n",
    "    for i in indexes:\n",
    "        row = []\n",
    "        prev = i - 1 - n\n",
    "        for j in range(i, prev, -1):\n",
    "            row.append(data.iloc[j][content_key])\n",
    "        contexted.append(row)\n",
    "            \n",
    "    columns = [\"response\", \"context\"]\n",
    "    columns = columns + [\"context/\" + str(i) for i in range(n - 1)]\n",
    "\n",
    "    print(columns)\n",
    "    df = pd.DataFrame.from_records(contexted, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    columns = [col for col in df] \n",
    "    dataset = Dataset.from_pandas(concat_text(df))\n",
    "    dataset = dataset.remove_columns(columns + ['__index_level_0__'])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def concat_text(df):\n",
    "    df[\"text\"] = df.apply(concat_text_in_row, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def concat_text_in_row(row, eos_token):\n",
    "    concat_text = f\"{eos_token}\".join(row)\n",
    "    # Add to end\n",
    "    concat_text += eos_token\n",
    "    print(concat_text)\n",
    "    return concat_text\n",
    "\n",
    "\n",
    "def construct_conv(example, tokenizer, eos = True):\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    conv = list(reversed([tokenizer.encode(x, padding=\"max_length\", max_length=250) + [tokenizer.eos_token_id] for x in example]))\n",
    "    print(f\"Conv Length: {len(conv)}\") \n",
    "    print(set(list(map(len, conv))))\n",
    "    conv = flatten(conv)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e7b3ccf-e3ab-4c2f-a38e-1c3384db0222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce5db7f6-8486-4b76-a76f-63559628fa4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5']\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = prepare_data(df, filter_by=\"character\", filter_value=\"bitjockey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30ae9cb3-8351-4aa8-b25c-bf64702b651a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i nvr askd</td>\n",
       "      <td>@bitjockey im free nw...?</td>\n",
       "      <td>@Charlotte we nvr hd a ch4nce 2 t4lk</td>\n",
       "      <td>((just watch))</td>\n",
       "      <td>((I don't know what to do but I'm excited))</td>\n",
       "      <td>((convention accepted))</td>\n",
       "      <td>((this will indicate ooc responses))</td>\n",
       "      <td>yea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wht exactly do u kno abt m3</td>\n",
       "      <td>i nvr askd</td>\n",
       "      <td>@bitjockey im free nw...?</td>\n",
       "      <td>@Charlotte we nvr hd a ch4nce 2 t4lk</td>\n",
       "      <td>((just watch))</td>\n",
       "      <td>((I don't know what to do but I'm excited))</td>\n",
       "      <td>((convention accepted))</td>\n",
       "      <td>((this will indicate ooc responses))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((omg why do they type like this lmao))</td>\n",
       "      <td>wht exactly do u kno abt m3</td>\n",
       "      <td>i nvr askd</td>\n",
       "      <td>@bitjockey im free nw...?</td>\n",
       "      <td>@Charlotte we nvr hd a ch4nce 2 t4lk</td>\n",
       "      <td>((just watch))</td>\n",
       "      <td>((I don't know what to do but I'm excited))</td>\n",
       "      <td>((convention accepted))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>((okay I have no idea what that says lol))</td>\n",
       "      <td>ur nm. rl 1</td>\n",
       "      <td>lik</td>\n",
       "      <td>um</td>\n",
       "      <td>((_dystopia_. Also charlotte is a little shit))</td>\n",
       "      <td>((omg why do they type like this lmao))</td>\n",
       "      <td>wht exactly do u kno abt m3</td>\n",
       "      <td>i nvr askd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Charlotte do u ever type in real words</td>\n",
       "      <td>((I speak hackese))</td>\n",
       "      <td>((you speak charlotte!)</td>\n",
       "      <td>((don't ask how I can do this lol))</td>\n",
       "      <td>((your name, real one))</td>\n",
       "      <td>((would hopper?))</td>\n",
       "      <td>((okay I have no idea what that says lol))</td>\n",
       "      <td>ur nm. rl 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>Hello. Do you...have some time? To talk?</td>\n",
       "      <td>[_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.</td>\n",
       "      <td>[_weak smile_] Thanks. [_heads there_]</td>\n",
       "      <td>She's in the office.</td>\n",
       "      <td>[_Meanwhile, elsewhere..._]</td>\n",
       "      <td>[_is idly running fingers through Shiro's hair as she sleeps_] Trust me, I'm the _last_ person who's going to fault you for that bit of worry.</td>\n",
       "      <td>I don't know her well, but I guess this isn't how it normally goes? Maybe she didn't want to distract you while you were working. [_sighs_] But you're probably thinking of all the bad case scenarios, aren't you?</td>\n",
       "      <td>[_nods_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?</td>\n",
       "      <td>[_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]</td>\n",
       "      <td>Of course.</td>\n",
       "      <td>Hello. Do you...have some time? To talk?</td>\n",
       "      <td>[_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.</td>\n",
       "      <td>[_weak smile_] Thanks. [_heads there_]</td>\n",
       "      <td>She's in the office.</td>\n",
       "      <td>[_Meanwhile, elsewhere..._]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>Uhm, well. I need a refresher? I think?</td>\n",
       "      <td>How much do you know?</td>\n",
       "      <td>Oh! Sure, I'd love that.</td>\n",
       "      <td>Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?</td>\n",
       "      <td>[_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]</td>\n",
       "      <td>Of course.</td>\n",
       "      <td>Hello. Do you...have some time? To talk?</td>\n",
       "      <td>[_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>[_nods_] Right, right...so..how can I help?</td>\n",
       "      <td>[_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]</td>\n",
       "      <td>Right.</td>\n",
       "      <td>Uhm, well. I need a refresher? I think?</td>\n",
       "      <td>How much do you know?</td>\n",
       "      <td>Oh! Sure, I'd love that.</td>\n",
       "      <td>Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?</td>\n",
       "      <td>[_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>[_nods_]</td>\n",
       "      <td>[_thinking_] I remember you being more interested in the practical than the theory. Is that still true?</td>\n",
       "      <td>[_nods_] Right, right...so..how can I help?</td>\n",
       "      <td>[_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]</td>\n",
       "      <td>Right.</td>\n",
       "      <td>Uhm, well. I need a refresher? I think?</td>\n",
       "      <td>How much do you know?</td>\n",
       "      <td>Oh! Sure, I'd love that.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4963 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                     response  \\\n",
       "0                                                                                                                                  i nvr askd   \n",
       "1                                                                                                                 wht exactly do u kno abt m3   \n",
       "2                                                                                                     ((omg why do they type like this lmao))   \n",
       "3                                                                                                  ((okay I have no idea what that says lol))   \n",
       "4                                                                                                     @Charlotte do u ever type in real words   \n",
       "...                                                                                                                                       ...   \n",
       "4958                                                                                                 Hello. Do you...have some time? To talk?   \n",
       "4959  Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?   \n",
       "4960                                                                                                  Uhm, well. I need a refresher? I think?   \n",
       "4961                                                                                              [_nods_] Right, right...so..how can I help?   \n",
       "4962                                                                                                                                 [_nods_]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  context  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               @bitjockey im free nw...?   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              i nvr askd   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             wht exactly do u kno abt m3   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ur nm. rl 1   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ((I speak hackese))   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "4958                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.   \n",
       "4959                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]   \n",
       "4960                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                How much do you know?   \n",
       "4961  [_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]   \n",
       "4962                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              [_thinking_] I remember you being more interested in the practical than the theory. Is that still true?   \n",
       "\n",
       "                                        context/0  \\\n",
       "0            @Charlotte we nvr hd a ch4nce 2 t4lk   \n",
       "1                       @bitjockey im free nw...?   \n",
       "2                                      i nvr askd   \n",
       "3                                             lik   \n",
       "4                         ((you speak charlotte!)   \n",
       "...                                           ...   \n",
       "4958       [_weak smile_] Thanks. [_heads there_]   \n",
       "4959                                   Of course.   \n",
       "4960                     Oh! Sure, I'd love that.   \n",
       "4961                                       Right.   \n",
       "4962  [_nods_] Right, right...so..how can I help?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                context/1  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ((just watch))   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    @Charlotte we nvr hd a ch4nce 2 t4lk   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               @bitjockey im free nw...?   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      um   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ((don't ask how I can do this lol))   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "4958                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 She's in the office.   \n",
       "4959                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Hello. Do you...have some time? To talk?   \n",
       "4960                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?   \n",
       "4961                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Uhm, well. I need a refresher? I think?   \n",
       "4962  [_Akari launches into a technical explanation. The short version is that even if Nix and Temper manage to stop the degradation, the damage has already been done. Neither of them are certain they'll be able to fix that, so they're really more focused on keeping Shiro alive. In most cases, a fix to this kind of problem would be biotech replacements or treatments. However, since Shiro's system is so fucked up, the introduction of new cyberware was the catalyst for this in the first place, and the modifications are basically evolving. The closest comparison is a very bad autoimmune disorder.\\nWhen Akari was in Montreal, her research area was working on new cyberware. It's currently theoretical, but Akari was able to figure out a way to integrate cyberware in such a way that it does less damage to the body. It's not nanotech but an almost symbiotic merging of biotech and cybertech. Akari is convinced the theory is sound, she just needs to work out the physical details_]   \n",
       "\n",
       "                                                                                                                                      context/2  \\\n",
       "0                                                                                                   ((I don't know what to do but I'm excited))   \n",
       "1                                                                                                                                ((just watch))   \n",
       "2                                                                                                          @Charlotte we nvr hd a ch4nce 2 t4lk   \n",
       "3                                                                                               ((_dystopia_. Also charlotte is a little shit))   \n",
       "4                                                                                                                       ((your name, real one))   \n",
       "...                                                                                                                                         ...   \n",
       "4958                                                                                                                [_Meanwhile, elsewhere..._]   \n",
       "4959                                                       [_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.   \n",
       "4960  [_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]   \n",
       "4961                                                                                                                      How much do you know?   \n",
       "4962                                                                                                                                     Right.   \n",
       "\n",
       "                                                                                                                                           context/3  \\\n",
       "0                                                                                                                            ((convention accepted))   \n",
       "1                                                                                                        ((I don't know what to do but I'm excited))   \n",
       "2                                                                                                                                     ((just watch))   \n",
       "3                                                                                                            ((omg why do they type like this lmao))   \n",
       "4                                                                                                                                  ((would hopper?))   \n",
       "...                                                                                                                                              ...   \n",
       "4958  [_is idly running fingers through Shiro's hair as she sleeps_] Trust me, I'm the _last_ person who's going to fault you for that bit of worry.   \n",
       "4959                                                                                                          [_weak smile_] Thanks. [_heads there_]   \n",
       "4960                                                                                                                                      Of course.   \n",
       "4961                                                                                                                        Oh! Sure, I'd love that.   \n",
       "4962                                                                                                         Uhm, well. I need a refresher? I think?   \n",
       "\n",
       "                                                                                                                                                                                                                context/4  \\\n",
       "0                                                                                                                                                                                    ((this will indicate ooc responses))   \n",
       "1                                                                                                                                                                                                 ((convention accepted))   \n",
       "2                                                                                                                                                                             ((I don't know what to do but I'm excited))   \n",
       "3                                                                                                                                                                                             wht exactly do u kno abt m3   \n",
       "4                                                                                                                                                                              ((okay I have no idea what that says lol))   \n",
       "...                                                                                                                                                                                                                   ...   \n",
       "4958  I don't know her well, but I guess this isn't how it normally goes? Maybe she didn't want to distract you while you were working. [_sighs_] But you're probably thinking of all the bad case scenarios, aren't you?   \n",
       "4959                                                                                                                                                                                                 She's in the office.   \n",
       "4960                                                                                                                                                                             Hello. Do you...have some time? To talk?   \n",
       "4961                                                                              Uhm, so...I was wondering if....There was something you mentioned about helping Shiro. I was wondering if I could maybe help with that?   \n",
       "4962                                                                                                                                                                                                How much do you know?   \n",
       "\n",
       "                                                                                                                                      context/5  \n",
       "0                                                                                                                                           yea  \n",
       "1                                                                                                          ((this will indicate ooc responses))  \n",
       "2                                                                                                                       ((convention accepted))  \n",
       "3                                                                                                                                    i nvr askd  \n",
       "4                                                                                                                                   ur nm. rl 1  \n",
       "...                                                                                                                                         ...  \n",
       "4958                                                                                                                                   [_nods_]  \n",
       "4959                                                                                                                [_Meanwhile, elsewhere..._]  \n",
       "4960                                                       [_is in the office working at a computer. She looks up when Hopper enters_] Hi Alex.  \n",
       "4961  [_collateral nonchalantly wanders into the common room, sits down and resumes watching {whatever sci-fi show he was watching previous}._]  \n",
       "4962                                                                                                                   Oh! Sure, I'd love that.  \n",
       "\n",
       "[4963 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80d9e8e2-818e-40b9-9881-1654803aaf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i nvr askd', '@bitjockey im free nw...?',\n",
       "       '@Charlotte we nvr hd a ch4nce 2 t4lk', '((just watch))',\n",
       "       \"((I don't know what to do but I'm excited))\",\n",
       "       '((convention accepted))', '((this will indicate ooc responses))',\n",
       "       'yea'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc165239-6ec7-43f9-b981-772f8783d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bcc0914-a207-4d1c-9a9a-6634a2e6517c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 4963\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c2c91b-70c9-456b-8ca5-63bbe748e289",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'context', 'context/0', 'context/1', 'context/2', 'context/3', 'context/4', 'context/5', '__index_level_0__'],\n",
       "    num_rows: 552\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53a7fc9a-668f-4382-88bf-f816e8ae0ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(tokenizer, max_length=512):\n",
    "    def _construct(examples):\n",
    "        flatten = lambda l: [item for sublist in l for item in sublist] \n",
    "        concat_text = f\"{tokenizer.eos_token}\".join(reversed([v for _, v in examples.items() if isinstance(v, str)]))\n",
    "        concat_text = concat_text + tokenizer.eos_token\n",
    "        tokenized = tokenizer(concat_text, padding=\"max_length\",  max_length=max_length)\n",
    "        examples[\"input_ids\"] = tokenized[\"input_ids\"]\n",
    "        examples[\"attention_mask\"] = tokenized[\"attention_mask\"]\n",
    "        return examples\n",
    "        \n",
    "    return _construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61d53884-df1c-42d0-8a32-648afca98ae6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f183d83d027348289823a024b26df2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4963 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b9bcb4c2f74a728fd23c3fdf3a1552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(train_dataset.features.keys()))\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function(tokenizer=base_tokenizer, max_length=256), remove_columns=list(val_dataset.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcd83ed6-3fac-447a-bd65-2a8c56397b8d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 hard to find someone who doesn’t exist anymore<|endoftext|>But enough about me<|endoftext|>I could make it harder to find. Make sure other people can't follow the trail I did. If you want.<|endoftext|>I’m..open to it<|endoftext|>I can put Pongo to work on it<|endoftext|>pngo?<|endoftext|>One of my sprites<|endoftext|>a sprite?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 I’m..open to it<|endoftext|>I can put Pongo to work on it<|endoftext|>pngo?<|endoftext|>One of my sprites<|endoftext|>a sprite?<|endoftext|>Yeah, like Wilbur?<|endoftext|>...have I not explained him?<|endoftext|>No<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 Yeah, like Wilbur?<|endoftext|>...have I not explained him?<|endoftext|>No<|endoftext|>Oh<|endoftext|>well they're sort of...code that's friend-shaped<|endoftext|>they're...kind of like AIs? Except they aren't made the way an AI is, they just already exist in the resonance and I just bring them out into the matrix<|endoftext|>or, well really they bring _themselves_ out, I just ask politely<|endoftext|>Have they helped us before?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 No<|endoftext|>Oh<|endoftext|>well they're sort of...code that's friend-shaped<|endoftext|>they're...kind of like AIs? Except they aren't made the way an AI is, they just already exist in the resonance and I just bring them out into the matrix<|endoftext|>or, well really they bring _themselves_ out, I just ask politely<|endoftext|>Have they helped us before?<|endoftext|>Yes? Wilbur got me into the computer at the Pyrausta building?<|endoftext|>Oh. I assumed he was a contact of yours in meatspace<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 well they're sort of...code that's friend-shaped<|endoftext|>they're...kind of like AIs? Except they aren't made the way an AI is, they just already exist in the resonance and I just bring them out into the matrix<|endoftext|>or, well really they bring _themselves_ out, I just ask politely<|endoftext|>Have they helped us before?<|endoftext|>Yes? Wilbur got me into the computer at the Pyrausta building?<|endoftext|>Oh. I assumed he was a contact of yours in meatspace<|endoftext|>....ok yeah i can see how that was confusing<|endoftext|>Yeah...<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 they're...kind of like AIs? Except they aren't made the way an AI is, they just already exist in the resonance and I just bring them out into the matrix<|endoftext|>or, well really they bring _themselves_ out, I just ask politely<|endoftext|>Have they helped us before?<|endoftext|>Yes? Wilbur got me into the computer at the Pyrausta building?<|endoftext|>Oh. I assumed he was a contact of yours in meatspace<|endoftext|>....ok yeah i can see how that was confusing<|endoftext|>Yeah...<|endoftext|>So what..do you mean exactly by  friend shape code? Can’t say I relate :/<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 Yes? Wilbur got me into the computer at the Pyrausta building?<|endoftext|>Oh. I assumed he was a contact of yours in meatspace<|endoftext|>....ok yeah i can see how that was confusing<|endoftext|>Yeah...<|endoftext|>So what..do you mean exactly by  friend shape code? Can’t say I relate :/<|endoftext|>I don't...really know how to explain it better than that? They're made of code, but the friendly kind.<|endoftext|>oh, I know! it's like the difference between a blanket and a stuffed animal. They're both cloth, but one is blanket-shaped and the other is friend-shaped<|endoftext|>I see<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 ....ok yeah i can see how that was confusing<|endoftext|>Yeah...<|endoftext|>So what..do you mean exactly by  friend shape code? Can’t say I relate :/<|endoftext|>I don't...really know how to explain it better than that? They're made of code, but the friendly kind.<|endoftext|>oh, I know! it's like the difference between a blanket and a stuffed animal. They're both cloth, but one is blanket-shaped and the other is friend-shaped<|endoftext|>I see<|endoftext|>...it's weird, I know<|endoftext|>How long have you, er, known them?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 So what..do you mean exactly by  friend shape code? Can’t say I relate :/<|endoftext|>I don't...really know how to explain it better than that? They're made of code, but the friendly kind.<|endoftext|>oh, I know! it's like the difference between a blanket and a stuffed animal. They're both cloth, but one is blanket-shaped and the other is friend-shaped<|endoftext|>I see<|endoftext|>...it's weird, I know<|endoftext|>How long have you, er, known them?<|endoftext|>Years. Since I was a kid, with some of them<|endoftext|>That’s<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n",
      "256 I don't...really know how to explain it better than that? They're made of code, but the friendly kind.<|endoftext|>oh, I know! it's like the difference between a blanket and a stuffed animal. They're both cloth, but one is blanket-shaped and the other is friend-shaped<|endoftext|>I see<|endoftext|>...it's weird, I know<|endoftext|>How long have you, er, known them?<|endoftext|>Years. Since I was a kid, with some of them<|endoftext|>That’s<|endoftext|>Cool<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 110):\n",
    "    decoded = base_tokenizer.decode(tokenized_train_dataset[i][\"input_ids\"])\n",
    "    print(len(tokenized_train_dataset[i][\"input_ids\"]), decoded, \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68930df4-c807-418a-ba40-9db502d9daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 4963\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bf184bd-0785-4853-ac2e-aef373830e05",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_train_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
    "tokenized_val_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d05942e-528c-4b02-b8d3-085a99a10951",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In our defense, you _were_ a little obnoxious.<|endoftext|>Wow.<|endoftext|>Well I didn't exactly think I'd be there very long.<|endoftext|>[_frowns_]<|endoftext|>[*shrugs*] I'd been through a lot of fosters at that point.<|endoftext|>*Kalahan's ears perk up at the word 'fosters' and he frowns, somewhat confused, as he tries to remember if he already knew about this or not.*<|endoftext|>*He recalls that he did know she was adopted and seems to mellow out, but he's more interested in the situation now.*<|endoftext|>So..Medusa and Nix..you were already close?<|endoftext|>[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_tokenizer.decode(tokenized_train_dataset[3000][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ee5835-da48-468b-b2af-45d407d9a8c9",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52d02923-9740-413b-ba81-c46597c56423",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"perplexity\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2313d34-3806-4d23-a40a-495d36c084e2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc4fb8f8-39eb-45f9-a9a0-25575af5e5f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.resize_token_embeddings(len(base_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52086282-7820-4e5f-91b3-549529ed7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNED_MODEL = 'CHARLOTTE-05162022a-myDialoGPT2-small'\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=base_tokenizer,\n",
    "    mlm=False,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "trainer = None\n",
    "training_args = None\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=FINETUNED_MODEL,          # output directory\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=3,           # total # of training epochs\n",
    "    per_device_train_batch_size=2,  # batch size per device during training\n",
    "    per_device_eval_batch_size=2,   # batch size for evaluation\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    logging_dir=FINETUNED_MODEL,            # directory for storing logs\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e9eab83-e5f6-4da7-8d90-69d808da13c5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "985db8b4-0d4d-4c9b-a96c-a712c4c1ebf0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 7823\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11736' max='11736' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11736/11736 24:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.988000</td>\n",
       "      <td>3.169161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.590200</td>\n",
       "      <td>3.244871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.425600</td>\n",
       "      <td>3.307563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "4.3112\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.786980231765508e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.5121\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.573960463531016e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.3265\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.360940695296524e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.2139\n",
      "Attempted to log scalar metric learning_rate:\n",
      "4.147920927062032e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.1432\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.934901158827539e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "3.0656\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.7218813905930474e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.988\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.508861622358555e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "3.169161319732666\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "12.1362\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "71.687\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "35.843\n",
      "Attempted to log scalar metric epoch:\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.9464\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.2958418541240625e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.7669\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.0828220858895703e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.7445\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.8698023176550785e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.6896\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.656782549420586e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.68\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.4437627811860943e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.6444\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.230743012951602e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.6484\n",
      "Attempted to log scalar metric learning_rate:\n",
      "2.01772324471711e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.5902\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.8047034764826175e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-7500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "3.244870901107788\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "12.0984\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "71.91\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "35.955\n",
      "Attempted to log scalar metric epoch:\n",
      "2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.5169\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.5916837082481257e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "2.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4503\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.3786639400136334e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4398\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.1656441717791411e-05\n",
      "Attempted to log scalar metric epoch:\n",
      "2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4249\n",
      "Attempted to log scalar metric learning_rate:\n",
      "9.52624403544649e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4436\n",
      "Attempted to log scalar metric learning_rate:\n",
      "7.3960463531015685e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.406\n",
      "Attempted to log scalar metric learning_rate:\n",
      "5.265848670756646e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11000\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4101\n",
      "Attempted to log scalar metric learning_rate:\n",
      "3.135650988411725e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11500\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric loss:\n",
      "2.4256\n",
      "Attempted to log scalar metric learning_rate:\n",
      "1.0054533060668031e-06\n",
      "Attempted to log scalar metric epoch:\n",
      "2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/checkpoint-11500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 870\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric eval_loss:\n",
      "3.307562828063965\n",
      "Attempted to log scalar metric eval_runtime:\n",
      "12.0967\n",
      "Attempted to log scalar metric eval_samples_per_second:\n",
      "71.92\n",
      "Attempted to log scalar metric eval_steps_per_second:\n",
      "35.96\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempted to log scalar metric train_runtime:\n",
      "1450.5928\n",
      "Attempted to log scalar metric train_samples_per_second:\n",
      "16.179\n",
      "Attempted to log scalar metric train_steps_per_second:\n",
      "8.09\n",
      "Attempted to log scalar metric total_flos:\n",
      "3102890851584000.0\n",
      "Attempted to log scalar metric train_loss:\n",
      "2.808187192203077\n",
      "Attempted to log scalar metric epoch:\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11736, training_loss=2.808187192203077, metrics={'train_runtime': 1450.5928, 'train_samples_per_second': 16.179, 'train_steps_per_second': 8.09, 'total_flos': 3102890851584000.0, 'train_loss': 2.808187192203077, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a77399-5118-458b-8147-54139ede96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to CHARLOTTE-05162022a-myDialoGPT2-small\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/config.json\n",
      "Model weights saved in CHARLOTTE-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "tokenizer config file saved in CHARLOTTE-05162022a-myDialoGPT2-small/tokenizer_config.json\n",
      "Special tokens file saved in CHARLOTTE-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "Configuration saved in CHARLOTTE-05162022a-myDialoGPT2-small/config.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(FINETUNED_MODEL)\n",
    "base_tokenizer.save_pretrained(FINETUNED_MODEL)\n",
    "config.save_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "490541df-a595-4c80-8e5c-9b8ff66a9c39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file CHARLOTTE-05162022a-myDialoGPT2-small/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"CHARLOTTE-05162022a-myDialoGPT2-small\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"conversational\": {\n",
      "      \"max_length\": 1000\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50258\n",
      "}\n",
      "\n",
      "loading weights file CHARLOTTE-05162022a-myDialoGPT2-small/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at CHARLOTTE-05162022a-myDialoGPT2-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/vocab.json\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/merges.txt\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/tokenizer.json\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/added_tokens.json\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/special_tokens_map.json\n",
      "loading file CHARLOTTE-05162022a-myDialoGPT2-small/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "finetuned_model = AutoModelForCausalLM.from_pretrained(FINETUNED_MODEL)\n",
    "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af6daae3-1241-4782-920e-16b5e67933f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, text, chat_history_ids=None, step=0):\n",
    "    # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "    new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # append the new user input tokens to the chat history\n",
    "    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if step > 0 else new_user_input_ids\n",
    "\n",
    "    # generated a response while limiting the total chat history to 1000 tokens, \n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        do_sample=True,\n",
    "        top_k=100,\n",
    "        top_p=0.7\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    return response, chat_history_ids, step + 1\n",
    "\n",
    "def chat(model, tokenizer):\n",
    "    step = 0\n",
    "    chat_history_ids = []\n",
    "    \n",
    "    while True: \n",
    "        text = input(\">> \")\n",
    "        if text in [\"/q\", \"/quit\", \"/e\", \"/exit\"]: break\n",
    "        print(f\"User: {text}\")\n",
    "        response, chat_history_ids, step = generate_responses(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            text=text,\n",
    "            chat_history_ids=chat_history_ids,\n",
    "            step=step\n",
    "        )\n",
    "        print(f\"Bot: {response}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e12e5dce-153c-46be-80b7-f29db173c474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hello\n",
      "Bot: *Kalahan chuckles and shrugs.*\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What's wrong with you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's wrong with you?\n",
      "Bot: *He glances over at Amarok and Eliza.*\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What about them?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What about them?\n",
      "Bot: [_shrugs_] I don't know. They seem nice.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How are you doing?\n",
      "Bot: They're doing better. I think. I mean, it's nice to have something to do.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  No, I mean you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: No, I mean you.\n",
      "Bot: [_quietly_] Right, that.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  This doesn't make sense, dude.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: This doesn't make sense, dude.\n",
      "Bot: It's...not the end of the world.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  But isn't it though?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: But isn't it though?\n",
      "Bot: It...is not?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How's Shiro?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How's Shiro?\n",
      "Bot: She's doing better\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  That's good to hear.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: That's good to hear.\n",
      "Bot: I guess\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Who is she with?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Who is she with?\n",
      "Bot: [*shrug*]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What are you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What are you doing?\n",
      "Bot: Just hanging out\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Are we meeting up? Where?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Are we meeting up? Where?\n",
      "Bot: Yep\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Where are we meeting up?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Where are we meeting up?\n",
      "Bot: Yeah\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What is the location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the location\n",
      "Bot: You know where I'm going to meet up\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  No, I do not.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: No, I do not.\n",
      "Bot: [charlotte will show up soon\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hey\n",
      "Bot: [[*follows after him*] Did you guys have anything else to drink?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  No we don't\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: No we don't\n",
      "Bot: [will wait unless you want to wait?]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I don't\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I don't\n",
      "Bot: ....[*will wait if you want us to...?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I really don't want to\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I really don't want to\n",
      "Bot: [_will show up unless you say something\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  /quit\n"
     ]
    }
   ],
   "source": [
    "chat(finetuned_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e6352-e9a2-4bfd-a05f-8ea1beec58fd",
   "metadata": {},
   "source": [
    "## Re-do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbfe9c9a-2d91-421e-b3ce-74cece0cf3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response                                                    [_looks concerned_] ..what do you mean?\n",
       "context                                                     Now...I think...it was the same as you.\n",
       "context/0                         I...remember much...of it. I...lose sense of time...near the end.\n",
       "context/1                                                                       It is...unpleasant.\n",
       "context/2                                                                                  [_nods_]\n",
       "context/3                                                                  ...perhaps...it is time.\n",
       "context/4    [_smiles weakly_] I thought...with everything that..you might want to talk to someone.\n",
       "context/5                                                                ...is that...why you came?\n",
       "Name: 3466, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44b06ee5-ab76-40b9-af9f-665db0b3b1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character                                     text\n",
       "14345  bitjockey  [_looks concerned_] ..what do you mean?"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[\"text\"] == \"[_looks concerned_] ..what do you mean?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d1a5d749-d467-47cd-9e97-6127a5838ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14345</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14346</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>[_sighs_] They tried to...program me, I suppose. Simsense. Simulations. Drugs, I think.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14347</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>I...remember the tank. But...near the end...things are chaotic. The memories...slip.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>[_stiffens_]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14349</th>\n",
       "      <td>bitjockey</td>\n",
       "      <td>So there are...gaps too? In your memory?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14350</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>At that point...yes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14351</th>\n",
       "      <td>Shiro</td>\n",
       "      <td>I...some are there but...I can't...hold onto them.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character  \\\n",
       "14345  bitjockey   \n",
       "14346      Shiro   \n",
       "14347      Shiro   \n",
       "14348  bitjockey   \n",
       "14349  bitjockey   \n",
       "14350      Shiro   \n",
       "14351      Shiro   \n",
       "\n",
       "                                                                                          text  \n",
       "14345                                                  [_looks concerned_] ..what do you mean?  \n",
       "14346  [_sighs_] They tried to...program me, I suppose. Simsense. Simulations. Drugs, I think.  \n",
       "14347     I...remember the tank. But...near the end...things are chaotic. The memories...slip.  \n",
       "14348                                                                             [_stiffens_]  \n",
       "14349                                                 So there are...gaps too? In your memory?  \n",
       "14350                                                                     At that point...yes.  \n",
       "14351                                       I...some are there but...I can't...hold onto them.  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[14345:14352]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae90d01a-4d00-4577-b4ae-b0c0d185e6dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Hiya\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hiya\n",
      "Bot: So, uh, what's up?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Nothing much. You?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Nothing much. You?\n",
      "Bot: I...just woke up.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  You did?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: You did?\n",
      "Bot: Yeah.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Did you sleep okay?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Did you sleep okay?\n",
      "Bot: You know it sounds like you are going to have a panic attack and start screaming.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  What?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What?\n",
      "Bot: _::sits up straighter::_\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How you doing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How you doing?\n",
      "Bot: Just.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Just?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Just?\n",
      "Bot: About.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  I don't know\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: I don't know\n",
      "Bot: Did your dad..tell you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  [_shrugs_]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: [_shrugs_]\n",
      "Bot: I was born in '97, so I...had some time to think about it before coming back to this.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  How old are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: How old are you?\n",
      "Bot: ...I'm not really sure.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  /quit\n"
     ]
    }
   ],
   "source": [
    "chat(finetuned_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8923873-b6dc-4de0-bec1-4793f060e5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/2</th>\n",
       "      <th>context/3</th>\n",
       "      <th>context/4</th>\n",
       "      <th>context/5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>[_looks concerned_] ..what do you mean?</td>\n",
       "      <td>Now...I think...it was the same as you.</td>\n",
       "      <td>I...remember much...of it. I...lose sense of time...near the end.</td>\n",
       "      <td>It is...unpleasant.</td>\n",
       "      <td>[_nods_]</td>\n",
       "      <td>...perhaps...it is time.</td>\n",
       "      <td>[_smiles weakly_] I thought...with everything that..you might want to talk to someone.</td>\n",
       "      <td>...is that...why you came?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     response  \\\n",
       "3466  [_looks concerned_] ..what do you mean?   \n",
       "\n",
       "                                      context  \\\n",
       "3466  Now...I think...it was the same as you.   \n",
       "\n",
       "                                                              context/0  \\\n",
       "3466  I...remember much...of it. I...lose sense of time...near the end.   \n",
       "\n",
       "                context/1 context/2                 context/3  \\\n",
       "3466  It is...unpleasant.  [_nods_]  ...perhaps...it is time.   \n",
       "\n",
       "                                                                                   context/4  \\\n",
       "3466  [_smiles weakly_] I thought...with everything that..you might want to talk to someone.   \n",
       "\n",
       "                       context/5  \n",
       "3466  ...is that...why you came?  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df[\"response\"] == \"[_looks concerned_] ..what do you mean?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a630dba-39a3-4115-8b46-4030cd94d8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '[_looks concerned_] ..what do you mean?',\n",
       " 'context': 'Now...I think...it was the same as you.',\n",
       " 'context/0': 'I...remember much...of it. I...lose sense of time...near the end.',\n",
       " 'context/1': 'It is...unpleasant.',\n",
       " 'context/2': '[_nods_]',\n",
       " 'context/3': '...perhaps...it is time.',\n",
       " 'context/4': '[_smiles weakly_] I thought...with everything that..you might want to talk to someone.',\n",
       " 'context/5': '...is that...why you came?',\n",
       " '__index_level_0__': 3466}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8c67c-5c65-4e8c-9070-a5d13fdcd9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0526b0db3ffe489e91e584aab7cd5d26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_eeb7ea0968db4e2784ea9642ad581215",
       "max": 552,
       "style": "IPY_MODEL_f960b366a4834184bb6db905c45d9829",
       "value": 552
      }
     },
     "0828f7b9d30f42d2a5420a5db5d46c38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0afa047086a44a35a811976f8fbdda26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0e848886132c489f92dce447ef64c69a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_2bb582b658084f7baa0029a41d49e261",
       "max": 4963,
       "style": "IPY_MODEL_c668cca2d28c432595bb3b1ed9d0eafb",
       "value": 4963
      }
     },
     "27902d6fb2b34edcbf15ca5af1001ba9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "28b9bcb4c2f74a728fd23c3fdf3a1552": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8a4877c359aa4a09bdec42840b6406ca",
        "IPY_MODEL_0526b0db3ffe489e91e584aab7cd5d26",
        "IPY_MODEL_e8086aa5490443fab90291ffe1ec711e"
       ],
       "layout": "IPY_MODEL_e93c45827c53437890540b8cbd57e995"
      }
     },
     "2bb582b658084f7baa0029a41d49e261": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "45cfd946c3194f44b60edf0f57aa2cdd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "49df82d687a842ff87a9d261fda646e9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5dc4d538948940058614544a55c65fbc",
       "style": "IPY_MODEL_b55ad8d952eb4e9587db35991f51c75e",
       "value": "100%"
      }
     },
     "5dc4d538948940058614544a55c65fbc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5fa3d72a60bf4613ae50ba468bb2ca78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "67c759ede4c047a698823ed7aea60a44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a4877c359aa4a09bdec42840b6406ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_45cfd946c3194f44b60edf0f57aa2cdd",
       "style": "IPY_MODEL_27902d6fb2b34edcbf15ca5af1001ba9",
       "value": "100%"
      }
     },
     "8dae89f353364834bd5815d8f1e55b15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b96b4804b6dd4a61904b26b818aee67b",
       "style": "IPY_MODEL_0afa047086a44a35a811976f8fbdda26",
       "value": " 4963/4963 [00:01&lt;00:00, 2561.01ex/s]"
      }
     },
     "b55ad8d952eb4e9587db35991f51c75e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b96b4804b6dd4a61904b26b818aee67b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c668cca2d28c432595bb3b1ed9d0eafb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e8086aa5490443fab90291ffe1ec711e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_67c759ede4c047a698823ed7aea60a44",
       "style": "IPY_MODEL_0828f7b9d30f42d2a5420a5db5d46c38",
       "value": " 552/552 [00:00&lt;00:00, 2401.90ex/s]"
      }
     },
     "e93c45827c53437890540b8cbd57e995": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "eeb7ea0968db4e2784ea9642ad581215": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f183d83d027348289823a024b26df2cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_49df82d687a842ff87a9d261fda646e9",
        "IPY_MODEL_0e848886132c489f92dce447ef64c69a",
        "IPY_MODEL_8dae89f353364834bd5815d8f1e55b15"
       ],
       "layout": "IPY_MODEL_5fa3d72a60bf4613ae50ba468bb2ca78"
      }
     },
     "f960b366a4834184bb6db905c45d9829": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
