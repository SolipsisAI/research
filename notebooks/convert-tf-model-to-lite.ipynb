{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e9f425-89a3-4d88-85db-6a80e171f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad684c9-a923-4e5d-8cb3-736a4010ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TFAutoModelForSequenceClassification, TFAutoModel, AutoTokenizer\n",
    "\n",
    "#MODEL_NAME = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "MODEL_NAME = \"bhadresh-savani/distilbert-base-uncased-emotion\"\n",
    "SAVED_MODEL_NAME = \"bhadresh-emotion-classifier-output\"\n",
    "TOKENIZER_NAME = \"bert-base-uncased\"\n",
    "TFLITE_OUTPUT = \"tflite/bhadresh-output\"\n",
    "\n",
    "\n",
    "def load_vocab(filename, reverse=False):\n",
    "    data = load_data(filename, reverse=reverse)\n",
    "    return dict(data)\n",
    "\n",
    "\n",
    "def load_data(filename, reverse=False):\n",
    "    def prepare(i, line):\n",
    "        line = line.strip()\n",
    "        return (i, line) if reverse else (line, i)\n",
    "        \n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        #lines = list(filter(lambda l: not l.startswith(\"##\"), lines))\n",
    "        return [prepare(i, line) for i, line in enumerate(lines)]\n",
    " \n",
    "\n",
    "class DataUtil:\n",
    "    def __init__(self):\n",
    "        self.token2id = load_vocab(\"vocab.txt\")\n",
    "        self.id2token = load_vocab(\"vocab.txt\", reverse=True) \n",
    "    \n",
    "    def tokenize(self, text, padding=True, max_len=87):\n",
    "        tokens = [line.strip().lower() for line in text.split(\" \")]\n",
    "        # Starting\n",
    "        token_ids = [101]\n",
    "        count = 1\n",
    "\n",
    "        for token in tokens:\n",
    "            token_id = self.token2id.get(token)\n",
    "            token_ids.append(token_id)\n",
    "            count += 1\n",
    "\n",
    "        token_ids.append(102)\n",
    "        count +=1\n",
    "\n",
    "        # Padding\n",
    "        if padding:\n",
    "            for _ in range(count, max_len):\n",
    "                 token_ids.append(0)\n",
    "        \n",
    "        return token_ids\n",
    "    \n",
    "    def preprocess(self, text, padding=True, max_len=87):\n",
    "        token_ids = self.tokenize(text, padding=padding, max_len=max_len)\n",
    "        return np.array([token_ids], dtype=np.int32) # float32 for text_classification.tflite\n",
    "\n",
    "\n",
    "data_util = DataUtil()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2c89d-9025-4d8b-b6ce-b72200a7108d",
   "metadata": {},
   "source": [
    "# Load Transformers Model (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e5b59f-21bd-44b1-b411-3fced4f40e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:43:13.162319: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-04 16:43:13.162343: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 0701f5cb6f1a\n",
      "2023-01-04 16:43:13.162348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 0701f5cb6f1a\n",
      "2023-01-04 16:43:13.162402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.73.5\n",
      "2023-01-04 16:43:13.162416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2023-01-04 16:43:13.162420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.73.5\n",
      "2023-01-04 16:43:13.162601: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbeeaa10-e12c-4c55-939a-9897ed4fcdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x7f55ed3ed630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01ee22b-f291-49c7-aaa5-71657db857e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"sadness\",\n",
       "    \"1\": \"joy\",\n",
       "    \"2\": \"love\",\n",
       "    \"3\": \"anger\",\n",
       "    \"4\": \"fear\",\n",
       "    \"5\": \"surprise\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"anger\": 3,\n",
       "    \"fear\": 4,\n",
       "    \"joy\": 1,\n",
       "    \"love\": 2,\n",
       "    \"sadness\": 0,\n",
       "    \"surprise\": 5\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.20.0\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c47a9-ca72-4c05-a7bc-b28a57351e07",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97abc7ae-1add-4807-a7c6-b504eed77e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76a36334-2eed-4d60-aeae-f783bea59024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc34bc85-ba20-48ab-b56d-b7b1345a3e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration SetFit--emotion-89147fdf376d67e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/SetFit--emotion to /home/jovyan/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-89147fdf376d67e2/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb881d572274574b523fc5aa1ccff43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa0befc928149779a0ab8a3744d1800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc39116fb844508721d23869bdd88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/279k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5b05a1c34d4bffb7f792bdaba382e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/276k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309463c0b88d44d6828208af95b11dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-89147fdf376d67e2/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091b79f79ee54184b848e2da555e9667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# emotions = load_dataset(\"emotion\")\n",
    "emotions = load_dataset(\"SetFit/emotion\")  # emotion is broken right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbcc769-e99b-488e-980d-87aff4f9bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize at 0x7f53e80ce950> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28749524ec0438dbe7b5d2ca8434536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4432c0cb5b74296bb9afd157f80f569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd7dafc59004834a35c9464f2782c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a446bb-009c-4f6f-b120-c8911316c8f7",
   "metadata": {},
   "source": [
    "# Convert and save model as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc10c18-10d3-4c15-a40d-012bba737070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(model, saved_model_path):\n",
    "    # Attempt conversion to tflite\n",
    "    # Set TensorSpec - dynamic shape though\n",
    "    input_spec = tf.TensorSpec([1, None], tf.int32)\n",
    "    \n",
    "    print(input_spec)\n",
    "\n",
    "    # Save to correct tensor dims\n",
    "    model._saved_model_inputs_spec = None\n",
    "    model._set_save_spec(input_spec)\n",
    "\n",
    "    # Convert\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(saved_model_path, 'wb') as f:\n",
    "      f.write(tflite_model)\n",
    "    \n",
    "    print(f\"Saved to {saved_model_path}\")\n",
    "    \n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748f595-7b9f-4343-ad6c-7d1308dc2b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(1, None), dtype=tf.int32, name=None)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f549bf41d20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f54984ca200>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498520640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498522a40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498530c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498533040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp82_hxel4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp82_hxel4/assets\n",
      "2023-01-04 16:43:38.263331: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-01-04 16:43:38.263362: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-01-04 16:43:38.263851: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.280089: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-01-04 16:43:38.280107: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.333620: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-01-04 16:43:38.352236: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-01-04 16:43:38.662523: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.802934: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 539084 microseconds.\n",
      "2023-01-04 16:43:39.092268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to bhadresh-emotion-classifier-output\n"
     ]
    }
   ],
   "source": [
    "tflite_model = convert(model, SAVED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4468f8-3b54-4af3-ba92-b41a86809866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = tf.saved_model.load(SAVED_MODEL_NAME)\n",
    "# print(saved_model.signatures)\n",
    "# print(saved_model.signatures)\n",
    "# saved_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0]\n",
    "# concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# new_model = tf.keras.models.load_model(\"output\")\n",
    "# new_model.summary()\n",
    "# concrete_func = new_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# tf.saved_model.save(new_model, \"output-new\", signatures={\"infer\": concrete_func})\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"output-new\")\n",
    "\n",
    "\"\"\"\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba1a2a-8ff8-47ca-a459-b3e36a899046",
   "metadata": {},
   "source": [
    "# Test tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7b87f9-c5d7-4e77-8847-eb8d60a354a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def run(interpreter, text): \n",
    "    token_ids = data_util.tokenize(text)\n",
    "    input_ids = np.array([token_ids], dtype=np.int32)\n",
    "    \n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(\"---INPUT DETAILS----\")\n",
    "    print(input_details)\n",
    "    print(\"---OUTPUT DETAILS----\")\n",
    "    print(output_details)\n",
    "     \n",
    "    # Resize input shape based on current input\n",
    "    interpreter.resize_tensor_input(input_details[0]['index'], input_ids.shape)\n",
    "    interpreter.allocate_tensors()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_ids)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "\n",
    "def load_interpreter(saved_model_path):\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    if Path(saved_model_path).exists():\n",
    "        print(\"Loading existing model\")\n",
    "        interpreter = tf.lite.Interpreter(model_path=saved_model_path)\n",
    "    else:\n",
    "        print(\"Converting model\")\n",
    "        interpreter = convert(model)\n",
    "    return interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bec7b069-5111-4ec4-9076-9b1a4e9cb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "interpreter = load_interpreter(SAVED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f1a1fcf-f4ef-4fd5-b7fc-c91eb8c783a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data = emotions_encoded[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04b32464-b847-4679-853e-b3a8893b61dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1045,\n",
       " 2064,\n",
       " 2175,\n",
       " 2013,\n",
       " 3110,\n",
       " 2061,\n",
       " 20625,\n",
       " 2000,\n",
       " 2061,\n",
       " 9636,\n",
       " 17772,\n",
       " 2074,\n",
       " 2013,\n",
       " 2108,\n",
       " 2105,\n",
       " 2619,\n",
       " 2040,\n",
       " 14977,\n",
       " 1998,\n",
       " 2003,\n",
       " 8300,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected\n",
    "print(input_data[\"text\"])\n",
    "input_data[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f7476be-6a57-41e0-9ae5-9c4d5c5ed4ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 1045,\n",
       " 2064,\n",
       " 2175,\n",
       " 2013,\n",
       " 3110,\n",
       " 2061,\n",
       " 20625,\n",
       " 2000,\n",
       " 2061,\n",
       " 9636,\n",
       " 17772,\n",
       " 2074,\n",
       " 2013,\n",
       " 2108,\n",
       " 2105,\n",
       " 2619,\n",
       " 2040,\n",
       " 14977,\n",
       " 1998,\n",
       " 2003,\n",
       " 8300,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = input_data[\"text\"]\n",
    "print(text)\n",
    "input_ids = data_util.tokenize(text)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a056ebf-a863-492e-83a7-641fa48eebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---INPUT DETAILS----\n",
      "[{'name': 'serving_default_args_0:0', 'index': 0, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "---OUTPUT DETAILS----\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 720, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "output_data = run(interpreter, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c50acec-07b7-4bbe-87c1-326041efaa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.401265 , -1.6106292, -1.8561203, -2.283181 , -0.2701278,\n",
       "        -1.820318 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4492c3d7-e2d7-4d89-813c-d85ae93de062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---INPUT DETAILS----\n",
      "[{'name': 'serving_default_args_0:0', 'index': 0, 'shape': array([ 1, 87], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "---OUTPUT DETAILS----\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 720, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.3885894 ,  0.06877743, -2.2457612 , -0.60844797, -0.58697104,\n",
       "        -2.528897  ]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = run(interpreter, \"I am very depressed\")\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d6964-d639-42a8-bc9f-89e5cf8b4a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
