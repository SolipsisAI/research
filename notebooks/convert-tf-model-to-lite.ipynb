{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e9f425-89a3-4d88-85db-6a80e171f275",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fad684c9-a923-4e5d-8cb3-736a4010ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from transformers import TFAutoModelForSequenceClassification, TFAutoModel, AutoTokenizer\n",
    "\n",
    "#MODEL_NAME = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "MODEL_NAME = \"bhadresh-savani/distilbert-base-uncased-emotion\"\n",
    "SAVED_MODEL_NAME = \"bhadresh-emotion-classifier-output\"\n",
    "TOKENIZER_NAME = \"bert-base-uncased\"\n",
    "TFLITE_OUTPUT = \"tflite/bhadresh-output\"\n",
    "\n",
    "\n",
    "def load_vocab(filename, reverse=False):\n",
    "    data = load_data(filename, reverse=reverse)\n",
    "    return dict(data)\n",
    "\n",
    "\n",
    "def load_data(filename, reverse=False):\n",
    "    def prepare(i, line):\n",
    "        line = line.strip()\n",
    "        return (i, line) if reverse else (line, i)\n",
    "        \n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        #lines = list(filter(lambda l: not l.startswith(\"##\"), lines))\n",
    "        return [prepare(i, line) for i, line in enumerate(lines)]\n",
    " \n",
    "\n",
    "class DataUtil:\n",
    "    def __init__(self):\n",
    "        self.token2id = load_vocab(\"vocab.txt\")\n",
    "        self.id2token = load_vocab(\"vocab.txt\", reverse=True) \n",
    "    \n",
    "    def tokenize(self, text, padding=True, max_len=87):\n",
    "        tokens = [line.strip().lower() for line in text.split(\" \")]\n",
    "        # Starting\n",
    "        token_ids = [101]\n",
    "        count = 1\n",
    "\n",
    "        for token in tokens:\n",
    "            if token == 'ive':\n",
    "                part1 = self.token2id.get(\"iv\")\n",
    "                part2 = self.token2id.get(\"##e\")\n",
    "                token_ids += [part1, part2]\n",
    "                continue\n",
    "                \n",
    "            token_id = self.token2id.get(token)\n",
    "            token_ids.append(token_id)\n",
    "            count += 1\n",
    "\n",
    "        token_ids.append(102)\n",
    "        count +=1\n",
    "\n",
    "        # Padding\n",
    "        if padding:\n",
    "            for _ in range(count, max_len):\n",
    "                 token_ids.append(0)\n",
    "        \n",
    "        return token_ids\n",
    "    \n",
    "    def preprocess(self, text, padding=True, max_len=87):\n",
    "        token_ids = self.tokenize(text, padding=padding, max_len=max_len)\n",
    "        return np.array([token_ids], dtype=np.int32) # float32 for text_classification.tflite\n",
    "\n",
    "\n",
    "data_util = DataUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d5d4cea-2e2c-4e0c-bf88-f013bcbe2b1e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 4921,\n",
       " 2063,\n",
       " 2042,\n",
       " 102,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_util.tokenize(\"ive been\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2c89d-9025-4d8b-b6ce-b72200a7108d",
   "metadata": {},
   "source": [
    "# Load Transformers Model (TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e5b59f-21bd-44b1-b411-3fced4f40e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 16:43:13.162319: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-01-04 16:43:13.162343: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 0701f5cb6f1a\n",
      "2023-01-04 16:43:13.162348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 0701f5cb6f1a\n",
      "2023-01-04 16:43:13.162402: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 510.73.5\n",
      "2023-01-04 16:43:13.162416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 510.73.5\n",
      "2023-01-04 16:43:13.162420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 510.73.5\n",
      "2023-01-04 16:43:13.162601: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbeeaa10-e12c-4c55-939a-9897ed4fcdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertForSequenceClassification at 0x7f55ed3ed630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01ee22b-f291-49c7-aaa5-71657db857e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"sadness\",\n",
       "    \"1\": \"joy\",\n",
       "    \"2\": \"love\",\n",
       "    \"3\": \"anger\",\n",
       "    \"4\": \"fear\",\n",
       "    \"5\": \"surprise\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"anger\": 3,\n",
       "    \"fear\": 4,\n",
       "    \"joy\": 1,\n",
       "    \"love\": 2,\n",
       "    \"sadness\": 0,\n",
       "    \"surprise\": 5\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.20.0\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c47a9-ca72-4c05-a7bc-b28a57351e07",
   "metadata": {},
   "source": [
    "# Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "97abc7ae-1add-4807-a7c6-b504eed77e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "76a36334-2eed-4d60-aeae-f783bea59024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc34bc85-ba20-48ab-b56d-b7b1345a3e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration SetFit--emotion-89147fdf376d67e2\n",
      "WARNING:datasets.builder:Reusing dataset json (/home/jovyan/.cache/huggingface/datasets/SetFit___json/SetFit--emotion-89147fdf376d67e2/0.0.0/da492aad5680612e4028e7f6ddc04b1dfcec4b64db470ed7cc5f2bb265b9b6b5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a76ca41fbf24037a63c2233d6f49fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# emotions = load_dataset(\"emotion\")\n",
    "emotions = load_dataset(\"SetFit/emotion\")  # emotion is broken right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4cbcc769-e99b-488e-980d-87aff4f9bb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ff6321020c45389892158baa940db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "529b11f7361644428be8f86fd164233e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754d1ce805074b4f9d7b197dd88c82df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
    "emotions_encoded.set_format(\"tf\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9caa4-0d36-4253-aa1d-603f508bad5a",
   "metadata": {},
   "source": [
    "# Test original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1c2b3c69-172c-4b77-a77d-e84888ef1f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i feel romantic too', 'label': 2, 'label_text': 'love'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = 9\n",
    "emotions[\"train\"][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e0ab5574-6bf8-455f-bcc9-6303d2c256e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_input_data = emotions_encoded[\"train\"][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "246087e3-7862-4bf6-8e47-b80c65ddd37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(87,), dtype=int64, numpy=\n",
       " array([ 101, 1045, 2514, 6298, 2205,  102,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(87,), dtype=int64, numpy=\n",
       " array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bf2e8e9f-e0e5-43a6-8503-7c183d21e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "69566895-35af-4a16-9cdd-bce0a3fb3426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'i feel romantic too', 'label': 2, 'label_text': 'love'}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[\"train\"][test_id]  # original input data before preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "25681312-9746-4589-853a-b50846cafdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "20ecd13f-cd25-4c06-8bf3-63baf2cb4aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[-1.460196 , -0.5406702,  5.794202 , -1.9637783, -1.5457897,\n",
       "        -1.2147366]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4aba5bf4-ecd2-4f65-9a91-72212a5cbc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7.0391811e-04 1.7654973e-03 9.9555922e-01 4.2542111e-04 6.4617366e-04\n",
      "  8.9975417e-04]], shape=(1, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9a5b1e82-d844-4cec-b485-5a23eb18eaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[7.0391811e-04, 1.7654973e-03, 9.9555922e-01, 4.2542111e-04,\n",
       "        6.4617366e-04, 8.9975417e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a446bb-009c-4f6f-b120-c8911316c8f7",
   "metadata": {},
   "source": [
    "# Convert and save model as tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc10c18-10d3-4c15-a40d-012bba737070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(model, saved_model_path):\n",
    "    # Attempt conversion to tflite\n",
    "    # Set TensorSpec - dynamic shape though\n",
    "    input_spec = tf.TensorSpec([1, None], tf.int32)\n",
    "    \n",
    "    print(input_spec)\n",
    "\n",
    "    # Save to correct tensor dims\n",
    "    model._saved_model_inputs_spec = None\n",
    "    model._set_save_spec(input_spec)\n",
    "\n",
    "    # Convert\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(saved_model_path, 'wb') as f:\n",
    "      f.write(tflite_model)\n",
    "    \n",
    "    print(f\"Saved to {saved_model_path}\")\n",
    "    \n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b748f595-7b9f-4343-ad6c-7d1308dc2b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorSpec(shape=(1, None), dtype=tf.int32, name=None)\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f549bf41d20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f54984ca200>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498520640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498522a40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498530c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f5498533040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 164). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp82_hxel4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp82_hxel4/assets\n",
      "2023-01-04 16:43:38.263331: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-01-04 16:43:38.263362: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-01-04 16:43:38.263851: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.280089: I tensorflow/cc/saved_model/reader.cc:81] Reading meta graph with tags { serve }\n",
      "2023-01-04 16:43:38.280107: I tensorflow/cc/saved_model/reader.cc:122] Reading SavedModel debug info (if present) from: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.333620: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2023-01-04 16:43:38.352236: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2023-01-04 16:43:38.662523: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp82_hxel4\n",
      "2023-01-04 16:43:38.802934: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 539084 microseconds.\n",
      "2023-01-04 16:43:39.092268: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to bhadresh-emotion-classifier-output\n"
     ]
    }
   ],
   "source": [
    "tflite_model = convert(model, SAVED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4468f8-3b54-4af3-ba92-b41a86809866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved_model = tf.saved_model.load(SAVED_MODEL_NAME)\n",
    "# print(saved_model.signatures)\n",
    "# print(saved_model.signatures)\n",
    "# saved_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0]\n",
    "# concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# new_model = tf.keras.models.load_model(\"output\")\n",
    "# new_model.summary()\n",
    "# concrete_func = new_model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "# tf.saved_model.save(new_model, \"output-new\", signatures={\"infer\": concrete_func})\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(\"output-new\")\n",
    "\n",
    "\"\"\"\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.\n",
    "]\n",
    "converter.experimental_enable_resource_variables = True\n",
    "tflite_model = converter.convert()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ba1a2a-8ff8-47ca-a459-b3e36a899046",
   "metadata": {},
   "source": [
    "# Test tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7b87f9-c5d7-4e77-8847-eb8d60a354a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def run(interpreter, text): \n",
    "    token_ids = data_util.tokenize(text)\n",
    "    input_ids = np.array([token_ids], dtype=np.int32)\n",
    "    \n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print(\"---INPUT DETAILS----\")\n",
    "    print(input_details)\n",
    "    print(\"---OUTPUT DETAILS----\")\n",
    "    print(output_details)\n",
    "     \n",
    "    # Resize input shape based on current input\n",
    "    interpreter.resize_tensor_input(input_details[0]['index'], input_ids.shape)\n",
    "    interpreter.allocate_tensors()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_ids)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    return output_data\n",
    "\n",
    "\n",
    "def load_interpreter(saved_model_path):\n",
    "    # Load the TFLite model and allocate tensors.\n",
    "    if Path(saved_model_path).exists():\n",
    "        print(\"Loading existing model\")\n",
    "        interpreter = tf.lite.Interpreter(model_path=saved_model_path)\n",
    "    else:\n",
    "        print(\"Converting model\")\n",
    "        interpreter = convert(model)\n",
    "    return interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bec7b069-5111-4ec4-9076-9b1a4e9cb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "interpreter = load_interpreter(SAVED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3f1a1fcf-f4ef-4fd5-b7fc-c91eb8c783a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_data = emotions_encoded[\"train\"][test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "04b32464-b847-4679-853e-b3a8893b61dc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel romantic too\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(87,), dtype=int64, numpy=\n",
       "array([ 101, 1045, 2514, 6298, 2205,  102,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected\n",
    "text = emotions[\"train\"][test_id][\"text\"]\n",
    "print(text)\n",
    "input_data[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f7476be-6a57-41e0-9ae5-9c4d5c5ed4ff",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1045, 2514, 6298, 2205, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "input_ids = data_util.tokenize(text)\n",
    "print(input_ids)\n",
    "\n",
    "for i, input_id in enumerate(input_ids):\n",
    "    if input_id is None:\n",
    "        print(i, input_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3a056ebf-a863-492e-83a7-641fa48eebe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---INPUT DETAILS----\n",
      "[{'name': 'serving_default_args_0:0', 'index': 0, 'shape': array([ 1, 87], dtype=int32), 'shape_signature': array([-1, -1], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "---OUTPUT DETAILS----\n",
      "[{'name': 'StatefulPartitionedCall:0', 'index': 720, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "output_data = run(interpreter, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8c50acec-07b7-4bbe-87c1-326041efaa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.4168833 , -0.69242686,  5.377131  , -1.7829715 , -1.1952535 ,\n",
       "        -1.18323   ]], dtype=float32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4492c3d7-e2d7-4d89-813c-d85ae93de062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[-1.460196 , -0.5406702,  5.794202 , -1.9637783, -1.5457897,\n",
       "        -1.2147366]], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "92b3d817-6255-4e7c-92a3-e789fe776222",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tf.math.softmax(output_data, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "750d6964-d639-42a8-bc9f-89e5cf8b4a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
       "array([[1.1126471e-03, 2.2960694e-03, 9.9302554e-01, 7.7155605e-04,\n",
       "        1.3887055e-03, 1.4055034e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b74450-cb78-4d97-8e2a-09f986be7ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
